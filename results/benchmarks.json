{
    "benchmarks.TimeAppend.time_append": {
        "code": "class TimeAppend:\n    def time_append(self, shapes, sort):\n        execute(self.df1.append(self.df2, sort=sort))\n\n    def setup(self, shapes, sort):\n        self.df1 = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shapes[0], RAND_LOW, RAND_HIGH\n        )\n        self.df2 = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shapes[1], RAND_LOW, RAND_HIGH\n        )\n        if sort:\n            self.df1.columns = self.df1.columns[::-1]",
        "min_run_count": 2,
        "name": "benchmarks.TimeAppend.time_append",
        "number": 0,
        "param_names": [
            "shapes",
            "sort"
        ],
        "params": [
            [
                "[[5000, 5000], [5000, 5000]]",
                "[[500000, 20], [1000000, 10]]"
            ],
            [
                "False",
                "True"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "c2d89eb99a9d7965ff21009a90377a267577d695e1baeeedba0a97d62f2f8030",
        "warmup_time": -1
    },
    "benchmarks.TimeArithmetic.time_abs": {
        "code": "class TimeArithmetic:\n    def time_abs(self, shape, axis):\n        execute(self.df.abs())\n\n    def setup(self, shape, axis):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)",
        "min_run_count": 2,
        "name": "benchmarks.TimeArithmetic.time_abs",
        "number": 0,
        "param_names": [
            "shape",
            "axis"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "24f94b5cd16c91dc2b6404040d368ff5c94e3501114f33c6725c5518b224dc3f",
        "warmup_time": -1
    },
    "benchmarks.TimeArithmetic.time_add": {
        "code": "class TimeArithmetic:\n    def time_add(self, shape, axis):\n        execute(self.df.add(2, axis=axis))\n\n    def setup(self, shape, axis):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)",
        "min_run_count": 2,
        "name": "benchmarks.TimeArithmetic.time_add",
        "number": 0,
        "param_names": [
            "shape",
            "axis"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "926c0f2b5bfbd2ed09c9346ea43c9fd1dd9b118570849bf7441f48a03516a224",
        "warmup_time": -1
    },
    "benchmarks.TimeArithmetic.time_aggregate": {
        "code": "class TimeArithmetic:\n    def time_aggregate(self, shape, axis):\n        execute(self.df.aggregate(lambda df: df.sum(), axis=axis))\n\n    def setup(self, shape, axis):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)",
        "min_run_count": 2,
        "name": "benchmarks.TimeArithmetic.time_aggregate",
        "number": 0,
        "param_names": [
            "shape",
            "axis"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f9927313f1bbf27149feaf733d3ac499f4ee819b96f0d62eddc3934eca2d2fb2",
        "warmup_time": -1
    },
    "benchmarks.TimeArithmetic.time_apply": {
        "code": "class TimeArithmetic:\n    def time_apply(self, shape, axis):\n        execute(self.df.apply(lambda df: df.sum(), axis=axis))\n\n    def setup(self, shape, axis):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)",
        "min_run_count": 2,
        "name": "benchmarks.TimeArithmetic.time_apply",
        "number": 0,
        "param_names": [
            "shape",
            "axis"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "219317b7fcbaf3f87050bca6999e1b68c258853598a859ac59da82b025bf251a",
        "warmup_time": -1
    },
    "benchmarks.TimeArithmetic.time_count": {
        "code": "class TimeArithmetic:\n    def time_count(self, shape, axis):\n        execute(self.df.count(axis=axis))\n\n    def setup(self, shape, axis):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)",
        "min_run_count": 2,
        "name": "benchmarks.TimeArithmetic.time_count",
        "number": 0,
        "param_names": [
            "shape",
            "axis"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "937a01aa3157b31b90d06b230e988161f695f9177379d1cabcdebbbde01dbee8",
        "warmup_time": -1
    },
    "benchmarks.TimeArithmetic.time_is_in": {
        "code": "class TimeArithmetic:\n    def time_is_in(self, shape, axis):\n        execute(self.df.isin([0, 2]))\n\n    def setup(self, shape, axis):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)",
        "min_run_count": 2,
        "name": "benchmarks.TimeArithmetic.time_is_in",
        "number": 0,
        "param_names": [
            "shape",
            "axis"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "75f626b4cadcefefd7d710aca76a4d389b9e84c04ad15e57f38a5eb5ef3ee1fe",
        "warmup_time": -1
    },
    "benchmarks.TimeArithmetic.time_mean": {
        "code": "class TimeArithmetic:\n    def time_mean(self, shape, axis):\n        execute(self.df.mean(axis=axis))\n\n    def setup(self, shape, axis):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)",
        "min_run_count": 2,
        "name": "benchmarks.TimeArithmetic.time_mean",
        "number": 0,
        "param_names": [
            "shape",
            "axis"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b541392002bd635e8fdf6d069d1fb9147bf2e0d1cbccf130bf1b596c17454708",
        "warmup_time": -1
    },
    "benchmarks.TimeArithmetic.time_median": {
        "code": "class TimeArithmetic:\n    def time_median(self, shape, axis):\n        execute(self.df.median(axis=axis))\n\n    def setup(self, shape, axis):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)",
        "min_run_count": 2,
        "name": "benchmarks.TimeArithmetic.time_median",
        "number": 0,
        "param_names": [
            "shape",
            "axis"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "6f99b2ce6d39b39818206977c6513e7df8166e01bbff37724a82601a9c4875ad",
        "warmup_time": -1
    },
    "benchmarks.TimeArithmetic.time_mod": {
        "code": "class TimeArithmetic:\n    def time_mod(self, shape, axis):\n        execute(self.df.mod(2, axis=axis))\n\n    def setup(self, shape, axis):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)",
        "min_run_count": 2,
        "name": "benchmarks.TimeArithmetic.time_mod",
        "number": 0,
        "param_names": [
            "shape",
            "axis"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "79c73bb1f28da6f697ffd689a2159040e9c1e55940e3d12c5978a59a0a1d49e1",
        "warmup_time": -1
    },
    "benchmarks.TimeArithmetic.time_mode": {
        "code": "class TimeArithmetic:\n    def time_mode(self, shape, axis):\n        execute(self.df.mode(axis=axis))\n\n    def setup(self, shape, axis):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)",
        "min_run_count": 2,
        "name": "benchmarks.TimeArithmetic.time_mode",
        "number": 0,
        "param_names": [
            "shape",
            "axis"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "8a005b316455fcca753ca4edbb670ef5f5b93695be2cdda740158fe96407f527",
        "warmup_time": -1
    },
    "benchmarks.TimeArithmetic.time_mul": {
        "code": "class TimeArithmetic:\n    def time_mul(self, shape, axis):\n        execute(self.df.mul(2, axis=axis))\n\n    def setup(self, shape, axis):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)",
        "min_run_count": 2,
        "name": "benchmarks.TimeArithmetic.time_mul",
        "number": 0,
        "param_names": [
            "shape",
            "axis"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "641518d19f0fdf68546ce858ce9bb40a774bf6de779da780a464f7b9e6e3dbc6",
        "warmup_time": -1
    },
    "benchmarks.TimeArithmetic.time_nunique": {
        "code": "class TimeArithmetic:\n    def time_nunique(self, shape, axis):\n        execute(self.df.nunique(axis=axis))\n\n    def setup(self, shape, axis):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)",
        "min_run_count": 2,
        "name": "benchmarks.TimeArithmetic.time_nunique",
        "number": 0,
        "param_names": [
            "shape",
            "axis"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "2e6aa9b726c293d7e2d3121d8ad006add467a8da0531eac8774b3f0384ca64bc",
        "warmup_time": -1
    },
    "benchmarks.TimeArithmetic.time_sum": {
        "code": "class TimeArithmetic:\n    def time_sum(self, shape, axis):\n        execute(self.df.sum(axis=axis))\n\n    def setup(self, shape, axis):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)",
        "min_run_count": 2,
        "name": "benchmarks.TimeArithmetic.time_sum",
        "number": 0,
        "param_names": [
            "shape",
            "axis"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "3ade96bfe969295a9d3c99d61bc88dedda36a799925710d5620e5fb30438d074",
        "warmup_time": -1
    },
    "benchmarks.TimeArithmetic.time_transpose": {
        "code": "class TimeArithmetic:\n    def time_transpose(self, shape, axis):\n        execute(self.df.transpose())\n\n    def setup(self, shape, axis):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)",
        "min_run_count": 2,
        "name": "benchmarks.TimeArithmetic.time_transpose",
        "number": 0,
        "param_names": [
            "shape",
            "axis"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "899e91bd633602197288afb8eedca1c38d2df5fb39590f0693060e896e297e41",
        "warmup_time": -1
    },
    "benchmarks.TimeAstype.time_astype": {
        "code": "class TimeAstype:\n    def time_astype(self, shape, dtype, astype_ncolumns):\n        execute(self.df.astype(self.astype_arg))\n\n    def setup(self, shape, dtype, astype_ncolumns):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        if astype_ncolumns == \"all\":\n            self.astype_arg = dtype\n        elif astype_ncolumns == \"one\":\n            self.astype_arg = {\"col1\": dtype}\n        else:\n            raise ValueError(f\"astype_ncolumns: {astype_ncolumns} isn't supported\")",
        "min_run_count": 2,
        "name": "benchmarks.TimeAstype.time_astype",
        "number": 0,
        "param_names": [
            "shape",
            "dtype",
            "astype_ncolumns"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "'float64'",
                "'category'"
            ],
            [
                "'one'",
                "'all'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "2c9914d910acdc984e9ed93f58b52ea59a07273d6dd0f8b8d150e78cfce95cec",
        "warmup_time": -1
    },
    "benchmarks.TimeBinaryOp.time_binary_op": {
        "code": "class TimeBinaryOp:\n    def time_binary_op(self, shapes, binary_op, axis):\n        execute(self.op(self.df2, axis=axis))\n\n    def setup(self, shapes, binary_op, axis):\n        self.df1 = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shapes[0], RAND_LOW, RAND_HIGH\n        )\n        self.df2 = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shapes[1], RAND_LOW, RAND_HIGH\n        )\n        self.op = getattr(self.df1, binary_op)",
        "min_run_count": 2,
        "name": "benchmarks.TimeBinaryOp.time_binary_op",
        "number": 0,
        "param_names": [
            "shapes",
            "binary_op",
            "axis"
        ],
        "params": [
            [
                "[[5000, 5000], [5000, 5000]]",
                "[[500000, 20], [1000000, 10]]"
            ],
            [
                "'mul'"
            ],
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "9ff776f725432c65f49e1c3f59022f6f3d976278510bf9915fda51ba51ad13ae",
        "warmup_time": -1
    },
    "benchmarks.TimeConcat.time_concat": {
        "code": "class TimeConcat:\n    def time_concat(self, shapes, how, axis):\n        execute(IMPL[ASV_USE_IMPL].concat([self.df1, self.df2], axis=axis, join=how))\n\n    def setup(self, shapes, how, axis):\n        self.df1 = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shapes[0], RAND_LOW, RAND_HIGH\n        )\n        self.df2 = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shapes[1], RAND_LOW, RAND_HIGH\n        )",
        "min_run_count": 2,
        "name": "benchmarks.TimeConcat.time_concat",
        "number": 0,
        "param_names": [
            "shapes",
            "how",
            "axis"
        ],
        "params": [
            [
                "[[5000, 5000], [5000, 5000]]",
                "[[500000, 20], [1000000, 10]]"
            ],
            [
                "'inner'"
            ],
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "718c07f0450388e6f586cf10e7466f364cc94e4a6909380b7f50d8213c45205c",
        "warmup_time": -1
    },
    "benchmarks.TimeDescribe.time_describe": {
        "code": "class TimeDescribe:\n    def time_describe(self, shape):\n        execute(self.df.describe())\n\n    def setup(self, shape):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)",
        "min_run_count": 2,
        "name": "benchmarks.TimeDescribe.time_describe",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b06d1af039ee49fcea92c1e11a041c293d33b86c73874976592036d57e966eb8",
        "warmup_time": -1
    },
    "benchmarks.TimeDrop.time_drop": {
        "code": "class TimeDrop:\n    def time_drop(self, shape, axis, drop_ncols):\n        execute(self.df.drop(self.labels, axis))\n\n    def setup(self, shape, axis, drop_ncols):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        drop_count = (\n            int(len(self.df.axes[axis]) * drop_ncols)\n            if isinstance(drop_ncols, float)\n            else drop_ncols\n        )\n        self.labels = self.df.axes[axis][:drop_count]",
        "min_run_count": 2,
        "name": "benchmarks.TimeDrop.time_drop",
        "number": 0,
        "param_names": [
            "shape",
            "axis",
            "drop_ncols"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "0",
                "1"
            ],
            [
                "1",
                "0.8"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "cbeb16adcb3fadd00159e6c9922ccbfaac0eb086cd953d0eebb36b89c3e6e266",
        "warmup_time": -1
    },
    "benchmarks.TimeExplode.time_explode": {
        "code": "class TimeExplode:\n    def time_explode(self, shape):\n        execute(self.df.explode(\"col1\"))\n\n    def setup(self, shape):\n        self.df = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH, gen_unique_key=True\n        )",
        "min_run_count": 2,
        "name": "benchmarks.TimeExplode.time_explode",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "838561e282ad48904dd657640c80a57649cdca0dd65193a9f71528401ab163be",
        "warmup_time": -1
    },
    "benchmarks.TimeFillnaDataFrame.time_fillna": {
        "code": "class TimeFillnaDataFrame:\n    def time_fillna(self, value_type, shape, limit):\n        execute(self.df.fillna(**self.kw))\n\n    def setup(self, value_type, shape, limit):\n        pd = IMPL[ASV_USE_IMPL]\n        self.df = gen_nan_data(ASV_USE_IMPL, *shape)\n        columns = self.df.columns\n    \n        if value_type == \"scalar\":\n            self.value = 18.19\n        elif value_type == \"dict\":\n            self.value = {k: i * 1.23 for i, k in enumerate(columns)}\n        elif value_type == \"Series\":\n            self.value = pd.Series(\n                [i * 1.23 for i in range(len(columns))], index=columns\n            )\n        elif value_type == \"DataFrame\":\n            self.value = pd.DataFrame(\n                {\n                    k: [i + j * 1.23 for j in range(shape[0])]\n                    for i, k in enumerate(columns)\n                },\n                index=pd.RangeIndex(shape[0]),\n                columns=columns,\n            )\n        else:\n            assert False\n        limit = int(limit * shape[0]) if limit else None\n        self.kw = {\"value\": self.value, \"limit\": limit}",
        "min_run_count": 2,
        "name": "benchmarks.TimeFillnaDataFrame.time_fillna",
        "number": 0,
        "param_names": [
            "value_type",
            "shape",
            "limit"
        ],
        "params": [
            [
                "'scalar'",
                "'dict'",
                "'DataFrame'",
                "'Series'"
            ],
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "None",
                "0.8"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "2a53f1e1a0506c8eb4c8131875b0264407549701c13dd2dd8018496eb81ed5ec",
        "warmup_time": -1
    },
    "benchmarks.TimeFillnaDataFrame.time_fillna_inplace": {
        "code": "class TimeFillnaDataFrame:\n    def time_fillna_inplace(self, value_type, shape, limit):\n        self.df.fillna(inplace=True, **self.kw)\n        execute(self.df)\n\n    def setup(self, value_type, shape, limit):\n        pd = IMPL[ASV_USE_IMPL]\n        self.df = gen_nan_data(ASV_USE_IMPL, *shape)\n        columns = self.df.columns\n    \n        if value_type == \"scalar\":\n            self.value = 18.19\n        elif value_type == \"dict\":\n            self.value = {k: i * 1.23 for i, k in enumerate(columns)}\n        elif value_type == \"Series\":\n            self.value = pd.Series(\n                [i * 1.23 for i in range(len(columns))], index=columns\n            )\n        elif value_type == \"DataFrame\":\n            self.value = pd.DataFrame(\n                {\n                    k: [i + j * 1.23 for j in range(shape[0])]\n                    for i, k in enumerate(columns)\n                },\n                index=pd.RangeIndex(shape[0]),\n                columns=columns,\n            )\n        else:\n            assert False\n        limit = int(limit * shape[0]) if limit else None\n        self.kw = {\"value\": self.value, \"limit\": limit}",
        "min_run_count": 2,
        "name": "benchmarks.TimeFillnaDataFrame.time_fillna_inplace",
        "number": 0,
        "param_names": [
            "value_type",
            "shape",
            "limit"
        ],
        "params": [
            [
                "'scalar'",
                "'dict'",
                "'DataFrame'",
                "'Series'"
            ],
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "None",
                "0.8"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "56651978c860fb892d9eb8fcf32ccd99fcbadfe19d53dcdb4b70a9d2e38a3c6b",
        "warmup_time": -1
    },
    "benchmarks.TimeFillnaSeries.time_fillna": {
        "code": "class TimeFillnaSeries:\n    def time_fillna(self, value_type, shape, limit):\n        execute(self.series.fillna(**self.kw))\n\n    def setup(self, value_type, shape, limit):\n        pd = IMPL[ASV_USE_IMPL]\n        self.series = gen_nan_data(ASV_USE_IMPL, *shape)\n    \n        if value_type == \"scalar\":\n            self.value = 18.19\n        elif value_type == \"dict\":\n            self.value = {k: k * 1.23 for k in range(shape[0])}\n        elif value_type == \"Series\":\n            self.value = pd.Series(\n                [k * 1.23 for k in range(shape[0])], index=pd.RangeIndex(shape[0])\n            )\n        else:\n            assert False\n        limit = int(limit * shape[0]) if limit else None\n        self.kw = {\"value\": self.value, \"limit\": limit}",
        "min_run_count": 2,
        "name": "benchmarks.TimeFillnaSeries.time_fillna",
        "number": 0,
        "param_names": [
            "value_type",
            "shape",
            "limit"
        ],
        "params": [
            [
                "'scalar'",
                "'dict'",
                "'Series'"
            ],
            [
                "[100000, 1]"
            ],
            [
                "None",
                "0.8"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "115f3f751e134490d58d0d1c2719751654d2e9884fd5454b14ff96532d704a97",
        "warmup_time": -1
    },
    "benchmarks.TimeFillnaSeries.time_fillna_inplace": {
        "code": "class TimeFillnaSeries:\n    def time_fillna_inplace(self, value_type, shape, limit):\n        self.series.fillna(inplace=True, **self.kw)\n        execute(self.series)\n\n    def setup(self, value_type, shape, limit):\n        pd = IMPL[ASV_USE_IMPL]\n        self.series = gen_nan_data(ASV_USE_IMPL, *shape)\n    \n        if value_type == \"scalar\":\n            self.value = 18.19\n        elif value_type == \"dict\":\n            self.value = {k: k * 1.23 for k in range(shape[0])}\n        elif value_type == \"Series\":\n            self.value = pd.Series(\n                [k * 1.23 for k in range(shape[0])], index=pd.RangeIndex(shape[0])\n            )\n        else:\n            assert False\n        limit = int(limit * shape[0]) if limit else None\n        self.kw = {\"value\": self.value, \"limit\": limit}",
        "min_run_count": 2,
        "name": "benchmarks.TimeFillnaSeries.time_fillna_inplace",
        "number": 0,
        "param_names": [
            "value_type",
            "shape",
            "limit"
        ],
        "params": [
            [
                "'scalar'",
                "'dict'",
                "'Series'"
            ],
            [
                "[100000, 1]"
            ],
            [
                "None",
                "0.8"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "72c059f8c6ffc17e37dde767459a738f551b15746a1d284572ee91b3d913dc9c",
        "warmup_time": -1
    },
    "benchmarks.TimeGroupByDefaultAggregations.time_groupby_count": {
        "code": "class TimeGroupByDefaultAggregations:\n    def time_groupby_count(self, *args, **kwargs):\n        execute(self.df.groupby(by=self.groupby_columns).count())\n\nclass BaseTimeGroupBy:\n    def setup(self, shape, ngroups=5, groupby_ncols=1):\n        ngroups = translator_groupby_ngroups(ngroups, shape)\n        self.df, self.groupby_columns = generate_dataframe(\n            ASV_USE_IMPL,\n            \"int\",\n            *shape,\n            RAND_LOW,\n            RAND_HIGH,\n            groupby_ncols,\n            count_groups=ngroups,\n        )",
        "min_run_count": 2,
        "name": "benchmarks.TimeGroupByDefaultAggregations.time_groupby_count",
        "number": 0,
        "param_names": [
            "shape",
            "ngroups"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "100",
                "'huge_amount_groups'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "46a1f84a3f0c0b546f071c9be94866f953ddb6e2384a6ccbc518ad0b9154380c",
        "warmup_time": -1
    },
    "benchmarks.TimeGroupByDefaultAggregations.time_groupby_mean": {
        "code": "class TimeGroupByDefaultAggregations:\n    def time_groupby_mean(self, *args, **kwargs):\n        execute(self.df.groupby(by=self.groupby_columns).mean())\n\nclass BaseTimeGroupBy:\n    def setup(self, shape, ngroups=5, groupby_ncols=1):\n        ngroups = translator_groupby_ngroups(ngroups, shape)\n        self.df, self.groupby_columns = generate_dataframe(\n            ASV_USE_IMPL,\n            \"int\",\n            *shape,\n            RAND_LOW,\n            RAND_HIGH,\n            groupby_ncols,\n            count_groups=ngroups,\n        )",
        "min_run_count": 2,
        "name": "benchmarks.TimeGroupByDefaultAggregations.time_groupby_mean",
        "number": 0,
        "param_names": [
            "shape",
            "ngroups"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "100",
                "'huge_amount_groups'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "23ad92017cdfe129d3ab99f79e62fe2722466cfac0a55179a1ecc00b910c4857",
        "warmup_time": -1
    },
    "benchmarks.TimeGroupByDefaultAggregations.time_groupby_size": {
        "code": "class TimeGroupByDefaultAggregations:\n    def time_groupby_size(self, *args, **kwargs):\n        execute(self.df.groupby(by=self.groupby_columns).size())\n\nclass BaseTimeGroupBy:\n    def setup(self, shape, ngroups=5, groupby_ncols=1):\n        ngroups = translator_groupby_ngroups(ngroups, shape)\n        self.df, self.groupby_columns = generate_dataframe(\n            ASV_USE_IMPL,\n            \"int\",\n            *shape,\n            RAND_LOW,\n            RAND_HIGH,\n            groupby_ncols,\n            count_groups=ngroups,\n        )",
        "min_run_count": 2,
        "name": "benchmarks.TimeGroupByDefaultAggregations.time_groupby_size",
        "number": 0,
        "param_names": [
            "shape",
            "ngroups"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "100",
                "'huge_amount_groups'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f597a5f0dac5a4fabed5dd5548e9d73d8d39698a8437bf3466131cb18ed4dde5",
        "warmup_time": -1
    },
    "benchmarks.TimeGroupByDefaultAggregations.time_groupby_sum": {
        "code": "class TimeGroupByDefaultAggregations:\n    def time_groupby_sum(self, *args, **kwargs):\n        execute(self.df.groupby(by=self.groupby_columns).sum())\n\nclass BaseTimeGroupBy:\n    def setup(self, shape, ngroups=5, groupby_ncols=1):\n        ngroups = translator_groupby_ngroups(ngroups, shape)\n        self.df, self.groupby_columns = generate_dataframe(\n            ASV_USE_IMPL,\n            \"int\",\n            *shape,\n            RAND_LOW,\n            RAND_HIGH,\n            groupby_ncols,\n            count_groups=ngroups,\n        )",
        "min_run_count": 2,
        "name": "benchmarks.TimeGroupByDefaultAggregations.time_groupby_sum",
        "number": 0,
        "param_names": [
            "shape",
            "ngroups"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "100",
                "'huge_amount_groups'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "ec74cb917a463fae4337b5d3444788e696f710113878e9df35417a0f56f92d09",
        "warmup_time": -1
    },
    "benchmarks.TimeGroupByDictionaryAggregation.time_groupby_dict_agg": {
        "code": "class TimeGroupByDictionaryAggregation:\n    def time_groupby_dict_agg(self, *args, **kwargs):\n        execute(self.df.groupby(by=self.groupby_columns).agg(self.agg_dict))\n\n    def setup(self, shape, ngroups, operation_type):\n        super().setup(shape, ngroups)\n        self.cols_to_agg = self.df.columns[1:4]\n        operations = self.operations[operation_type]\n        self.agg_dict = {\n            c: operations[i % len(operations)] for i, c in enumerate(self.cols_to_agg)\n        }",
        "min_run_count": 2,
        "name": "benchmarks.TimeGroupByDictionaryAggregation.time_groupby_dict_agg",
        "number": 0,
        "param_names": [
            "shape",
            "ngroups",
            "operation_type"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "100",
                "'huge_amount_groups'"
            ],
            [
                "'reduce'",
                "'aggregation'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "7aa41865cba30449bba2f4d9a40fe5d15e9d9b4c2c737222bd2a643fd6dcb39a",
        "warmup_time": -1
    },
    "benchmarks.TimeGroupByMultiColumn.time_groupby_agg_mean": {
        "code": "class TimeGroupByMultiColumn:\n    def time_groupby_agg_mean(self, *args, **kwargs):\n        execute(self.df.groupby(by=self.groupby_columns).apply(lambda df: df.mean()))\n\nclass BaseTimeGroupBy:\n    def setup(self, shape, ngroups=5, groupby_ncols=1):\n        ngroups = translator_groupby_ngroups(ngroups, shape)\n        self.df, self.groupby_columns = generate_dataframe(\n            ASV_USE_IMPL,\n            \"int\",\n            *shape,\n            RAND_LOW,\n            RAND_HIGH,\n            groupby_ncols,\n            count_groups=ngroups,\n        )",
        "min_run_count": 2,
        "name": "benchmarks.TimeGroupByMultiColumn.time_groupby_agg_mean",
        "number": 0,
        "param_names": [
            "shape",
            "ngroups",
            "groupby_ncols"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "100",
                "'huge_amount_groups'"
            ],
            [
                "6"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "6584be7f02bda8d4601daf00fbd3fce226a7d4436faa6353a196619348047dea",
        "warmup_time": -1
    },
    "benchmarks.TimeGroupByMultiColumn.time_groupby_agg_quan": {
        "code": "class TimeGroupByMultiColumn:\n    def time_groupby_agg_quan(self, *args, **kwargs):\n        execute(self.df.groupby(by=self.groupby_columns).agg(\"quantile\"))\n\nclass BaseTimeGroupBy:\n    def setup(self, shape, ngroups=5, groupby_ncols=1):\n        ngroups = translator_groupby_ngroups(ngroups, shape)\n        self.df, self.groupby_columns = generate_dataframe(\n            ASV_USE_IMPL,\n            \"int\",\n            *shape,\n            RAND_LOW,\n            RAND_HIGH,\n            groupby_ncols,\n            count_groups=ngroups,\n        )",
        "min_run_count": 2,
        "name": "benchmarks.TimeGroupByMultiColumn.time_groupby_agg_quan",
        "number": 0,
        "param_names": [
            "shape",
            "ngroups",
            "groupby_ncols"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "100",
                "'huge_amount_groups'"
            ],
            [
                "6"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "202444e83676d4998bfbfc58f218de93462f070c86e5000c628e56fb334193dc",
        "warmup_time": -1
    },
    "benchmarks.TimeHead.time_head": {
        "code": "class TimeHead:\n    def time_head(self, shape, head_count):\n        execute(self.df.head(self.head_count))\n\n    def setup(self, shape, head_count):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        self.head_count = (\n            int(head_count * len(self.df.index))\n            if isinstance(head_count, float)\n            else head_count\n        )",
        "min_run_count": 2,
        "name": "benchmarks.TimeHead.time_head",
        "number": 0,
        "param_names": [
            "shape",
            "head_count"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "5",
                "0.8"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "0ab97d453eb88717822a7fbc0a43910d61e597489b0d1c49eec882656edd2dcf",
        "warmup_time": -1
    },
    "benchmarks.TimeIndexing.time_iloc": {
        "code": "class TimeIndexing:\n    def time_iloc(self, shape, indexer_type):\n        # Pandas doesn't implement `df.iloc[series boolean_mask]` and raises an exception on it.\n        # Replacing this with the semantically equivalent construction:\n        if indexer_type != \"bool_series\":\n            execute(self.df.iloc[self.indexer])\n        else:\n            execute(self.df[self.indexer])\n\n    def setup(self, shape, indexer_type):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df)\n    \n        self.indexer = self.indexer_getters[indexer_type](self.df)\n        if isinstance(self.indexer, (pd.Series, pd.DataFrame)):\n            # HACK: Triggering `dtypes` meta-data computation in advance,\n            # so it won't affect the `loc/iloc` time:\n            self.indexer.dtypes",
        "min_run_count": 2,
        "name": "benchmarks.TimeIndexing.time_iloc",
        "number": 0,
        "param_names": [
            "shape",
            "indexer_type"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "'bool_array'",
                "'bool_series'",
                "'scalar'",
                "'slice'",
                "'continuous_slice'",
                "'numpy_array_take_all_values'",
                "'python_list_take_10_values'",
                "'function'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "0bd0ae3526940e0a2f9f79b17c7583ba0f2d6b33aad55393f2bd7a5f63b4de3f",
        "warmup_time": -1
    },
    "benchmarks.TimeIndexing.time_loc": {
        "code": "class TimeIndexing:\n    def time_loc(self, shape, indexer_type):\n        execute(self.df.loc[self.indexer])\n\n    def setup(self, shape, indexer_type):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df)\n    \n        self.indexer = self.indexer_getters[indexer_type](self.df)\n        if isinstance(self.indexer, (pd.Series, pd.DataFrame)):\n            # HACK: Triggering `dtypes` meta-data computation in advance,\n            # so it won't affect the `loc/iloc` time:\n            self.indexer.dtypes",
        "min_run_count": 2,
        "name": "benchmarks.TimeIndexing.time_loc",
        "number": 0,
        "param_names": [
            "shape",
            "indexer_type"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "'bool_array'",
                "'bool_series'",
                "'scalar'",
                "'slice'",
                "'continuous_slice'",
                "'numpy_array_take_all_values'",
                "'python_list_take_10_values'",
                "'function'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "496fb1e124a319acd18ec43552530104fceb6b668df356a4694bc7f2fb0aa408",
        "warmup_time": -1
    },
    "benchmarks.TimeIndexingColumns.time___getitem__": {
        "code": "class TimeIndexingColumns:\n    def time___getitem__(self, shape):\n        execute(self.df[self.labels_indexer])\n\n    def setup(self, shape):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df)\n        self.numeric_indexer = [0, 1]\n        self.labels_indexer = self.df.columns[self.numeric_indexer].tolist()",
        "min_run_count": 2,
        "name": "benchmarks.TimeIndexingColumns.time___getitem__",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "38a0fad1487d34f22254d7e3abf8f0c9debc51c0a14c4d2cfad57f2b8a38723f",
        "warmup_time": -1
    },
    "benchmarks.TimeIndexingColumns.time_iloc": {
        "code": "class TimeIndexingColumns:\n    def time_iloc(self, shape):\n        execute(self.df.iloc[:, self.numeric_indexer])\n\n    def setup(self, shape):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df)\n        self.numeric_indexer = [0, 1]\n        self.labels_indexer = self.df.columns[self.numeric_indexer].tolist()",
        "min_run_count": 2,
        "name": "benchmarks.TimeIndexingColumns.time_iloc",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "d8b8c528f5b7eb459cf4f5cf42bb42af77b301eb1acec2dc93511ecd7a0584c5",
        "warmup_time": -1
    },
    "benchmarks.TimeIndexingColumns.time_loc": {
        "code": "class TimeIndexingColumns:\n    def time_loc(self, shape):\n        execute(self.df.loc[:, self.labels_indexer])\n\n    def setup(self, shape):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df)\n        self.numeric_indexer = [0, 1]\n        self.labels_indexer = self.df.columns[self.numeric_indexer].tolist()",
        "min_run_count": 2,
        "name": "benchmarks.TimeIndexingColumns.time_loc",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "1bcabed67270f400c9f0ff69bed971dbb47456a21fc3d705e3986bb2cef41996",
        "warmup_time": -1
    },
    "benchmarks.TimeInsert.time_insert_qc": {
        "code": "class TimeInsert:\n    def time_insert_qc(self, *args, **kwargs):\n        self.df.insert(loc=self.iloc, column=random_string(), value=self.item)\n        execute(self.df)\n\nclass BaseTimeSetItem:\n    def setup(self, shape, item_length, loc, is_equal_indices):\n        self.df = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH\n        ).copy()\n        self.loc, self.iloc = self.get_loc(\n            self.df, loc, item_length=item_length, axis=1\n        )\n    \n        self.item = self.df[self.loc] + 1\n        self.item_raw = self.item.to_numpy()\n        if not is_equal_indices:\n            self.item.index = reversed(self.item.index)",
        "min_run_count": 2,
        "name": "benchmarks.TimeInsert.time_insert_qc",
        "number": 0,
        "param_names": [
            "shape",
            "item_length",
            "loc",
            "is_equal_indices"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "1"
            ],
            [
                "'zero'",
                "'middle'",
                "'last'"
            ],
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "6a36fc5cdb39f04cd6acb87bb95abcbb19bda4f85209e8d039c523287bdbf7a2",
        "warmup_time": -1
    },
    "benchmarks.TimeInsert.time_insert_raw": {
        "code": "class TimeInsert:\n    def time_insert_raw(self, *args, **kwargs):\n        self.df.insert(loc=self.iloc, column=random_string(), value=self.item_raw)\n        execute(self.df)\n\nclass BaseTimeSetItem:\n    def setup(self, shape, item_length, loc, is_equal_indices):\n        self.df = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH\n        ).copy()\n        self.loc, self.iloc = self.get_loc(\n            self.df, loc, item_length=item_length, axis=1\n        )\n    \n        self.item = self.df[self.loc] + 1\n        self.item_raw = self.item.to_numpy()\n        if not is_equal_indices:\n            self.item.index = reversed(self.item.index)",
        "min_run_count": 2,
        "name": "benchmarks.TimeInsert.time_insert_raw",
        "number": 0,
        "param_names": [
            "shape",
            "item_length",
            "loc",
            "is_equal_indices"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "1"
            ],
            [
                "'zero'",
                "'middle'",
                "'last'"
            ],
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "3df7c66b76b70618061bcfe51d0d0b9e10c21a48362cc453908a653cbe2fd176",
        "warmup_time": -1
    },
    "benchmarks.TimeJoin.time_join": {
        "code": "class TimeJoin:\n    def time_join(self, shapes, how, sort):\n        # join dataframes on index to get the predictable shape\n        execute(self.df1.join(self.df2, how=how, lsuffix=\"left_\", sort=sort))\n\n    def setup(self, shapes, how, sort):\n        self.df1 = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shapes[0], RAND_LOW, RAND_HIGH\n        )\n        self.df2 = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shapes[1], RAND_LOW, RAND_HIGH\n        )",
        "min_run_count": 2,
        "name": "benchmarks.TimeJoin.time_join",
        "number": 0,
        "param_names": [
            "shapes",
            "how",
            "sort"
        ],
        "params": [
            [
                "[[5000, 5000], [5000, 5000]]",
                "[[500000, 20], [1000000, 10]]"
            ],
            [
                "'left'",
                "'inner'"
            ],
            [
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "1aebc2ab80819fc05dfc2e9db051894b755bc1f69150780b6a4541019f1728dc",
        "warmup_time": -1
    },
    "benchmarks.TimeMerge.time_merge": {
        "code": "class TimeMerge:\n    def time_merge(self, shapes, how, sort):\n        # merge dataframes by index to get the predictable shape\n        execute(\n            self.df1.merge(\n                self.df2, left_index=True, right_index=True, how=how, sort=sort\n            )\n        )\n\n    def setup(self, shapes, how, sort):\n        self.df1 = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shapes[0], RAND_LOW, RAND_HIGH\n        )\n        self.df2 = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shapes[1], RAND_LOW, RAND_HIGH\n        )",
        "min_run_count": 2,
        "name": "benchmarks.TimeMerge.time_merge",
        "number": 0,
        "param_names": [
            "shapes",
            "how",
            "sort"
        ],
        "params": [
            [
                "[[5000, 5000], [5000, 5000]]",
                "[[500000, 20], [1000000, 10]]"
            ],
            [
                "'left'",
                "'inner'"
            ],
            [
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "5dd956fb7db1d5b0a96e59375c5e98318f9f43faa97b9b6562cf41d9445c9d9a",
        "warmup_time": -1
    },
    "benchmarks.TimeMultiIndexing.time_multiindex_loc": {
        "code": "class TimeMultiIndexing:\n    def time_multiindex_loc(self, shape):\n        execute(\n            self.df.loc[\n                self.df.index[2] : self.df.index[-2],\n                self.df.columns[2] : self.df.columns[-2],\n            ]\n        )\n\n    def setup(self, shape):\n        df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n    \n        index = pd.MultiIndex.from_product([df.index[: shape[0] // 2], [\"bar\", \"foo\"]])\n        columns = pd.MultiIndex.from_product(\n            [df.columns[: shape[1] // 2], [\"buz\", \"fuz\"]]\n        )\n    \n        df.index = index\n        df.columns = columns\n    \n        self.df = df.sort_index(axis=1)",
        "min_run_count": 2,
        "name": "benchmarks.TimeMultiIndexing.time_multiindex_loc",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "80e00dd183fe0c4a8126be25f72361ee20f99910b9769b7b35381e106e45dc4f",
        "warmup_time": -1
    },
    "benchmarks.TimeProperties.time_columns": {
        "code": "class TimeProperties:\n    def time_columns(self, shape):\n        return self.df.columns\n\n    def setup(self, shape):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)",
        "min_run_count": 2,
        "name": "benchmarks.TimeProperties.time_columns",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "effb7b0976e7b3b0ee005ca8318ad48fb5588e1836d8ec6535810367e46725a8",
        "warmup_time": -1
    },
    "benchmarks.TimeProperties.time_index": {
        "code": "class TimeProperties:\n    def time_index(self, shape):\n        return self.df.index\n\n    def setup(self, shape):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)",
        "min_run_count": 2,
        "name": "benchmarks.TimeProperties.time_index",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "487a3dbef05f696142e0534475d8373a9075dd28d31de0cf3449ca7a95ffb7b2",
        "warmup_time": -1
    },
    "benchmarks.TimeProperties.time_shape": {
        "code": "class TimeProperties:\n    def time_shape(self, shape):\n        return self.df.shape\n\n    def setup(self, shape):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)",
        "min_run_count": 2,
        "name": "benchmarks.TimeProperties.time_shape",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b8ce432425cc9aa74975357694dfa8cb95a0553d19b8daf97522757a0a607904",
        "warmup_time": -1
    },
    "benchmarks.TimeResetIndex.time_reset_index": {
        "code": "class TimeResetIndex:\n    def time_reset_index(self, shape, drop, level):\n        execute(self.df.reset_index(drop=drop, level=level))\n\n    def setup(self, shape, drop, level):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n    \n        if level:\n            index = pd.MultiIndex.from_product(\n                [self.df.index[: shape[0] // 2], [\"bar\", \"foo\"]],\n                names=[\"level_1\", \"level_2\"],\n            )\n            self.df.index = index",
        "min_run_count": 2,
        "name": "benchmarks.TimeResetIndex.time_reset_index",
        "number": 0,
        "param_names": [
            "shape",
            "drop",
            "level"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "False",
                "True"
            ],
            [
                "None",
                "'level_1'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "4ae1af8df03b9d41e917e8e6e18bd1eea483e80e35aa4f462ed1acee2f0a94a2",
        "warmup_time": -1
    },
    "benchmarks.TimeSetItem.time_setitem_qc": {
        "code": "class TimeSetItem:\n    def time_setitem_qc(self, *args, **kwargs):\n        self.df[self.loc] = self.item\n        execute(self.df)\n\nclass BaseTimeSetItem:\n    def setup(self, shape, item_length, loc, is_equal_indices):\n        self.df = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH\n        ).copy()\n        self.loc, self.iloc = self.get_loc(\n            self.df, loc, item_length=item_length, axis=1\n        )\n    \n        self.item = self.df[self.loc] + 1\n        self.item_raw = self.item.to_numpy()\n        if not is_equal_indices:\n            self.item.index = reversed(self.item.index)",
        "min_run_count": 2,
        "name": "benchmarks.TimeSetItem.time_setitem_qc",
        "number": 0,
        "param_names": [
            "shape",
            "item_length",
            "loc",
            "is_equal_indices"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "1"
            ],
            [
                "'zero'",
                "'middle'",
                "'last'"
            ],
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "1dcdd3d591970df5bad4e794a6b247d6b11cd6be21cf344809de06747fafbe17",
        "warmup_time": -1
    },
    "benchmarks.TimeSetItem.time_setitem_raw": {
        "code": "class TimeSetItem:\n    def time_setitem_raw(self, *args, **kwargs):\n        self.df[self.loc] = self.item_raw\n        execute(self.df)\n\nclass BaseTimeSetItem:\n    def setup(self, shape, item_length, loc, is_equal_indices):\n        self.df = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH\n        ).copy()\n        self.loc, self.iloc = self.get_loc(\n            self.df, loc, item_length=item_length, axis=1\n        )\n    \n        self.item = self.df[self.loc] + 1\n        self.item_raw = self.item.to_numpy()\n        if not is_equal_indices:\n            self.item.index = reversed(self.item.index)",
        "min_run_count": 2,
        "name": "benchmarks.TimeSetItem.time_setitem_raw",
        "number": 0,
        "param_names": [
            "shape",
            "item_length",
            "loc",
            "is_equal_indices"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "1"
            ],
            [
                "'zero'",
                "'middle'",
                "'last'"
            ],
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "6cae5f1f7d662915a35e36dc638b77707287a9bc5f67309f89f75fd57743ef01",
        "warmup_time": -1
    },
    "benchmarks.TimeSortValues.time_sort_values": {
        "code": "class TimeSortValues:\n    def time_sort_values(self, shape, columns_number, ascending_list):\n        execute(self.df.sort_values(self.columns, ascending=self.ascending))\n\n    def setup(self, shape, columns_number, ascending_list):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        self.columns = random_columns(self.df.columns, columns_number)\n        self.ascending = (\n            random_booleans(columns_number)\n            if ascending_list\n            else bool(random_booleans(1)[0])\n        )",
        "min_run_count": 2,
        "name": "benchmarks.TimeSortValues.time_sort_values",
        "number": 0,
        "param_names": [
            "shape",
            "columns_number",
            "ascending_list"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "1",
                "2",
                "10",
                "100"
            ],
            [
                "False",
                "True"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "5cf2258ccb3d7833acd5e9765b8023fdbf0d27fd70e540f457f576be26c37ec9",
        "warmup_time": -1
    },
    "benchmarks.TimeTail.time_tail": {
        "code": "class TimeTail:\n    def time_tail(self, shape, tail_count):\n        execute(self.df.tail(self.tail_count))\n\n    def setup(self, shape, tail_count):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        self.tail_count = (\n            int(tail_count * len(self.df.index))\n            if isinstance(tail_count, float)\n            else tail_count\n        )",
        "min_run_count": 2,
        "name": "benchmarks.TimeTail.time_tail",
        "number": 0,
        "param_names": [
            "shape",
            "tail_count"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "5",
                "0.8"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "9495a0ea1a5971936e52b8002b286fe7a89c3d369e790ad396708620f8daa685",
        "warmup_time": -1
    },
    "benchmarks.TimeValueCountsFrame.time_value_counts": {
        "code": "class TimeValueCountsFrame:\n    def time_value_counts(self, *args, **kwargs):\n        execute(self.df.value_counts(subset=self.subset))\n\nclass BaseTimeValueCounts:\n    def setup(self, shape, ngroups=5, subset=1):\n        ngroups = translator_groupby_ngroups(ngroups, shape)\n        self.df, self.subset = generate_dataframe(\n            ASV_USE_IMPL,\n            \"int\",\n            *shape,\n            RAND_LOW,\n            RAND_HIGH,\n            groupby_ncols=subset,\n            count_groups=ngroups,\n        )",
        "min_run_count": 2,
        "name": "benchmarks.TimeValueCountsFrame.time_value_counts",
        "number": 0,
        "param_names": [
            "shape",
            "ngroups",
            "subset"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "100",
                "'huge_amount_groups'"
            ],
            [
                "2",
                "10"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "488013b792c8a1214b90fe24d1b8841b79b064073eec3c9c83d6c8132499b600",
        "warmup_time": -1
    },
    "benchmarks.TimeValueCountsSeries.time_value_counts": {
        "code": "class TimeValueCountsSeries:\n    def time_value_counts(self, shape, ngroups, bins):\n        execute(self.df.value_counts(bins=bins))\n\n    def setup(self, shape, ngroups, bins):\n        super().setup(ngroups=ngroups, shape=shape)\n        self.df = self.df[self.subset[0]]",
        "min_run_count": 2,
        "name": "benchmarks.TimeValueCountsSeries.time_value_counts",
        "number": 0,
        "param_names": [
            "shape",
            "ngroups",
            "bins"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "100",
                "'huge_amount_groups'"
            ],
            [
                "None",
                "3"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "161a0ca50c23d2aadc9c3fc29d46e3cd4699d4354b8a8b752b6d17f67e924a85",
        "warmup_time": -1
    },
    "io.csv.TimeReadCsvNamesDtype.time_read_csv_names_dtype": {
        "code": "class TimeReadCsvNamesDtype:\n    def time_read_csv_names_dtype(self, cache, shape, names, dtype):\n        execute(\n            IMPL[ASV_USE_IMPL].read_csv(\n                self.filename,\n                names=self.names,\n                header=0,\n                dtype=self.dtype,\n                parse_dates=self.parse_dates,\n            )\n        )\n\n    def setup(self, cache, shape, names, dtype):\n        # ray init\n        if ASV_USE_IMPL == \"modin\":\n            pd.DataFrame([])\n        file_id = self._get_file_id(shape, dtype)\n        self.filename, self.names, self.dtype = cache[file_id]\n    \n        self.parse_dates = None\n        if dtype == \"Int64_Timestamp\":\n            # cached version of dtype should not change\n            self.dtype = self.dtype.copy()\n            for col in self._timestamp_columns:\n                del self.dtype[col]\n            self.parse_dates = self._timestamp_columns\n\n    def setup_cache(self, test_filename=\"io_test_file_csv_names_dtype\"):\n        # filenames with a metadata of saved dataframes\n        cache = {}\n        for shape in self.shapes:\n            for dtype in self._dtypes_params:\n                df = generate_dataframe(\"pandas\", \"int\", *shape, RAND_LOW, RAND_HIGH)\n                if dtype == \"Int64_Timestamp\":\n                    df = self._add_timestamp_columns(df)\n    \n                file_id = self._get_file_id(shape, dtype)\n                cache[file_id] = (\n                    f\"{test_filename}_{file_id}.csv\",\n                    df.columns.to_list(),\n                    df.dtypes.to_dict(),\n                )\n                df.to_csv(cache[file_id][0], index=False)\n        return cache",
        "min_run_count": 2,
        "name": "io.csv.TimeReadCsvNamesDtype.time_read_csv_names_dtype",
        "number": 0,
        "param_names": [
            "shape",
            "names",
            "dtype"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "'array-like'"
            ],
            [
                "'Int64'",
                "'Int64_Timestamp'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "io.csv:112",
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "369f7d09f2322523c7befbe04c29bc8fdd6ca1273a5932743a623dcfdef3e597",
        "warmup_time": -1
    },
    "io.csv.TimeReadCsvSkiprows.time_skiprows": {
        "code": "class TimeReadCsvSkiprows:\n    def time_skiprows(self, test_filenames, shape, skiprows):\n        execute(\n            IMPL[ASV_USE_IMPL].read_csv(\n                test_filenames[self.shape_id], skiprows=self.skiprows\n            )\n        )\n\n    def setup(self, test_filenames, shape, skiprows):\n        super().setup(test_filenames, shape, skiprows)\n        self.skiprows = self.skiprows_mapping[skiprows] if skiprows else None\n\nclass BaseReadCsv:\n    def setup_cache(self, test_filename=\"io_test_file\"):\n        test_filenames = prepare_io_data(\n            test_filename, self.data_type, get_benchmark_shapes(self.__class__.__name__)\n        )\n        return test_filenames",
        "min_run_count": 2,
        "name": "io.csv.TimeReadCsvSkiprows.time_skiprows",
        "number": 0,
        "param_names": [
            "shape",
            "skiprows"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "None",
                "'lambda_even_rows'",
                "'range_uniform'",
                "'range_step2'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "io.csv:33",
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "eeb505794553ac5bb0c569262aa60e11c74a22da29ae2a77b9c071c55c6770d1",
        "warmup_time": -1
    },
    "io.csv.TimeReadCsvTrueFalseValues.time_true_false_values": {
        "code": "class TimeReadCsvTrueFalseValues:\n    def time_true_false_values(self, test_filenames, shape):\n        execute(\n            IMPL[ASV_USE_IMPL].read_csv(\n                test_filenames[self.shape_id],\n                true_values=[\"Yes\", \"true\"],\n                false_values=[\"No\", \"false\"],\n            ),\n            trigger_omnisci_import=ASV_USE_STORAGE_FORMAT == \"omnisci\",\n        )\n\nclass BaseReadCsv:\n    def setup(self, test_filenames, shape, *args, **kwargs):\n        # ray init\n        if ASV_USE_IMPL == \"modin\":\n            pd.DataFrame([])\n        self.shape_id = get_shape_id(shape)\n\n    def setup_cache(self, test_filename=\"io_test_file\"):\n        test_filenames = prepare_io_data(\n            test_filename, self.data_type, get_benchmark_shapes(self.__class__.__name__)\n        )\n        return test_filenames",
        "min_run_count": 2,
        "name": "io.csv.TimeReadCsvTrueFalseValues.time_true_false_values",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "io.csv:33",
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "12e5e8c7de4a5d3ecdf96c0d074afc33f7091f65ca0c8e2777bb25e2600a19cc",
        "warmup_time": -1
    },
    "io.parquet.TimeReadParquet.time_read_parquet": {
        "code": "class TimeReadParquet:\n    def time_read_parquet(self, test_filenames, shape):\n        execute(\n            IMPL[ASV_USE_IMPL].read_parquet(\n                test_filenames[self.shape_id],\n            )\n        )\n\n    def setup(self, test_filenames, shape):\n        # ray init\n        if ASV_USE_IMPL == \"modin\":\n            pd.DataFrame([])\n        self.shape_id = get_shape_id(shape)\n\n    def setup_cache(self, test_filename=\"io_test_file\"):\n        test_filenames = prepare_io_data_parquet(\n            test_filename, self.data_type, get_benchmark_shapes(self.__class__.__name__)\n        )\n        return test_filenames",
        "min_run_count": 2,
        "name": "io.parquet.TimeReadParquet.time_read_parquet",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "io.parquet:36",
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "6c6ecffce9824ae3a5ad80efca974b844cf1cc6219e16b176c7ed4887a204ac0",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeAppend.time_append": {
        "code": "class TimeAppend:\n    def time_append(self, shapes):\n        execute(self.df1.append(self.df2))\n\n    def setup(self, shapes):\n        self.df1, self.df2 = (\n            generate_dataframe(\n                ASV_USE_IMPL,\n                \"int\",\n                *shape,\n                RAND_LOW,\n                RAND_HIGH,\n                cache_prefix=f\"{i}-th_frame_to_append\",\n            )\n            for i, shape in enumerate(shapes)\n        )\n        trigger_import(self.df1, self.df2)",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeAppend.time_append",
        "number": 0,
        "param_names": [
            "shapes"
        ],
        "params": [
            [
                "[[500000, 20], [1000000, 10]]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "63544950c1476966977c77eae9667c39d304ab77355ca0cb03743f5f2cef92f0",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeArithmetic.time_apply": {
        "code": "class TimeArithmetic:\n    def time_apply(self, shape):\n        execute(self.df.apply(lambda df: df.sum()))\n\n    def setup(self, shape):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df)",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeArithmetic.time_apply",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "102328f8998e0541eaf1f8eefe81980715093c9ac0b9698ea1ce873c5329d002",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeArithmetic.time_mean": {
        "code": "class TimeArithmetic:\n    def time_mean(self, shape):\n        execute(self.df.mean())\n\n    def setup(self, shape):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df)",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeArithmetic.time_mean",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "7b7253c6d69ebf76f78d95932242931a1b351c7efdcc6ba728001639803757c5",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeArithmetic.time_median": {
        "code": "class TimeArithmetic:\n    def time_median(self, shape):\n        execute(self.df.median())\n\n    def setup(self, shape):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df)",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeArithmetic.time_median",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "248c3be0eae97f5b41a25722371a4807821ba9844a9dc0229c11bbcb1e698034",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeArithmetic.time_nunique": {
        "code": "class TimeArithmetic:\n    def time_nunique(self, shape):\n        execute(self.df.nunique())\n\n    def setup(self, shape):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df)",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeArithmetic.time_nunique",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "3e671ac667a0f34da79eba557d22bf6a0fc7869df080ba3f261bfbfde292ae88",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeArithmetic.time_sum": {
        "code": "class TimeArithmetic:\n    def time_sum(self, shape):\n        execute(self.df.sum())\n\n    def setup(self, shape):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df)",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeArithmetic.time_sum",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "fafe40a04bebc4a1dc38cb3af7625d5ad6708abdba8d6efa61c6fb7435983444",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeAstype.time_astype": {
        "code": "class TimeAstype:\n    def time_astype(self, shape, dtype, astype_ncolumns):\n        execute(self.df.astype(self.astype_arg))\n\n    def setup(self, shape, dtype, astype_ncolumns):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df)\n        self.astype_arg = self.create_astype_arg(dtype, astype_ncolumns)",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeAstype.time_astype",
        "number": 0,
        "param_names": [
            "shape",
            "dtype",
            "astype_ncolumns"
        ],
        "params": [
            [
                "[1000000, 10]"
            ],
            [
                "'float64'"
            ],
            [
                "'one'",
                "'all'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "772dbb2b652ec375c854f681e7c304dde1f13aea1027f1046b2d0120a3a80c61",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeBinaryOpDataFrame.time_mul_dataframes": {
        "code": "class TimeBinaryOpDataFrame:\n    def time_mul_dataframes(self, shape, binary_op):\n        execute(self.op(self.df1))\n\n    def setup(self, shape, binary_op):\n        self.df1 = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df1)\n        self.op = getattr(self.df1, binary_op)",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeBinaryOpDataFrame.time_mul_dataframes",
        "number": 0,
        "param_names": [
            "shape",
            "binary_op"
        ],
        "params": [
            [
                "[1000000, 10]"
            ],
            [
                "'mul'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "cbf27cfd54582f373feb1cb9927f6467f2dc44af9cdcc225af882f55508fb2c9",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeBinaryOpDataFrame.time_mul_scalar": {
        "code": "class TimeBinaryOpDataFrame:\n    def time_mul_scalar(self, shape, binary_op):\n        execute(self.op(2))\n\n    def setup(self, shape, binary_op):\n        self.df1 = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df1)\n        self.op = getattr(self.df1, binary_op)",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeBinaryOpDataFrame.time_mul_scalar",
        "number": 0,
        "param_names": [
            "shape",
            "binary_op"
        ],
        "params": [
            [
                "[1000000, 10]"
            ],
            [
                "'mul'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "34e84906699176fea6c896064546451029287238c6072608e7064ade1f052b8e",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeBinaryOpSeries.time_mul_series": {
        "code": "class TimeBinaryOpSeries:\n    def time_mul_series(self, shape, binary_op):\n        execute(self.op(self.series))\n\n    def setup(self, shape, binary_op):\n        self.series = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH\n        )[\"col0\"]\n        trigger_import(self.series)\n        self.op = getattr(self.series, binary_op)",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeBinaryOpSeries.time_mul_series",
        "number": 0,
        "param_names": [
            "shape",
            "binary_op"
        ],
        "params": [
            [
                "[10000000, 1]"
            ],
            [
                "'mul'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "60a8e3e8f118610009cc3d75cf410b8ee379c830c2c63c8d483ebec34ad66d6b",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeDescribe.time_describe": {
        "code": "class TimeDescribe:\n    def time_describe(self, shape):\n        execute(self.df.describe())\n\n    def setup(self, shape):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df)",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeDescribe.time_describe",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "ae65a6c7ffb9c354886add011790b81bce91e041559bb34e3869a6b570db085e",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeDrop.time_drop": {
        "code": "class TimeDrop:\n    def time_drop(self, shape, drop_ncols):\n        execute(self.df.drop(self.labels, axis=1))\n\n    def setup(self, shape, drop_ncols):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df)\n        drop_count = (\n            int(len(self.df.axes[1]) * drop_ncols)\n            if isinstance(drop_ncols, float)\n            else drop_ncols\n        )\n        self.labels = self.df.axes[1][:drop_count]",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeDrop.time_drop",
        "number": 0,
        "param_names": [
            "shape",
            "drop_ncols"
        ],
        "params": [
            [
                "[1000000, 10]"
            ],
            [
                "1",
                "0.8"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "196ba2737a491f1ee6476f86b67ed527ee75d4026fee40c43dcfa84d09ca0e14",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeFillna.time_fillna": {
        "code": "class TimeFillna:\n    def time_fillna(self, value_type, shape, limit):\n        execute(self.df.fillna(**self.kw))\n\n    def setup(self, value_type, shape, limit):\n        self.df = gen_nan_data(ASV_USE_IMPL, *shape)\n        columns = self.df.columns\n        trigger_import(self.df)\n    \n        value = self.create_fillna_value(value_type, columns)\n        limit = int(limit * shape[0]) if limit else None\n        self.kw = {\"value\": value, \"limit\": limit}",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeFillna.time_fillna",
        "number": 0,
        "param_names": [
            "value_type",
            "shape",
            "limit"
        ],
        "params": [
            [
                "'scalar'",
                "'dict'"
            ],
            [
                "[1000000, 10]"
            ],
            [
                "None"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "ded6d632f7f53f3204d98bcc3b747aec90825900141de185eb34abdae64ffa10",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeGroupByDefaultAggregations.time_groupby_count": {
        "code": "class TimeGroupByDefaultAggregations:\n    def time_groupby_count(self, *args, **kwargs):\n        execute(self.df.groupby(by=self.groupby_columns).count())\n\nclass BaseTimeGroupBy:\n    def setup(self, shape, ngroups=5, groupby_ncols=1):\n        ngroups = translator_groupby_ngroups(ngroups, shape)\n        self.df, self.groupby_columns = generate_dataframe(\n            ASV_USE_IMPL,\n            \"int\",\n            *shape,\n            RAND_LOW,\n            RAND_HIGH,\n            groupby_ncols,\n            count_groups=ngroups,\n        )\n        # correct while we use 'col*' like name for non-groupby columns\n        # and 'groupby_col*' like name for groupby columns\n        self.non_groupby_columns = self.df.columns[:-groupby_ncols]\n        trigger_import(self.df)",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeGroupByDefaultAggregations.time_groupby_count",
        "number": 0,
        "param_names": [
            "shape",
            "ngroups"
        ],
        "params": [
            [
                "[1000000, 10]"
            ],
            [
                "100",
                "'huge_amount_groups'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "44639493437ba1e057d2d0793aebebf48eaf0141db935de196eb9ec9b386c7fd",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeGroupByDefaultAggregations.time_groupby_sum": {
        "code": "class TimeGroupByDefaultAggregations:\n    def time_groupby_sum(self, *args, **kwargs):\n        execute(self.df.groupby(by=self.groupby_columns).sum())\n\nclass BaseTimeGroupBy:\n    def setup(self, shape, ngroups=5, groupby_ncols=1):\n        ngroups = translator_groupby_ngroups(ngroups, shape)\n        self.df, self.groupby_columns = generate_dataframe(\n            ASV_USE_IMPL,\n            \"int\",\n            *shape,\n            RAND_LOW,\n            RAND_HIGH,\n            groupby_ncols,\n            count_groups=ngroups,\n        )\n        # correct while we use 'col*' like name for non-groupby columns\n        # and 'groupby_col*' like name for groupby columns\n        self.non_groupby_columns = self.df.columns[:-groupby_ncols]\n        trigger_import(self.df)",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeGroupByDefaultAggregations.time_groupby_sum",
        "number": 0,
        "param_names": [
            "shape",
            "ngroups"
        ],
        "params": [
            [
                "[1000000, 10]"
            ],
            [
                "100",
                "'huge_amount_groups'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "2bd5327d40b4ea4a49760c67b22c6fd1ab3e7b4c54d7e24c277a866d7c6b5efc",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeGroupByMultiColumn.time_groupby_agg_mean": {
        "code": "class TimeGroupByMultiColumn:\n    def time_groupby_agg_mean(self, *args, **kwargs):\n        execute(self.df.groupby(by=self.groupby_columns).agg(\"mean\"))\n\nclass BaseTimeGroupBy:\n    def setup(self, shape, ngroups=5, groupby_ncols=1):\n        ngroups = translator_groupby_ngroups(ngroups, shape)\n        self.df, self.groupby_columns = generate_dataframe(\n            ASV_USE_IMPL,\n            \"int\",\n            *shape,\n            RAND_LOW,\n            RAND_HIGH,\n            groupby_ncols,\n            count_groups=ngroups,\n        )\n        # correct while we use 'col*' like name for non-groupby columns\n        # and 'groupby_col*' like name for groupby columns\n        self.non_groupby_columns = self.df.columns[:-groupby_ncols]\n        trigger_import(self.df)",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeGroupByMultiColumn.time_groupby_agg_mean",
        "number": 0,
        "param_names": [
            "shape",
            "ngroups",
            "groupby_ncols"
        ],
        "params": [
            [
                "[1000000, 10]"
            ],
            [
                "100",
                "'huge_amount_groups'"
            ],
            [
                "6"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "4801523df968913d263845e5472875c3d154857756a4c42c64a1c19a26107ed7",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeGroupByMultiColumn.time_groupby_agg_mean_dict": {
        "code": "class TimeGroupByMultiColumn:\n    def time_groupby_agg_mean_dict(self, *args, **kwargs):\n        execute(\n            self.df.groupby(by=self.groupby_columns).agg(\n                {col: \"mean\" for col in self.non_groupby_columns}\n            )\n        )\n\nclass BaseTimeGroupBy:\n    def setup(self, shape, ngroups=5, groupby_ncols=1):\n        ngroups = translator_groupby_ngroups(ngroups, shape)\n        self.df, self.groupby_columns = generate_dataframe(\n            ASV_USE_IMPL,\n            \"int\",\n            *shape,\n            RAND_LOW,\n            RAND_HIGH,\n            groupby_ncols,\n            count_groups=ngroups,\n        )\n        # correct while we use 'col*' like name for non-groupby columns\n        # and 'groupby_col*' like name for groupby columns\n        self.non_groupby_columns = self.df.columns[:-groupby_ncols]\n        trigger_import(self.df)",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeGroupByMultiColumn.time_groupby_agg_mean_dict",
        "number": 0,
        "param_names": [
            "shape",
            "ngroups",
            "groupby_ncols"
        ],
        "params": [
            [
                "[1000000, 10]"
            ],
            [
                "100",
                "'huge_amount_groups'"
            ],
            [
                "6"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "2f1356cb83d0bebc29cae6e3d5f10ca627a7dfff7fb6e9714e19fa004d5c5628",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeGroupByMultiColumn.time_groupby_agg_nunique": {
        "code": "class TimeGroupByMultiColumn:\n    def time_groupby_agg_nunique(self, *args, **kwargs):\n        execute(self.df.groupby(by=self.groupby_columns).agg(\"nunique\"))\n\nclass BaseTimeGroupBy:\n    def setup(self, shape, ngroups=5, groupby_ncols=1):\n        ngroups = translator_groupby_ngroups(ngroups, shape)\n        self.df, self.groupby_columns = generate_dataframe(\n            ASV_USE_IMPL,\n            \"int\",\n            *shape,\n            RAND_LOW,\n            RAND_HIGH,\n            groupby_ncols,\n            count_groups=ngroups,\n        )\n        # correct while we use 'col*' like name for non-groupby columns\n        # and 'groupby_col*' like name for groupby columns\n        self.non_groupby_columns = self.df.columns[:-groupby_ncols]\n        trigger_import(self.df)",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeGroupByMultiColumn.time_groupby_agg_nunique",
        "number": 0,
        "param_names": [
            "shape",
            "ngroups",
            "groupby_ncols"
        ],
        "params": [
            [
                "[1000000, 10]"
            ],
            [
                "100",
                "'huge_amount_groups'"
            ],
            [
                "6"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "40372ef500919f7009235c869f063859b9f57fc0f6a1cddab5ac084193470c0b",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeGroupByMultiColumn.time_groupby_sum": {
        "code": "class TimeGroupByMultiColumn:\n    def time_groupby_sum(self, *args, **kwargs):\n        execute(self.df.groupby(by=self.groupby_columns).sum())\n\nclass BaseTimeGroupBy:\n    def setup(self, shape, ngroups=5, groupby_ncols=1):\n        ngroups = translator_groupby_ngroups(ngroups, shape)\n        self.df, self.groupby_columns = generate_dataframe(\n            ASV_USE_IMPL,\n            \"int\",\n            *shape,\n            RAND_LOW,\n            RAND_HIGH,\n            groupby_ncols,\n            count_groups=ngroups,\n        )\n        # correct while we use 'col*' like name for non-groupby columns\n        # and 'groupby_col*' like name for groupby columns\n        self.non_groupby_columns = self.df.columns[:-groupby_ncols]\n        trigger_import(self.df)",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeGroupByMultiColumn.time_groupby_sum",
        "number": 0,
        "param_names": [
            "shape",
            "ngroups",
            "groupby_ncols"
        ],
        "params": [
            [
                "[1000000, 10]"
            ],
            [
                "100",
                "'huge_amount_groups'"
            ],
            [
                "6"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "46987ffa124f620185bcc2c10d5f7e9dfa7a5885f938de1b6c4ffb4b1e916df3",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeHead.time_head": {
        "code": "class TimeHead:\n    def time_head(self, shape, head_count):\n        execute(self.df.head(self.head_count))\n\n    def setup(self, shape, head_count):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df)\n        self.head_count = (\n            int(head_count * len(self.df.index))\n            if isinstance(head_count, float)\n            else head_count\n        )",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeHead.time_head",
        "number": 0,
        "param_names": [
            "shape",
            "head_count"
        ],
        "params": [
            [
                "[1000000, 10]"
            ],
            [
                "5",
                "0.8"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "9b63f9023b24d56289392a553a624be4b0dbd5d006de0863066194880d3100f1",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeIndexing.time_iloc": {
        "code": "class TimeIndexing:\n    def time_iloc(self, shape, indexer_type):\n        # Pandas doesn't implement `df.iloc[series boolean_mask]` and raises an exception on it.\n        # Replacing this with the semantically equivalent construction:\n        if indexer_type != \"bool_series\":\n            execute(self.df.iloc[self.indexer])\n        else:\n            execute(self.df[self.indexer])\n\n    def setup(self, shape, indexer_type):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df)\n    \n        self.indexer = self.indexer_getters[indexer_type](self.df)\n        if isinstance(self.indexer, (pd.Series, pd.DataFrame)):\n            # HACK: Triggering `dtypes` meta-data computation in advance,\n            # so it won't affect the `loc/iloc` time:\n            self.indexer.dtypes",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeIndexing.time_iloc",
        "number": 0,
        "param_names": [
            "shape",
            "indexer_type"
        ],
        "params": [
            [
                "[1000000, 10]"
            ],
            [
                "'bool_array'",
                "'bool_series'",
                "'scalar'",
                "'slice'",
                "'continuous_slice'",
                "'numpy_array_take_all_values'",
                "'python_list_take_10_values'",
                "'function'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "0bd0ae3526940e0a2f9f79b17c7583ba0f2d6b33aad55393f2bd7a5f63b4de3f",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeIndexing.time_loc": {
        "code": "class TimeIndexing:\n    def time_loc(self, shape, indexer_type):\n        execute(self.df.loc[self.indexer])\n\n    def setup(self, shape, indexer_type):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df)\n    \n        self.indexer = self.indexer_getters[indexer_type](self.df)\n        if isinstance(self.indexer, (pd.Series, pd.DataFrame)):\n            # HACK: Triggering `dtypes` meta-data computation in advance,\n            # so it won't affect the `loc/iloc` time:\n            self.indexer.dtypes",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeIndexing.time_loc",
        "number": 0,
        "param_names": [
            "shape",
            "indexer_type"
        ],
        "params": [
            [
                "[1000000, 10]"
            ],
            [
                "'bool_array'",
                "'bool_series'",
                "'scalar'",
                "'slice'",
                "'continuous_slice'",
                "'numpy_array_take_all_values'",
                "'python_list_take_10_values'",
                "'function'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "496fb1e124a319acd18ec43552530104fceb6b668df356a4694bc7f2fb0aa408",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeIndexingColumns.time___getitem__": {
        "code": "class TimeIndexingColumns:\n    def time___getitem__(self, shape):\n        execute(self.df[self.labels_indexer])\n\n    def setup(self, shape):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df)\n        self.numeric_indexer = [0, 1]\n        self.labels_indexer = self.df.columns[self.numeric_indexer].tolist()",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeIndexingColumns.time___getitem__",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "38a0fad1487d34f22254d7e3abf8f0c9debc51c0a14c4d2cfad57f2b8a38723f",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeIndexingColumns.time_iloc": {
        "code": "class TimeIndexingColumns:\n    def time_iloc(self, shape):\n        execute(self.df.iloc[:, self.numeric_indexer])\n\n    def setup(self, shape):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df)\n        self.numeric_indexer = [0, 1]\n        self.labels_indexer = self.df.columns[self.numeric_indexer].tolist()",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeIndexingColumns.time_iloc",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "d8b8c528f5b7eb459cf4f5cf42bb42af77b301eb1acec2dc93511ecd7a0584c5",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeIndexingColumns.time_loc": {
        "code": "class TimeIndexingColumns:\n    def time_loc(self, shape):\n        execute(self.df.loc[:, self.labels_indexer])\n\n    def setup(self, shape):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df)\n        self.numeric_indexer = [0, 1]\n        self.labels_indexer = self.df.columns[self.numeric_indexer].tolist()",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeIndexingColumns.time_loc",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "1bcabed67270f400c9f0ff69bed971dbb47456a21fc3d705e3986bb2cef41996",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeJoin.time_join": {
        "code": "class TimeJoin:\n    def time_join(self, shape, how, is_equal_keys):\n        # join dataframes on index to get the predictable shape\n        execute(self.df1.join(self.df2, how=how, lsuffix=\"left_\"))\n\n    def setup(self, shape, how, is_equal_keys):\n        self.df1, self.df2 = (\n            generate_dataframe(\n                ASV_USE_IMPL,\n                \"int\",\n                *frame_shape,\n                RAND_LOW,\n                RAND_HIGH,\n                cache_prefix=f\"{i}-th_frame_to_join\",\n            )\n            for i, frame_shape in enumerate((shape, shape))\n        )\n    \n        if is_equal_keys:\n            # When the frames have default indices to join on: RangeIndex(frame_length),\n            # OmniSci backend performs join on the internal meta-column called 'rowid'.\n            # There is a bug in the engine that makes such joins fail. To avoid joining\n            # on the meta-column we explicitly specify a non-default index to join on.\n            # https://github.com/modin-project/modin/issues/3740\n            # Generating a new object for every index to avoid shared index objects:\n            self.df1.index = pandas.RangeIndex(1, len(self.df1) + 1)\n            self.df2.index = pandas.RangeIndex(1, len(self.df2) + 1)\n        else:\n            # Intersection rate indicates how many common join-keys `self.df1`\n            # and `self.df2` have in terms of percentage.\n            indices_intersection_rate = 0.5\n    \n            frame_length = len(self.df1)\n            intersect_size = int(frame_length * indices_intersection_rate)\n    \n            intersect_part = random_state.choice(\n                self.df1.index, size=intersect_size, replace=False\n            )\n            non_intersect_part = np.arange(\n                start=frame_length, stop=frame_length + (frame_length - intersect_size)\n            )\n            new_index = np.concatenate([intersect_part, non_intersect_part])\n    \n            random_state.shuffle(new_index)\n            self.df1.index = new_index\n    \n        trigger_import(self.df1, self.df2)",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeJoin.time_join",
        "number": 0,
        "param_names": [
            "shape",
            "how",
            "is_equal_keys"
        ],
        "params": [
            [
                "[1000000, 10]"
            ],
            [
                "'left'",
                "'inner'"
            ],
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "64224910083152b83f3cf1fabfd2d2b06ebab5e6ae167e7aac3775f33485e035",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeMerge.time_merge": {
        "code": "class TimeMerge:\n    def time_merge(self, shapes, how):\n        # merging dataframes by index is not supported, therefore we merge by column\n        # with arbitrary values, which leads to an unpredictable form of the operation result;\n        # it's need to get the predictable shape to get consistent performance results\n        execute(\n            self.dfs[0].merge(\n                self.dfs[1], on=\"col1\", how=how, suffixes=(\"left_\", \"right_\")\n            )\n        )\n\n    def setup(self, shapes, how):\n        gen_unique_key = how == \"inner\"\n        self.dfs = []\n        for i, shape in enumerate(shapes):\n            self.dfs.append(\n                generate_dataframe(\n                    ASV_USE_IMPL,\n                    \"int\",\n                    *shape,\n                    RAND_LOW,\n                    RAND_HIGH,\n                    gen_unique_key=gen_unique_key,\n                    cache_prefix=f\"{i}-th_frame_to_merge\",\n                )\n            )\n        trigger_import(*self.dfs)",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeMerge.time_merge",
        "number": 0,
        "param_names": [
            "shapes",
            "how"
        ],
        "params": [
            [
                "[[500000, 20], [1000000, 10]]"
            ],
            [
                "'left'",
                "'inner'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "862e0903e0abe2580c3fd6b2fe52934cc7a0c0d145e058a3df15ed60f238b609",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeProperties.time_columns": {
        "code": "class TimeProperties:\n    def time_columns(self, shape):\n        return self.df.columns\n\n    def setup(self, shape):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df)",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeProperties.time_columns",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "371c54e3ed71de7d9a90601685f95a9a17a2b8f30bddf01d9c8f747eb62d8044",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeProperties.time_index": {
        "code": "class TimeProperties:\n    def time_index(self, shape):\n        return self.df.index\n\n    def setup(self, shape):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df)",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeProperties.time_index",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "699a1c92d95a113816a7944b98f71ebf885071b39ccf7931a201101a9c9cf6a5",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeProperties.time_shape": {
        "code": "class TimeProperties:\n    def time_shape(self, shape):\n        return self.df.shape\n\n    def setup(self, shape):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df)",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeProperties.time_shape",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "18e9903979a6577b4db24064a47d09f727ae18f95cc0139f3fa7c0d193077731",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeResetIndex.time_reset_index": {
        "code": "class TimeResetIndex:\n    def time_reset_index(self, shape, drop, level):\n        execute(self.df.reset_index(drop=drop, level=level))\n\n    def setup(self, shape, drop, level):\n        pd = IMPL[ASV_USE_IMPL]\n        if not drop or level == \"level_1\":\n            raise NotImplementedError\n    \n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        if level:\n            index = pd.MultiIndex.from_product(\n                [self.df.index[: shape[0] // 2], [\"bar\", \"foo\"]],\n                names=[\"level_1\", \"level_2\"],\n            )\n            self.df.index = index\n        trigger_import(self.df)",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeResetIndex.time_reset_index",
        "number": 0,
        "param_names": [
            "shape",
            "drop",
            "level"
        ],
        "params": [
            [
                "[1000000, 10]"
            ],
            [
                "False",
                "True"
            ],
            [
                "None",
                "'level_1'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "53deff70a93b12387fa508c3c928f4056d8d8919cf4fd97a8597f4a6b1614df0",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeSortValues.time_sort_values": {
        "code": "class TimeSortValues:\n    def time_sort_values(self, shape, columns_number, ascending_list):\n        execute(self.df.sort_values(self.columns, ascending=self.ascending))\n\n    def setup(self, shape, columns_number, ascending_list):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df)\n        self.columns = random_columns(self.df.columns, columns_number)\n        self.ascending = (\n            random_booleans(columns_number)\n            if ascending_list\n            else bool(random_booleans(1)[0])\n        )",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeSortValues.time_sort_values",
        "number": 0,
        "param_names": [
            "shape",
            "columns_number",
            "ascending_list"
        ],
        "params": [
            [
                "[1000000, 10]"
            ],
            [
                "1",
                "5"
            ],
            [
                "False",
                "True"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "80291c87f0eb5241a860340ccd219981eb683da4e5702954d223fbbd475354d9",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeValueCountsDataFrame.time_value_counts": {
        "code": "class TimeValueCountsDataFrame:\n    def time_value_counts(self, *args, **kwargs):\n        execute(self.df.value_counts(subset=self.subset))\n\nclass BaseTimeValueCounts:\n    def setup(self, shape, ngroups=5, subset=1):\n        ngroups = translator_groupby_ngroups(ngroups, shape)\n        self.df, self.subset = generate_dataframe(\n            ASV_USE_IMPL,\n            \"int\",\n            *shape,\n            RAND_LOW,\n            RAND_HIGH,\n            groupby_ncols=subset,\n            count_groups=ngroups,\n        )\n        trigger_import(self.df)",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeValueCountsDataFrame.time_value_counts",
        "number": 0,
        "param_names": [
            "shape",
            "ngroups",
            "subset"
        ],
        "params": [
            [
                "[1000000, 10]"
            ],
            [
                "100",
                "'huge_amount_groups'"
            ],
            [
                "2",
                "10"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "130f78c46e8dd21a9803c5e15312e7bbeea976b28fa21590ee73e0fe18de8624",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeValueCountsSeries.time_value_counts": {
        "code": "class TimeValueCountsSeries:\n    def time_value_counts(self, shape, ngroups):\n        execute(self.series.value_counts())\n\n    def setup(self, shape, ngroups):\n        super().setup(shape, ngroups, subset=1)\n        self.series = self.df[self.subset[0]]\n        trigger_import(self.series)",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeValueCountsSeries.time_value_counts",
        "number": 0,
        "param_names": [
            "shape",
            "ngroups"
        ],
        "params": [
            [
                "[10000000, 1]"
            ],
            [
                "100",
                "'huge_amount_groups'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "50d039f809a57224798f163963708292724bc1f840d29c56433f0628d90b683b",
        "warmup_time": -1
    },
    "omnisci.io.TimeReadCsvNames.time_read_csv_names": {
        "code": "class TimeReadCsvNames:\n    def time_read_csv_names(self, cache, shape):\n        df = IMPL[ASV_USE_IMPL].read_csv(\n            self.filename,\n            names=self.names,\n            header=0,\n            dtype=self.dtype,\n        )\n        trigger_import(df)\n\n    def setup(self, cache, shape):\n        # ray init\n        if ASV_USE_IMPL == \"modin\":\n            pd.DataFrame([])\n        file_id = get_shape_id(shape)\n        self.filename, self.names, self.dtype = cache[file_id]\n\n    def setup_cache(self, test_filename=\"io_test_file_csv_names\"):\n        # filenames with a metadata of saved dataframes\n        cache = {}\n        for shape in self.shapes:\n            df = generate_dataframe(\"pandas\", \"int\", *shape, RAND_LOW, RAND_HIGH)\n            file_id = get_shape_id(shape)\n            cache[file_id] = (\n                f\"{test_filename}_{file_id}.csv\",\n                df.columns.to_list(),\n                df.dtypes.to_dict(),\n            )\n            df.to_csv(cache[file_id][0], index=False)\n        return cache",
        "min_run_count": 2,
        "name": "omnisci.io.TimeReadCsvNames.time_read_csv_names",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "omnisci.io:37",
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "ea3f66c8a5cbde5e04d94bc693e5b65e70285e7ebb5df1d6445a7f2aefb63f80",
        "warmup_time": -1
    },
    "omnisci.io.TimeReadCsvTrueFalseValues.time_true_false_values": {
        "code": "class TimeReadCsvTrueFalseValues:\n    def time_true_false_values(self, test_filenames, shape):\n        execute(\n            IMPL[ASV_USE_IMPL].read_csv(\n                test_filenames[self.shape_id],\n                true_values=[\"Yes\", \"true\"],\n                false_values=[\"No\", \"false\"],\n            ),\n            trigger_omnisci_import=ASV_USE_STORAGE_FORMAT == \"omnisci\",\n        )\n\nclass BaseReadCsv:\n    def setup(self, test_filenames, shape, *args, **kwargs):\n        # ray init\n        if ASV_USE_IMPL == \"modin\":\n            pd.DataFrame([])\n        self.shape_id = get_shape_id(shape)\n\n    def setup_cache(self, test_filename=\"io_test_file\"):\n        test_filenames = prepare_io_data(\n            test_filename, self.data_type, get_benchmark_shapes(self.__class__.__name__)\n        )\n        return test_filenames",
        "min_run_count": 2,
        "name": "omnisci.io.TimeReadCsvTrueFalseValues.time_true_false_values",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "io.csv:33",
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "12e5e8c7de4a5d3ecdf96c0d074afc33f7091f65ca0c8e2777bb25e2600a19cc",
        "warmup_time": -1
    },
    "scalability.scalability_benchmarks.TimeFromPandas.time_from_pandas": {
        "code": "class TimeFromPandas:\n    def time_from_pandas(self, shape, cpus):\n        execute(from_pandas(self.data))\n\n    def setup(self, shape, cpus):\n        self.data = pandas.DataFrame(gen_data(\"int\", *shape, RAND_LOW, RAND_HIGH))\n        from modin.config import NPartitions\n    \n        NPartitions.get = lambda: cpus\n        # trigger ray init\n        pd.DataFrame([])",
        "min_run_count": 2,
        "name": "scalability.scalability_benchmarks.TimeFromPandas.time_from_pandas",
        "number": 0,
        "param_names": [
            "shape",
            "cpus"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "4",
                "16",
                "32"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "8af06db97bd87859b17230125772585ddc3fe0c5e23426aca77776870540eab1",
        "warmup_time": -1
    },
    "scalability.scalability_benchmarks.TimeToPandas.time_to_pandas": {
        "code": "class TimeToPandas:\n    def time_to_pandas(self, shape, cpus):\n        # to_pandas is already synchronous\n        to_pandas(self.data)\n\n    def setup(self, shape, cpus):\n        from modin.config import NPartitions\n    \n        NPartitions.get = lambda: cpus\n        self.data = generate_dataframe(\"modin\", \"int\", *shape, RAND_LOW, RAND_HIGH)",
        "min_run_count": 2,
        "name": "scalability.scalability_benchmarks.TimeToPandas.time_to_pandas",
        "number": 0,
        "param_names": [
            "shape",
            "cpus"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "4",
                "16",
                "32"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "6e9561fb9fd503ccfe496c5c520304c983774eaabfbe0ec8958c49b39bdec972",
        "warmup_time": -1
    },
    "version": 2
}