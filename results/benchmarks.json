{
    "benchmarks.TimeAppend.time_append": {
        "code": "class TimeAppend:\n    def time_append(self, shapes, sort):\n        execute(self.df1.append(self.df2, sort=sort))\n\n    def setup(self, shapes, sort):\n        self.df1 = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shapes[0], RAND_LOW, RAND_HIGH\n        )\n        self.df2 = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shapes[1], RAND_LOW, RAND_HIGH\n        )\n        if sort:\n            self.df1.columns = self.df1.columns[::-1]",
        "min_run_count": 2,
        "name": "benchmarks.TimeAppend.time_append",
        "number": 0,
        "param_names": [
            "shapes",
            "sort"
        ],
        "params": [
            [
                "[[5000, 5000], [5000, 5000]]",
                "[[500000, 20], [1000000, 10]]"
            ],
            [
                "False",
                "True"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "c2d89eb99a9d7965ff21009a90377a267577d695e1baeeedba0a97d62f2f8030",
        "warmup_time": -1
    },
    "benchmarks.TimeArithmetic.time_apply": {
        "code": "class TimeArithmetic:\n    def time_apply(self, shape, axis):\n        execute(self.df.apply(lambda df: df.sum(), axis=axis))\n\n    def setup(self, shape, axis):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)",
        "min_run_count": 2,
        "name": "benchmarks.TimeArithmetic.time_apply",
        "number": 0,
        "param_names": [
            "shape",
            "axis"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "219317b7fcbaf3f87050bca6999e1b68c258853598a859ac59da82b025bf251a",
        "warmup_time": -1
    },
    "benchmarks.TimeArithmetic.time_mean": {
        "code": "class TimeArithmetic:\n    def time_mean(self, shape, axis):\n        execute(self.df.mean(axis=axis))\n\n    def setup(self, shape, axis):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)",
        "min_run_count": 2,
        "name": "benchmarks.TimeArithmetic.time_mean",
        "number": 0,
        "param_names": [
            "shape",
            "axis"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b541392002bd635e8fdf6d069d1fb9147bf2e0d1cbccf130bf1b596c17454708",
        "warmup_time": -1
    },
    "benchmarks.TimeArithmetic.time_median": {
        "code": "class TimeArithmetic:\n    def time_median(self, shape, axis):\n        execute(self.df.median(axis=axis))\n\n    def setup(self, shape, axis):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)",
        "min_run_count": 2,
        "name": "benchmarks.TimeArithmetic.time_median",
        "number": 0,
        "param_names": [
            "shape",
            "axis"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "6f99b2ce6d39b39818206977c6513e7df8166e01bbff37724a82601a9c4875ad",
        "warmup_time": -1
    },
    "benchmarks.TimeArithmetic.time_nunique": {
        "code": "class TimeArithmetic:\n    def time_nunique(self, shape, axis):\n        execute(self.df.nunique(axis=axis))\n\n    def setup(self, shape, axis):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)",
        "min_run_count": 2,
        "name": "benchmarks.TimeArithmetic.time_nunique",
        "number": 0,
        "param_names": [
            "shape",
            "axis"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "2e6aa9b726c293d7e2d3121d8ad006add467a8da0531eac8774b3f0384ca64bc",
        "warmup_time": -1
    },
    "benchmarks.TimeArithmetic.time_sum": {
        "code": "class TimeArithmetic:\n    def time_sum(self, shape, axis):\n        execute(self.df.sum(axis=axis))\n\n    def setup(self, shape, axis):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)",
        "min_run_count": 2,
        "name": "benchmarks.TimeArithmetic.time_sum",
        "number": 0,
        "param_names": [
            "shape",
            "axis"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "3ade96bfe969295a9d3c99d61bc88dedda36a799925710d5620e5fb30438d074",
        "warmup_time": -1
    },
    "benchmarks.TimeAstype.time_astype": {
        "code": "class TimeAstype:\n    def time_astype(self, shape, dtype, astype_ncolumns):\n        execute(self.df.astype(self.astype_arg))\n\n    def setup(self, shape, dtype, astype_ncolumns):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        if astype_ncolumns == \"all\":\n            self.astype_arg = dtype\n        elif astype_ncolumns == \"one\":\n            self.astype_arg = {\"col1\": dtype}\n        else:\n            raise ValueError(\"astype_ncolumns: {astype_ncolumns} isn't supported\")",
        "min_run_count": 2,
        "name": "benchmarks.TimeAstype.time_astype",
        "number": 0,
        "param_names": [
            "shape",
            "dtype",
            "astype_ncolumns"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "'float64'",
                "'category'"
            ],
            [
                "'one'",
                "'all'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "e0815604b1644fa44789102d06d841ad6e2d03792cc5d694a40c0838ae3275f3",
        "warmup_time": -1
    },
    "benchmarks.TimeBinaryOp.time_binary_op": {
        "code": "class TimeBinaryOp:\n    def time_binary_op(self, shapes, binary_op, axis):\n        execute(self.op(self.df2, axis=axis))\n\n    def setup(self, shapes, binary_op, axis):\n        self.df1 = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shapes[0], RAND_LOW, RAND_HIGH\n        )\n        self.df2 = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shapes[1], RAND_LOW, RAND_HIGH\n        )\n        self.op = getattr(self.df1, binary_op)",
        "min_run_count": 2,
        "name": "benchmarks.TimeBinaryOp.time_binary_op",
        "number": 0,
        "param_names": [
            "shapes",
            "binary_op",
            "axis"
        ],
        "params": [
            [
                "[[5000, 5000], [5000, 5000]]",
                "[[500000, 20], [1000000, 10]]"
            ],
            [
                "'mul'"
            ],
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "9ff776f725432c65f49e1c3f59022f6f3d976278510bf9915fda51ba51ad13ae",
        "warmup_time": -1
    },
    "benchmarks.TimeConcat.time_concat": {
        "code": "class TimeConcat:\n    def time_concat(self, shapes, how, axis):\n        execute(IMPL[ASV_USE_IMPL].concat([self.df1, self.df2], axis=axis, join=how))\n\n    def setup(self, shapes, how, axis):\n        self.df1 = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shapes[0], RAND_LOW, RAND_HIGH\n        )\n        self.df2 = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shapes[1], RAND_LOW, RAND_HIGH\n        )",
        "min_run_count": 2,
        "name": "benchmarks.TimeConcat.time_concat",
        "number": 0,
        "param_names": [
            "shapes",
            "how",
            "axis"
        ],
        "params": [
            [
                "[[5000, 5000], [5000, 5000]]",
                "[[500000, 20], [1000000, 10]]"
            ],
            [
                "'inner'"
            ],
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "718c07f0450388e6f586cf10e7466f364cc94e4a6909380b7f50d8213c45205c",
        "warmup_time": -1
    },
    "benchmarks.TimeDescribe.time_describe": {
        "code": "class TimeDescribe:\n    def time_describe(self, shape):\n        execute(self.df.describe())\n\n    def setup(self, shape):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)",
        "min_run_count": 2,
        "name": "benchmarks.TimeDescribe.time_describe",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b06d1af039ee49fcea92c1e11a041c293d33b86c73874976592036d57e966eb8",
        "warmup_time": -1
    },
    "benchmarks.TimeDrop.time_drop": {
        "code": "class TimeDrop:\n    def time_drop(self, shape, axis, drop_ncols):\n        execute(self.df.drop(self.labels, axis))\n\n    def setup(self, shape, axis, drop_ncols):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        drop_count = (\n            int(len(self.df.axes[axis]) * drop_ncols)\n            if isinstance(drop_ncols, float)\n            else drop_ncols\n        )\n        self.labels = self.df.axes[axis][:drop_count]",
        "min_run_count": 2,
        "name": "benchmarks.TimeDrop.time_drop",
        "number": 0,
        "param_names": [
            "shape",
            "axis",
            "drop_ncols"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "0",
                "1"
            ],
            [
                "1",
                "0.8"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "cbeb16adcb3fadd00159e6c9922ccbfaac0eb086cd953d0eebb36b89c3e6e266",
        "warmup_time": -1
    },
    "benchmarks.TimeFillnaDataFrame.time_fillna": {
        "code": "class TimeFillnaDataFrame:\n    def time_fillna(self, value_type, shape, limit):\n        execute(self.df.fillna(**self.kw))\n\n    def setup(self, value_type, shape, limit):\n        pd = IMPL[ASV_USE_IMPL]\n        self.df = gen_nan_data(ASV_USE_IMPL, *shape)\n        columns = self.df.columns\n    \n        if value_type == \"scalar\":\n            self.value = 18.19\n        elif value_type == \"dict\":\n            self.value = {k: i * 1.23 for i, k in enumerate(columns)}\n        elif value_type == \"Series\":\n            self.value = pd.Series(\n                [i * 1.23 for i in range(len(columns))], index=columns\n            )\n        elif value_type == \"DataFrame\":\n            self.value = pd.DataFrame(\n                {\n                    k: [i + j * 1.23 for j in range(shape[0])]\n                    for i, k in enumerate(columns)\n                },\n                index=pd.RangeIndex(shape[0]),\n                columns=columns,\n            )\n        else:\n            assert False\n        limit = int(limit * shape[0]) if limit else None\n        self.kw = {\"value\": self.value, \"limit\": limit}",
        "min_run_count": 2,
        "name": "benchmarks.TimeFillnaDataFrame.time_fillna",
        "number": 0,
        "param_names": [
            "value_type",
            "shape",
            "limit"
        ],
        "params": [
            [
                "'scalar'",
                "'dict'",
                "'DataFrame'",
                "'Series'"
            ],
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "None",
                "0.8"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "2a53f1e1a0506c8eb4c8131875b0264407549701c13dd2dd8018496eb81ed5ec",
        "warmup_time": -1
    },
    "benchmarks.TimeFillnaDataFrame.time_fillna_inplace": {
        "code": "class TimeFillnaDataFrame:\n    def time_fillna_inplace(self, value_type, shape, limit):\n        self.df.fillna(inplace=True, **self.kw)\n        execute(self.df)\n\n    def setup(self, value_type, shape, limit):\n        pd = IMPL[ASV_USE_IMPL]\n        self.df = gen_nan_data(ASV_USE_IMPL, *shape)\n        columns = self.df.columns\n    \n        if value_type == \"scalar\":\n            self.value = 18.19\n        elif value_type == \"dict\":\n            self.value = {k: i * 1.23 for i, k in enumerate(columns)}\n        elif value_type == \"Series\":\n            self.value = pd.Series(\n                [i * 1.23 for i in range(len(columns))], index=columns\n            )\n        elif value_type == \"DataFrame\":\n            self.value = pd.DataFrame(\n                {\n                    k: [i + j * 1.23 for j in range(shape[0])]\n                    for i, k in enumerate(columns)\n                },\n                index=pd.RangeIndex(shape[0]),\n                columns=columns,\n            )\n        else:\n            assert False\n        limit = int(limit * shape[0]) if limit else None\n        self.kw = {\"value\": self.value, \"limit\": limit}",
        "min_run_count": 2,
        "name": "benchmarks.TimeFillnaDataFrame.time_fillna_inplace",
        "number": 0,
        "param_names": [
            "value_type",
            "shape",
            "limit"
        ],
        "params": [
            [
                "'scalar'",
                "'dict'",
                "'DataFrame'",
                "'Series'"
            ],
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "None",
                "0.8"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "56651978c860fb892d9eb8fcf32ccd99fcbadfe19d53dcdb4b70a9d2e38a3c6b",
        "warmup_time": -1
    },
    "benchmarks.TimeFillnaSeries.time_fillna": {
        "code": "class TimeFillnaSeries:\n    def time_fillna(self, value_type, shape, limit):\n        execute(self.series.fillna(**self.kw))\n\n    def setup(self, value_type, shape, limit):\n        pd = IMPL[ASV_USE_IMPL]\n        self.series = gen_nan_data(ASV_USE_IMPL, *shape)\n    \n        if value_type == \"scalar\":\n            self.value = 18.19\n        elif value_type == \"dict\":\n            self.value = {k: k * 1.23 for k in range(shape[0])}\n        elif value_type == \"Series\":\n            self.value = pd.Series(\n                [k * 1.23 for k in range(shape[0])], index=pd.RangeIndex(shape[0])\n            )\n        else:\n            assert False\n        limit = int(limit * shape[0]) if limit else None\n        self.kw = {\"value\": self.value, \"limit\": limit}",
        "min_run_count": 2,
        "name": "benchmarks.TimeFillnaSeries.time_fillna",
        "number": 0,
        "param_names": [
            "value_type",
            "shape",
            "limit"
        ],
        "params": [
            [
                "'scalar'",
                "'dict'",
                "'Series'"
            ],
            [
                "[100000, 1]"
            ],
            [
                "None",
                "0.8"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "115f3f751e134490d58d0d1c2719751654d2e9884fd5454b14ff96532d704a97",
        "warmup_time": -1
    },
    "benchmarks.TimeFillnaSeries.time_fillna_inplace": {
        "code": "class TimeFillnaSeries:\n    def time_fillna_inplace(self, value_type, shape, limit):\n        self.series.fillna(inplace=True, **self.kw)\n        execute(self.series)\n\n    def setup(self, value_type, shape, limit):\n        pd = IMPL[ASV_USE_IMPL]\n        self.series = gen_nan_data(ASV_USE_IMPL, *shape)\n    \n        if value_type == \"scalar\":\n            self.value = 18.19\n        elif value_type == \"dict\":\n            self.value = {k: k * 1.23 for k in range(shape[0])}\n        elif value_type == \"Series\":\n            self.value = pd.Series(\n                [k * 1.23 for k in range(shape[0])], index=pd.RangeIndex(shape[0])\n            )\n        else:\n            assert False\n        limit = int(limit * shape[0]) if limit else None\n        self.kw = {\"value\": self.value, \"limit\": limit}",
        "min_run_count": 2,
        "name": "benchmarks.TimeFillnaSeries.time_fillna_inplace",
        "number": 0,
        "param_names": [
            "value_type",
            "shape",
            "limit"
        ],
        "params": [
            [
                "'scalar'",
                "'dict'",
                "'Series'"
            ],
            [
                "[100000, 1]"
            ],
            [
                "None",
                "0.8"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "72c059f8c6ffc17e37dde767459a738f551b15746a1d284572ee91b3d913dc9c",
        "warmup_time": -1
    },
    "benchmarks.TimeGroupByDefaultAggregations.time_groupby_count": {
        "code": "class TimeGroupByDefaultAggregations:\n    def time_groupby_count(self, *args, **kwargs):\n        execute(self.df.groupby(by=self.groupby_columns).count())\n\nclass BaseTimeGroupBy:\n    def setup(self, shape, ngroups=5, groupby_ncols=1):\n        ngroups = translator_groupby_ngroups(ngroups, shape)\n        self.df, self.groupby_columns = generate_dataframe(\n            ASV_USE_IMPL,\n            \"int\",\n            *shape,\n            RAND_LOW,\n            RAND_HIGH,\n            groupby_ncols,\n            count_groups=ngroups,\n        )",
        "min_run_count": 2,
        "name": "benchmarks.TimeGroupByDefaultAggregations.time_groupby_count",
        "number": 0,
        "param_names": [
            "shape",
            "ngroups"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "100",
                "'huge_amount_groups'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "46a1f84a3f0c0b546f071c9be94866f953ddb6e2384a6ccbc518ad0b9154380c",
        "warmup_time": -1
    },
    "benchmarks.TimeGroupByDefaultAggregations.time_groupby_mean": {
        "code": "class TimeGroupByDefaultAggregations:\n    def time_groupby_mean(self, *args, **kwargs):\n        execute(self.df.groupby(by=self.groupby_columns).mean())\n\nclass BaseTimeGroupBy:\n    def setup(self, shape, ngroups=5, groupby_ncols=1):\n        ngroups = translator_groupby_ngroups(ngroups, shape)\n        self.df, self.groupby_columns = generate_dataframe(\n            ASV_USE_IMPL,\n            \"int\",\n            *shape,\n            RAND_LOW,\n            RAND_HIGH,\n            groupby_ncols,\n            count_groups=ngroups,\n        )",
        "min_run_count": 2,
        "name": "benchmarks.TimeGroupByDefaultAggregations.time_groupby_mean",
        "number": 0,
        "param_names": [
            "shape",
            "ngroups"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "100",
                "'huge_amount_groups'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "23ad92017cdfe129d3ab99f79e62fe2722466cfac0a55179a1ecc00b910c4857",
        "warmup_time": -1
    },
    "benchmarks.TimeGroupByDefaultAggregations.time_groupby_size": {
        "code": "class TimeGroupByDefaultAggregations:\n    def time_groupby_size(self, *args, **kwargs):\n        execute(self.df.groupby(by=self.groupby_columns).size())\n\nclass BaseTimeGroupBy:\n    def setup(self, shape, ngroups=5, groupby_ncols=1):\n        ngroups = translator_groupby_ngroups(ngroups, shape)\n        self.df, self.groupby_columns = generate_dataframe(\n            ASV_USE_IMPL,\n            \"int\",\n            *shape,\n            RAND_LOW,\n            RAND_HIGH,\n            groupby_ncols,\n            count_groups=ngroups,\n        )",
        "min_run_count": 2,
        "name": "benchmarks.TimeGroupByDefaultAggregations.time_groupby_size",
        "number": 0,
        "param_names": [
            "shape",
            "ngroups"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "100",
                "'huge_amount_groups'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f597a5f0dac5a4fabed5dd5548e9d73d8d39698a8437bf3466131cb18ed4dde5",
        "warmup_time": -1
    },
    "benchmarks.TimeGroupByDefaultAggregations.time_groupby_sum": {
        "code": "class TimeGroupByDefaultAggregations:\n    def time_groupby_sum(self, *args, **kwargs):\n        execute(self.df.groupby(by=self.groupby_columns).sum())\n\nclass BaseTimeGroupBy:\n    def setup(self, shape, ngroups=5, groupby_ncols=1):\n        ngroups = translator_groupby_ngroups(ngroups, shape)\n        self.df, self.groupby_columns = generate_dataframe(\n            ASV_USE_IMPL,\n            \"int\",\n            *shape,\n            RAND_LOW,\n            RAND_HIGH,\n            groupby_ncols,\n            count_groups=ngroups,\n        )",
        "min_run_count": 2,
        "name": "benchmarks.TimeGroupByDefaultAggregations.time_groupby_sum",
        "number": 0,
        "param_names": [
            "shape",
            "ngroups"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "100",
                "'huge_amount_groups'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "ec74cb917a463fae4337b5d3444788e696f710113878e9df35417a0f56f92d09",
        "warmup_time": -1
    },
    "benchmarks.TimeGroupByDictionaryAggregation.time_groupby_dict_agg": {
        "code": "class TimeGroupByDictionaryAggregation:\n    def time_groupby_dict_agg(self, *args, **kwargs):\n        execute(self.df.groupby(by=self.groupby_columns).agg(self.agg_dict))\n\n    def setup(self, shape, ngroups, operation_type):\n        super().setup(shape, ngroups)\n        self.cols_to_agg = self.df.columns[1:4]\n        operations = self.operations[operation_type]\n        self.agg_dict = {\n            c: operations[i % len(operations)] for i, c in enumerate(self.cols_to_agg)\n        }",
        "min_run_count": 2,
        "name": "benchmarks.TimeGroupByDictionaryAggregation.time_groupby_dict_agg",
        "number": 0,
        "param_names": [
            "shape",
            "ngroups",
            "operation_type"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "100",
                "'huge_amount_groups'"
            ],
            [
                "'reduction'",
                "'aggregation'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "7aa41865cba30449bba2f4d9a40fe5d15e9d9b4c2c737222bd2a643fd6dcb39a",
        "warmup_time": -1
    },
    "benchmarks.TimeGroupByMultiColumn.time_groupby_agg_mean": {
        "code": "class TimeGroupByMultiColumn:\n    def time_groupby_agg_mean(self, *args, **kwargs):\n        execute(self.df.groupby(by=self.groupby_columns).apply(lambda df: df.mean()))\n\nclass BaseTimeGroupBy:\n    def setup(self, shape, ngroups=5, groupby_ncols=1):\n        ngroups = translator_groupby_ngroups(ngroups, shape)\n        self.df, self.groupby_columns = generate_dataframe(\n            ASV_USE_IMPL,\n            \"int\",\n            *shape,\n            RAND_LOW,\n            RAND_HIGH,\n            groupby_ncols,\n            count_groups=ngroups,\n        )",
        "min_run_count": 2,
        "name": "benchmarks.TimeGroupByMultiColumn.time_groupby_agg_mean",
        "number": 0,
        "param_names": [
            "shape",
            "ngroups",
            "groupby_ncols"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "100",
                "'huge_amount_groups'"
            ],
            [
                "6"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "6584be7f02bda8d4601daf00fbd3fce226a7d4436faa6353a196619348047dea",
        "warmup_time": -1
    },
    "benchmarks.TimeGroupByMultiColumn.time_groupby_agg_quan": {
        "code": "class TimeGroupByMultiColumn:\n    def time_groupby_agg_quan(self, *args, **kwargs):\n        execute(self.df.groupby(by=self.groupby_columns).agg(\"quantile\"))\n\nclass BaseTimeGroupBy:\n    def setup(self, shape, ngroups=5, groupby_ncols=1):\n        ngroups = translator_groupby_ngroups(ngroups, shape)\n        self.df, self.groupby_columns = generate_dataframe(\n            ASV_USE_IMPL,\n            \"int\",\n            *shape,\n            RAND_LOW,\n            RAND_HIGH,\n            groupby_ncols,\n            count_groups=ngroups,\n        )",
        "min_run_count": 2,
        "name": "benchmarks.TimeGroupByMultiColumn.time_groupby_agg_quan",
        "number": 0,
        "param_names": [
            "shape",
            "ngroups",
            "groupby_ncols"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "100",
                "'huge_amount_groups'"
            ],
            [
                "6"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "202444e83676d4998bfbfc58f218de93462f070c86e5000c628e56fb334193dc",
        "warmup_time": -1
    },
    "benchmarks.TimeHead.time_head": {
        "code": "class TimeHead:\n    def time_head(self, shape, head_count):\n        execute(self.df.head(self.head_count))\n\n    def setup(self, shape, head_count):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        self.head_count = (\n            int(head_count * len(self.df.index))\n            if isinstance(head_count, float)\n            else head_count\n        )",
        "min_run_count": 2,
        "name": "benchmarks.TimeHead.time_head",
        "number": 0,
        "param_names": [
            "shape",
            "head_count"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "5",
                "0.8"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "0ab97d453eb88717822a7fbc0a43910d61e597489b0d1c49eec882656edd2dcf",
        "warmup_time": -1
    },
    "benchmarks.TimeIndexing.time_iloc": {
        "code": "class TimeIndexing:\n    def time_iloc(self, shape, indexer_type):\n        execute(self.df.iloc[self.indexer])\n\n    def setup(self, shape, indexer_type):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        if indexer_type == \"bool\":\n            self.indexer = [False, True] * (shape[0] // 2)\n        elif indexer_type == \"scalar\":\n            self.indexer = shape[0] // 2\n        elif indexer_type == \"slice\":\n            self.indexer = slice(0, shape[0], 2)\n        elif indexer_type == \"list\":\n            self.indexer = [x for x in range(shape[0])]\n        elif indexer_type == \"function\":\n            self.indexer = lambda df: df.index[::-2]",
        "min_run_count": 2,
        "name": "benchmarks.TimeIndexing.time_iloc",
        "number": 0,
        "param_names": [
            "shape",
            "indexer_type"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "'scalar'",
                "'bool'",
                "'slice'",
                "'list'",
                "'function'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "4e7262aec0ddddcf2cf6befd225168aa1e9f52e0ebe945dc373d7bab9c5e494c",
        "warmup_time": -1
    },
    "benchmarks.TimeIndexing.time_loc": {
        "code": "class TimeIndexing:\n    def time_loc(self, shape, indexer_type):\n        execute(self.df.loc[self.indexer])\n\n    def setup(self, shape, indexer_type):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        if indexer_type == \"bool\":\n            self.indexer = [False, True] * (shape[0] // 2)\n        elif indexer_type == \"scalar\":\n            self.indexer = shape[0] // 2\n        elif indexer_type == \"slice\":\n            self.indexer = slice(0, shape[0], 2)\n        elif indexer_type == \"list\":\n            self.indexer = [x for x in range(shape[0])]\n        elif indexer_type == \"function\":\n            self.indexer = lambda df: df.index[::-2]",
        "min_run_count": 2,
        "name": "benchmarks.TimeIndexing.time_loc",
        "number": 0,
        "param_names": [
            "shape",
            "indexer_type"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "'scalar'",
                "'bool'",
                "'slice'",
                "'list'",
                "'function'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "7b6fd37f862f1a881d3f8e46bfd517d56f952ee9725a393f5c66ef88ba8a3a38",
        "warmup_time": -1
    },
    "benchmarks.TimeInsert.time_insert_qc": {
        "code": "class TimeInsert:\n    def time_insert_qc(self, *args, **kwargs):\n        self.df.insert(loc=self.iloc, column=random_string(), value=self.item)\n        execute(self.df)\n\nclass BaseTimeSetItem:\n    def setup(self, shape, item_length, loc, is_equal_indices):\n        self.df = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH\n        ).copy()\n        self.loc, self.iloc = self.get_loc(\n            self.df, loc, item_length=item_length, axis=1\n        )\n    \n        self.item = self.df[self.loc] + 1\n        self.item_raw = self.item.to_numpy()\n        if not is_equal_indices:\n            self.item.index = reversed(self.item.index)",
        "min_run_count": 2,
        "name": "benchmarks.TimeInsert.time_insert_qc",
        "number": 0,
        "param_names": [
            "shape",
            "item_length",
            "loc",
            "is_equal_indices"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "1"
            ],
            [
                "'zero'",
                "'middle'",
                "'last'"
            ],
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "6a36fc5cdb39f04cd6acb87bb95abcbb19bda4f85209e8d039c523287bdbf7a2",
        "warmup_time": -1
    },
    "benchmarks.TimeInsert.time_insert_raw": {
        "code": "class TimeInsert:\n    def time_insert_raw(self, *args, **kwargs):\n        self.df.insert(loc=self.iloc, column=random_string(), value=self.item_raw)\n        execute(self.df)\n\nclass BaseTimeSetItem:\n    def setup(self, shape, item_length, loc, is_equal_indices):\n        self.df = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH\n        ).copy()\n        self.loc, self.iloc = self.get_loc(\n            self.df, loc, item_length=item_length, axis=1\n        )\n    \n        self.item = self.df[self.loc] + 1\n        self.item_raw = self.item.to_numpy()\n        if not is_equal_indices:\n            self.item.index = reversed(self.item.index)",
        "min_run_count": 2,
        "name": "benchmarks.TimeInsert.time_insert_raw",
        "number": 0,
        "param_names": [
            "shape",
            "item_length",
            "loc",
            "is_equal_indices"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "1"
            ],
            [
                "'zero'",
                "'middle'",
                "'last'"
            ],
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "3df7c66b76b70618061bcfe51d0d0b9e10c21a48362cc453908a653cbe2fd176",
        "warmup_time": -1
    },
    "benchmarks.TimeJoin.time_join": {
        "code": "class TimeJoin:\n    def time_join(self, shapes, how, sort):\n        # join dataframes on index to get the predictable shape\n        execute(self.df1.join(self.df2, how=how, lsuffix=\"left_\", sort=sort))\n\n    def setup(self, shapes, how, sort):\n        self.df1 = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shapes[0], RAND_LOW, RAND_HIGH\n        )\n        self.df2 = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shapes[1], RAND_LOW, RAND_HIGH\n        )",
        "min_run_count": 2,
        "name": "benchmarks.TimeJoin.time_join",
        "number": 0,
        "param_names": [
            "shapes",
            "how",
            "sort"
        ],
        "params": [
            [
                "[[5000, 5000], [5000, 5000]]",
                "[[500000, 20], [1000000, 10]]"
            ],
            [
                "'left'",
                "'inner'"
            ],
            [
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "1aebc2ab80819fc05dfc2e9db051894b755bc1f69150780b6a4541019f1728dc",
        "warmup_time": -1
    },
    "benchmarks.TimeMerge.time_merge": {
        "code": "class TimeMerge:\n    def time_merge(self, shapes, how, sort):\n        # merge dataframes by index to get the predictable shape\n        execute(\n            self.df1.merge(\n                self.df2, left_index=True, right_index=True, how=how, sort=sort\n            )\n        )\n\n    def setup(self, shapes, how, sort):\n        self.df1 = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shapes[0], RAND_LOW, RAND_HIGH\n        )\n        self.df2 = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shapes[1], RAND_LOW, RAND_HIGH\n        )",
        "min_run_count": 2,
        "name": "benchmarks.TimeMerge.time_merge",
        "number": 0,
        "param_names": [
            "shapes",
            "how",
            "sort"
        ],
        "params": [
            [
                "[[5000, 5000], [5000, 5000]]",
                "[[500000, 20], [1000000, 10]]"
            ],
            [
                "'left'",
                "'inner'"
            ],
            [
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "5dd956fb7db1d5b0a96e59375c5e98318f9f43faa97b9b6562cf41d9445c9d9a",
        "warmup_time": -1
    },
    "benchmarks.TimeMultiIndexing.time_multiindex_loc": {
        "code": "class TimeMultiIndexing:\n    def time_multiindex_loc(self, shape):\n        execute(\n            self.df.loc[\n                self.df.index[2] : self.df.index[-2],\n                self.df.columns[2] : self.df.columns[-2],\n            ]\n        )\n\n    def setup(self, shape):\n        df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n    \n        index = pd.MultiIndex.from_product([df.index[: shape[0] // 2], [\"bar\", \"foo\"]])\n        columns = pd.MultiIndex.from_product(\n            [df.columns[: shape[1] // 2], [\"buz\", \"fuz\"]]\n        )\n    \n        df.index = index\n        df.columns = columns\n    \n        self.df = df.sort_index(axis=1)",
        "min_run_count": 2,
        "name": "benchmarks.TimeMultiIndexing.time_multiindex_loc",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "80e00dd183fe0c4a8126be25f72361ee20f99910b9769b7b35381e106e45dc4f",
        "warmup_time": -1
    },
    "benchmarks.TimeProperties.time_columns": {
        "code": "class TimeProperties:\n    def time_columns(self, shape):\n        return self.df.columns\n\n    def setup(self, shape):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)",
        "min_run_count": 2,
        "name": "benchmarks.TimeProperties.time_columns",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "effb7b0976e7b3b0ee005ca8318ad48fb5588e1836d8ec6535810367e46725a8",
        "warmup_time": -1
    },
    "benchmarks.TimeProperties.time_index": {
        "code": "class TimeProperties:\n    def time_index(self, shape):\n        return self.df.index\n\n    def setup(self, shape):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)",
        "min_run_count": 2,
        "name": "benchmarks.TimeProperties.time_index",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "487a3dbef05f696142e0534475d8373a9075dd28d31de0cf3449ca7a95ffb7b2",
        "warmup_time": -1
    },
    "benchmarks.TimeProperties.time_shape": {
        "code": "class TimeProperties:\n    def time_shape(self, shape):\n        return self.df.shape\n\n    def setup(self, shape):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)",
        "min_run_count": 2,
        "name": "benchmarks.TimeProperties.time_shape",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b8ce432425cc9aa74975357694dfa8cb95a0553d19b8daf97522757a0a607904",
        "warmup_time": -1
    },
    "benchmarks.TimeResetIndex.time_reset_index": {
        "code": "class TimeResetIndex:\n    def time_reset_index(self, shape, drop, level):\n        execute(self.df.reset_index(drop=drop, level=level))\n\n    def setup(self, shape, drop, level):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n    \n        if level:\n            index = pd.MultiIndex.from_product(\n                [self.df.index[: shape[0] // 2], [\"bar\", \"foo\"]],\n                names=[\"level_1\", \"level_2\"],\n            )\n            self.df.index = index",
        "min_run_count": 2,
        "name": "benchmarks.TimeResetIndex.time_reset_index",
        "number": 0,
        "param_names": [
            "shape",
            "drop",
            "level"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "False",
                "True"
            ],
            [
                "None",
                "'level_1'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "4ae1af8df03b9d41e917e8e6e18bd1eea483e80e35aa4f462ed1acee2f0a94a2",
        "warmup_time": -1
    },
    "benchmarks.TimeSetItem.time_setitem_qc": {
        "code": "class TimeSetItem:\n    def time_setitem_qc(self, *args, **kwargs):\n        self.df[self.loc] = self.item\n        execute(self.df)\n\nclass BaseTimeSetItem:\n    def setup(self, shape, item_length, loc, is_equal_indices):\n        self.df = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH\n        ).copy()\n        self.loc, self.iloc = self.get_loc(\n            self.df, loc, item_length=item_length, axis=1\n        )\n    \n        self.item = self.df[self.loc] + 1\n        self.item_raw = self.item.to_numpy()\n        if not is_equal_indices:\n            self.item.index = reversed(self.item.index)",
        "min_run_count": 2,
        "name": "benchmarks.TimeSetItem.time_setitem_qc",
        "number": 0,
        "param_names": [
            "shape",
            "item_length",
            "loc",
            "is_equal_indices"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "1"
            ],
            [
                "'zero'",
                "'middle'",
                "'last'"
            ],
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "1dcdd3d591970df5bad4e794a6b247d6b11cd6be21cf344809de06747fafbe17",
        "warmup_time": -1
    },
    "benchmarks.TimeSetItem.time_setitem_raw": {
        "code": "class TimeSetItem:\n    def time_setitem_raw(self, *args, **kwargs):\n        self.df[self.loc] = self.item_raw\n        execute(self.df)\n\nclass BaseTimeSetItem:\n    def setup(self, shape, item_length, loc, is_equal_indices):\n        self.df = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH\n        ).copy()\n        self.loc, self.iloc = self.get_loc(\n            self.df, loc, item_length=item_length, axis=1\n        )\n    \n        self.item = self.df[self.loc] + 1\n        self.item_raw = self.item.to_numpy()\n        if not is_equal_indices:\n            self.item.index = reversed(self.item.index)",
        "min_run_count": 2,
        "name": "benchmarks.TimeSetItem.time_setitem_raw",
        "number": 0,
        "param_names": [
            "shape",
            "item_length",
            "loc",
            "is_equal_indices"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "1"
            ],
            [
                "'zero'",
                "'middle'",
                "'last'"
            ],
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "6cae5f1f7d662915a35e36dc638b77707287a9bc5f67309f89f75fd57743ef01",
        "warmup_time": -1
    },
    "benchmarks.TimeSortValues.time_sort_values": {
        "code": "class TimeSortValues:\n    def time_sort_values(self, shape, columns_number, ascending_list):\n        execute(self.df.sort_values(self.columns, ascending=self.ascending))\n\n    def setup(self, shape, columns_number, ascending_list):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        self.columns = random_columns(self.df.columns, columns_number)\n        self.ascending = (\n            random_booleans(columns_number)\n            if ascending_list\n            else bool(random_booleans(1)[0])\n        )",
        "min_run_count": 2,
        "name": "benchmarks.TimeSortValues.time_sort_values",
        "number": 0,
        "param_names": [
            "shape",
            "columns_number",
            "ascending_list"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "1",
                "2",
                "10",
                "100"
            ],
            [
                "False",
                "True"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "5cf2258ccb3d7833acd5e9765b8023fdbf0d27fd70e540f457f576be26c37ec9",
        "warmup_time": -1
    },
    "benchmarks.TimeValueCountsFrame.time_value_counts": {
        "code": "class TimeValueCountsFrame:\n    def time_value_counts(self, *args, **kwargs):\n        execute(self.df.value_counts(subset=self.subset))\n\nclass BaseTimeValueCounts:\n    def setup(self, shape, ngroups=5, subset=1):\n        ngroups = translator_groupby_ngroups(ngroups, shape)\n        self.df, self.subset = generate_dataframe(\n            ASV_USE_IMPL,\n            \"int\",\n            *shape,\n            RAND_LOW,\n            RAND_HIGH,\n            groupby_ncols=subset,\n            count_groups=ngroups,\n        )",
        "min_run_count": 2,
        "name": "benchmarks.TimeValueCountsFrame.time_value_counts",
        "number": 0,
        "param_names": [
            "shape",
            "ngroups",
            "subset"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "100",
                "'huge_amount_groups'"
            ],
            [
                "2",
                "10"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "488013b792c8a1214b90fe24d1b8841b79b064073eec3c9c83d6c8132499b600",
        "warmup_time": -1
    },
    "benchmarks.TimeValueCountsSeries.time_value_counts": {
        "code": "class TimeValueCountsSeries:\n    def time_value_counts(self, shape, ngroups, bins):\n        execute(self.df.value_counts(bins=bins))\n\n    def setup(self, shape, ngroups, bins):\n        super().setup(ngroups=ngroups, shape=shape)\n        self.df = self.df[self.subset[0]]",
        "min_run_count": 2,
        "name": "benchmarks.TimeValueCountsSeries.time_value_counts",
        "number": 0,
        "param_names": [
            "shape",
            "ngroups",
            "bins"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "100",
                "'huge_amount_groups'"
            ],
            [
                "None",
                "3"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "161a0ca50c23d2aadc9c3fc29d46e3cd4699d4354b8a8b752b6d17f67e924a85",
        "warmup_time": -1
    },
    "io.csv.TimeReadCsvNamesDtype.time_read_csv_names_dtype": {
        "code": "class TimeReadCsvNamesDtype:\n    def time_read_csv_names_dtype(self, cache, shape, names, dtype):\n        execute(\n            IMPL[ASV_USE_IMPL].read_csv(\n                self.filename,\n                names=self.names,\n                header=0,\n                dtype=self.dtype,\n                parse_dates=self.parse_dates,\n            )\n        )\n\n    def setup(self, cache, shape, names, dtype):\n        # ray init\n        if ASV_USE_IMPL == \"modin\":\n            pd.DataFrame([])\n        file_id = self._get_file_id(shape, dtype)\n        self.filename, self.names, self.dtype = cache[file_id]\n    \n        self.parse_dates = None\n        if dtype == \"Int64_Timestamp\":\n            # cached version of dtype should not change\n            self.dtype = self.dtype.copy()\n            for col in self._timestamp_columns:\n                del self.dtype[col]\n            self.parse_dates = self._timestamp_columns\n\n    def setup_cache(self, test_filename=\"io_test_file_csv_names_dtype\"):\n        # filenames with a metadata of saved dataframes\n        cache = {}\n        for shape in self.shapes:\n            for dtype in self._dtypes_params:\n                df = generate_dataframe(\"pandas\", \"int\", *shape, RAND_LOW, RAND_HIGH)\n                if dtype == \"Int64_Timestamp\":\n                    df = self._add_timestamp_columns(df)\n    \n                file_id = self._get_file_id(shape, dtype)\n                cache[file_id] = (\n                    f\"{test_filename}_{file_id}.csv\",\n                    df.columns.to_list(),\n                    df.dtypes.to_dict(),\n                )\n                df.to_csv(cache[file_id][0], index=False)\n        return cache",
        "min_run_count": 2,
        "name": "io.csv.TimeReadCsvNamesDtype.time_read_csv_names_dtype",
        "number": 0,
        "param_names": [
            "shape",
            "names",
            "dtype"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "'array-like'"
            ],
            [
                "'Int64'",
                "'Int64_Timestamp'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "io.csv:121",
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "369f7d09f2322523c7befbe04c29bc8fdd6ca1273a5932743a623dcfdef3e597",
        "warmup_time": -1
    },
    "io.csv.TimeReadCsvSkiprows.time_skiprows": {
        "code": "class TimeReadCsvSkiprows:\n    def time_skiprows(self, test_filenames, shape, skiprows):\n        execute(\n            IMPL[ASV_USE_IMPL].read_csv(\n                test_filenames[self.shape_id], skiprows=self.skiprows\n            )\n        )\n\n    def setup(self, test_filenames, shape, skiprows):\n        super().setup(test_filenames, shape, skiprows)\n        self.skiprows = self.skiprows_mapping[skiprows] if skiprows else None\n\nclass BaseReadCsv:\n    def setup_cache(self, test_filename=\"io_test_file\"):\n        test_filenames = prepare_io_data(\n            test_filename, self.data_type, get_benchmark_shapes(self.__class__.__name__)\n        )\n        return test_filenames",
        "min_run_count": 2,
        "name": "io.csv.TimeReadCsvSkiprows.time_skiprows",
        "number": 0,
        "param_names": [
            "shape",
            "skiprows"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "None",
                "'lambda_even_rows'",
                "'range_uniform'",
                "'range_step2'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "io.csv:33",
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "eeb505794553ac5bb0c569262aa60e11c74a22da29ae2a77b9c071c55c6770d1",
        "warmup_time": -1
    },
    "io.csv.TimeReadCsvTrueFalseValues.time_true_false_values": {
        "code": "class TimeReadCsvTrueFalseValues:\n    def time_true_false_values(self, test_filenames, shape):\n        execute(\n            IMPL[ASV_USE_IMPL].read_csv(\n                test_filenames[self.shape_id],\n                true_values=[\"Yes\", \"true\"],\n                false_values=[\"No\", \"false\"],\n            ),\n            trigger_omnisci_import=ASV_USE_BACKEND == \"omnisci\",\n        )\n\nclass BaseReadCsv:\n    def setup(self, test_filenames, shape, *args, **kwargs):\n        # ray init\n        if ASV_USE_IMPL == \"modin\":\n            pd.DataFrame([])\n        self.shape_id = get_shape_id(shape)\n\n    def setup_cache(self, test_filename=\"io_test_file\"):\n        test_filenames = prepare_io_data(\n            test_filename, self.data_type, get_benchmark_shapes(self.__class__.__name__)\n        )\n        return test_filenames",
        "min_run_count": 2,
        "name": "io.csv.TimeReadCsvTrueFalseValues.time_true_false_values",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "io.csv:33",
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "eaa4cc15b433a38b333b4253efbc12e006b32fdb02cc28f8271db6b02e61d70a",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeAppend.time_append": {
        "code": "class TimeAppend:\n    def time_append(self, shapes):\n        execute(self.df1.append(self.df2))\n\n    def setup(self, shapes):\n        self.df1 = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shapes[0], RAND_LOW, RAND_HIGH\n        )\n        self.df2 = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shapes[1], RAND_LOW, RAND_HIGH\n        )\n        trigger_import(self.df1, self.df2)",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeAppend.time_append",
        "number": 0,
        "param_names": [
            "shapes"
        ],
        "params": [
            [
                "[[5000, 5000], [5000, 5000]]",
                "[[500000, 20], [1000000, 10]]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "a3cacbfc2a8a774c4d5f8246ef44446b11a8b1835e7a37c41c94d214b43ef227",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeArithmetic.time_apply": {
        "code": "class TimeArithmetic:\n    def time_apply(self, shape):\n        execute(self.df.apply(lambda df: df.sum()))\n\n    def setup(self, shape):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df)",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeArithmetic.time_apply",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "102328f8998e0541eaf1f8eefe81980715093c9ac0b9698ea1ce873c5329d002",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeArithmetic.time_mean": {
        "code": "class TimeArithmetic:\n    def time_mean(self, shape):\n        execute(self.df.mean())\n\n    def setup(self, shape):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df)",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeArithmetic.time_mean",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "7b7253c6d69ebf76f78d95932242931a1b351c7efdcc6ba728001639803757c5",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeArithmetic.time_median": {
        "code": "class TimeArithmetic:\n    def time_median(self, shape):\n        execute(self.df.median())\n\n    def setup(self, shape):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df)",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeArithmetic.time_median",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "248c3be0eae97f5b41a25722371a4807821ba9844a9dc0229c11bbcb1e698034",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeArithmetic.time_nunique": {
        "code": "class TimeArithmetic:\n    def time_nunique(self, shape):\n        execute(self.df.nunique())\n\n    def setup(self, shape):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df)",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeArithmetic.time_nunique",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "3e671ac667a0f34da79eba557d22bf6a0fc7869df080ba3f261bfbfde292ae88",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeArithmetic.time_sum": {
        "code": "class TimeArithmetic:\n    def time_sum(self, shape):\n        execute(self.df.sum())\n\n    def setup(self, shape):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df)",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeArithmetic.time_sum",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "fafe40a04bebc4a1dc38cb3af7625d5ad6708abdba8d6efa61c6fb7435983444",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeAstype.time_astype": {
        "code": "class TimeAstype:\n    def time_astype(self, shape, dtype, astype_ncolumns):\n        execute(self.df.astype(self.astype_arg))\n\n    def setup(self, shape, dtype, astype_ncolumns):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df)\n        self.astype_arg = self.create_astype_arg(dtype, astype_ncolumns)",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeAstype.time_astype",
        "number": 0,
        "param_names": [
            "shape",
            "dtype",
            "astype_ncolumns"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "'float64'"
            ],
            [
                "'one'",
                "'all'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "772dbb2b652ec375c854f681e7c304dde1f13aea1027f1046b2d0120a3a80c61",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeBinaryOpDataFrame.time_mul_dataframes": {
        "code": "class TimeBinaryOpDataFrame:\n    def time_mul_dataframes(self, shape, binary_op):\n        execute(self.op(self.df1))\n\n    def setup(self, shape, binary_op):\n        self.df1 = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df1)\n        self.op = getattr(self.df1, binary_op)",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeBinaryOpDataFrame.time_mul_dataframes",
        "number": 0,
        "param_names": [
            "shape",
            "binary_op"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "'mul'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "cbf27cfd54582f373feb1cb9927f6467f2dc44af9cdcc225af882f55508fb2c9",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeBinaryOpDataFrame.time_mul_scalar": {
        "code": "class TimeBinaryOpDataFrame:\n    def time_mul_scalar(self, shape, binary_op):\n        execute(self.op(2))\n\n    def setup(self, shape, binary_op):\n        self.df1 = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df1)\n        self.op = getattr(self.df1, binary_op)",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeBinaryOpDataFrame.time_mul_scalar",
        "number": 0,
        "param_names": [
            "shape",
            "binary_op"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "'mul'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "34e84906699176fea6c896064546451029287238c6072608e7064ade1f052b8e",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeBinaryOpSeries.time_mul_series": {
        "code": "class TimeBinaryOpSeries:\n    def time_mul_series(self, shape, binary_op):\n        execute(self.op(self.series))\n\n    def setup(self, shape, binary_op):\n        self.series = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH\n        )[\"col0\"]\n        trigger_import(self.series)\n        self.op = getattr(self.series, binary_op)",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeBinaryOpSeries.time_mul_series",
        "number": 0,
        "param_names": [
            "shape",
            "binary_op"
        ],
        "params": [
            [
                "[100000, 1]"
            ],
            [
                "'mul'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "60a8e3e8f118610009cc3d75cf410b8ee379c830c2c63c8d483ebec34ad66d6b",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeDescribe.time_describe": {
        "code": "class TimeDescribe:\n    def time_describe(self, shape):\n        execute(self.df.describe())\n\n    def setup(self, shape):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df)",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeDescribe.time_describe",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "ae65a6c7ffb9c354886add011790b81bce91e041559bb34e3869a6b570db085e",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeDrop.time_drop": {
        "code": "class TimeDrop:\n    def time_drop(self, shape, drop_ncols):\n        execute(self.df.drop(self.labels, axis=1))\n\n    def setup(self, shape, drop_ncols):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df)\n        drop_count = (\n            int(len(self.df.axes[1]) * drop_ncols)\n            if isinstance(drop_ncols, float)\n            else drop_ncols\n        )\n        self.labels = self.df.axes[1][:drop_count]",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeDrop.time_drop",
        "number": 0,
        "param_names": [
            "shape",
            "drop_ncols"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "1",
                "0.8"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "196ba2737a491f1ee6476f86b67ed527ee75d4026fee40c43dcfa84d09ca0e14",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeFillna.time_fillna": {
        "code": "class TimeFillna:\n    def time_fillna(self, value_type, shape, limit):\n        execute(self.df.fillna(**self.kw))\n\n    def setup(self, value_type, shape, limit):\n        self.df = gen_nan_data(ASV_USE_IMPL, *shape)\n        columns = self.df.columns\n        trigger_import(self.df)\n    \n        value = self.create_fillna_value(value_type, columns)\n        limit = int(limit * shape[0]) if limit else None\n        self.kw = {\"value\": value, \"limit\": limit}",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeFillna.time_fillna",
        "number": 0,
        "param_names": [
            "value_type",
            "shape",
            "limit"
        ],
        "params": [
            [
                "'scalar'",
                "'dict'"
            ],
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "None"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "ded6d632f7f53f3204d98bcc3b747aec90825900141de185eb34abdae64ffa10",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeGroupByDefaultAggregations.time_groupby_count": {
        "code": "class TimeGroupByDefaultAggregations:\n    def time_groupby_count(self, *args, **kwargs):\n        execute(self.df.groupby(by=self.groupby_columns).count())\n\nclass BaseTimeGroupBy:\n    def setup(self, shape, ngroups=5, groupby_ncols=1):\n        ngroups = translator_groupby_ngroups(ngroups, shape)\n        self.df, self.groupby_columns = generate_dataframe(\n            ASV_USE_IMPL,\n            \"int\",\n            *shape,\n            RAND_LOW,\n            RAND_HIGH,\n            groupby_ncols,\n            count_groups=ngroups,\n        )\n        trigger_import(self.df)",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeGroupByDefaultAggregations.time_groupby_count",
        "number": 0,
        "param_names": [
            "shape",
            "ngroups"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "100",
                "'huge_amount_groups'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "23828a6c2d72006664542f81e4745ca20d03e91ed2a366852706f6a0f8ba6a5b",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeGroupByDefaultAggregations.time_groupby_sum": {
        "code": "class TimeGroupByDefaultAggregations:\n    def time_groupby_sum(self, *args, **kwargs):\n        execute(self.df.groupby(by=self.groupby_columns).sum())\n\nclass BaseTimeGroupBy:\n    def setup(self, shape, ngroups=5, groupby_ncols=1):\n        ngroups = translator_groupby_ngroups(ngroups, shape)\n        self.df, self.groupby_columns = generate_dataframe(\n            ASV_USE_IMPL,\n            \"int\",\n            *shape,\n            RAND_LOW,\n            RAND_HIGH,\n            groupby_ncols,\n            count_groups=ngroups,\n        )\n        trigger_import(self.df)",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeGroupByDefaultAggregations.time_groupby_sum",
        "number": 0,
        "param_names": [
            "shape",
            "ngroups"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "100",
                "'huge_amount_groups'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "9c0a8d9189a5a6fadd049bd3a62bddea0a458f77dfb1b9b59d69300c83d52546",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeGroupByMultiColumn.time_groupby_agg_mean": {
        "code": "class TimeGroupByMultiColumn:\n    def time_groupby_agg_mean(self, *args, **kwargs):\n        execute(self.df.groupby(by=self.groupby_columns).agg(\"mean\"))\n\nclass BaseTimeGroupBy:\n    def setup(self, shape, ngroups=5, groupby_ncols=1):\n        ngroups = translator_groupby_ngroups(ngroups, shape)\n        self.df, self.groupby_columns = generate_dataframe(\n            ASV_USE_IMPL,\n            \"int\",\n            *shape,\n            RAND_LOW,\n            RAND_HIGH,\n            groupby_ncols,\n            count_groups=ngroups,\n        )\n        trigger_import(self.df)",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeGroupByMultiColumn.time_groupby_agg_mean",
        "number": 0,
        "param_names": [
            "shape",
            "ngroups",
            "groupby_ncols"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "100",
                "'huge_amount_groups'"
            ],
            [
                "6"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "5c240e7ca02754d6d335a823dc6e56c36b8724de362287527816a8b8fb2a2dd5",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeGroupByMultiColumn.time_groupby_agg_nunique": {
        "code": "class TimeGroupByMultiColumn:\n    def time_groupby_agg_nunique(self, *args, **kwargs):\n        execute(self.df.groupby(by=self.groupby_columns).agg(\"nunique\"))\n\nclass BaseTimeGroupBy:\n    def setup(self, shape, ngroups=5, groupby_ncols=1):\n        ngroups = translator_groupby_ngroups(ngroups, shape)\n        self.df, self.groupby_columns = generate_dataframe(\n            ASV_USE_IMPL,\n            \"int\",\n            *shape,\n            RAND_LOW,\n            RAND_HIGH,\n            groupby_ncols,\n            count_groups=ngroups,\n        )\n        trigger_import(self.df)",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeGroupByMultiColumn.time_groupby_agg_nunique",
        "number": 0,
        "param_names": [
            "shape",
            "ngroups",
            "groupby_ncols"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "100",
                "'huge_amount_groups'"
            ],
            [
                "6"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "79e05eb423f8550c69d398c23b942938cef120854c728323f2b96335aa419a52",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeGroupByMultiColumn.time_groupby_sum": {
        "code": "class TimeGroupByMultiColumn:\n    def time_groupby_sum(self, *args, **kwargs):\n        execute(self.df.groupby(by=self.groupby_columns).sum())\n\nclass BaseTimeGroupBy:\n    def setup(self, shape, ngroups=5, groupby_ncols=1):\n        ngroups = translator_groupby_ngroups(ngroups, shape)\n        self.df, self.groupby_columns = generate_dataframe(\n            ASV_USE_IMPL,\n            \"int\",\n            *shape,\n            RAND_LOW,\n            RAND_HIGH,\n            groupby_ncols,\n            count_groups=ngroups,\n        )\n        trigger_import(self.df)",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeGroupByMultiColumn.time_groupby_sum",
        "number": 0,
        "param_names": [
            "shape",
            "ngroups",
            "groupby_ncols"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "100",
                "'huge_amount_groups'"
            ],
            [
                "6"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "2672c1431f2e5e0812e02b54bb5b9e08dfd612a937d1d57e2cd07a524b51c650",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeHead.time_head": {
        "code": "class TimeHead:\n    def time_head(self, shape, head_count):\n        execute(self.df.head(self.head_count))\n\n    def setup(self, shape, head_count):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df)\n        self.head_count = (\n            int(head_count * len(self.df.index))\n            if isinstance(head_count, float)\n            else head_count\n        )",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeHead.time_head",
        "number": 0,
        "param_names": [
            "shape",
            "head_count"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "5",
                "0.8"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "9b63f9023b24d56289392a553a624be4b0dbd5d006de0863066194880d3100f1",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeIndexing.time_iloc": {
        "code": "class TimeIndexing:\n    def time_iloc(self, shape, indexer_type):\n        execute(self.df.iloc[self.indexer])\n\n    def setup(self, shape, indexer_type):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df)\n        self.indexer = {\n            \"bool\": [False, True] * (shape[0] // 2),\n            \"scalar\": shape[0] // 2,\n            \"slice\": slice(0, shape[0], 2),\n            \"list\": list(range(shape[0])),\n            \"function\": lambda df: df.index[::-2],\n        }[indexer_type]",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeIndexing.time_iloc",
        "number": 0,
        "param_names": [
            "shape",
            "indexer_type"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "'scalar'",
                "'bool'",
                "'slice'",
                "'list'",
                "'function'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "589f8c215898437525e4e3fb88c7f6fa2129b8b005f1020a4b649c342d694f45",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeIndexing.time_loc": {
        "code": "class TimeIndexing:\n    def time_loc(self, shape, indexer_type):\n        execute(self.df.loc[self.indexer])\n\n    def setup(self, shape, indexer_type):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df)\n        self.indexer = {\n            \"bool\": [False, True] * (shape[0] // 2),\n            \"scalar\": shape[0] // 2,\n            \"slice\": slice(0, shape[0], 2),\n            \"list\": list(range(shape[0])),\n            \"function\": lambda df: df.index[::-2],\n        }[indexer_type]",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeIndexing.time_loc",
        "number": 0,
        "param_names": [
            "shape",
            "indexer_type"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "'scalar'",
                "'bool'",
                "'slice'",
                "'list'",
                "'function'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "d399137366251ff11e3cbe69cc2e89676564e453b3bd0c3059c7c4b8c4b0d02d",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeJoin.time_join": {
        "code": "class TimeJoin:\n    def time_join(self, shape, how):\n        # join dataframes on index to get the predictable shape\n        execute(self.df1.join(self.df2, how=how, lsuffix=\"left_\"))\n\n    def setup(self, shape, how):\n        self.df1 = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        self.df2 = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df1, self.df2)",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeJoin.time_join",
        "number": 0,
        "param_names": [
            "shape",
            "how"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "'left'",
                "'inner'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "2b4b99896e2128e094cd7fe693d48b70635d5a4ae868bbd5949d57f69d39cba0",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeMerge.time_merge": {
        "code": "class TimeMerge:\n    def time_merge(self, shapes, how):\n        # merging dataframes by index is not supported, therefore we merge by column\n        # with arbitrary values, which leads to an unpredictable form of the operation result;\n        # it's need to get the predictable shape to get consistent performance results\n        execute(\n            self.df1.merge(self.df2, on=\"col1\", how=how, suffixes=(\"left_\", \"right_\"))\n        )\n\n    def setup(self, shapes, how):\n        self.df1 = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shapes[0], RAND_LOW, RAND_HIGH\n        )\n        self.df2 = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shapes[1], RAND_LOW, RAND_HIGH\n        )\n        trigger_import(self.df1, self.df2)",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeMerge.time_merge",
        "number": 0,
        "param_names": [
            "shapes",
            "how"
        ],
        "params": [
            [
                "[[5000, 5000], [5000, 5000]]",
                "[[500000, 20], [1000000, 10]]"
            ],
            [
                "'left'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "e9fc4f4bfabbef9470f18a815e57582c09797f6e609cf83eca5f0d5c6aa7c280",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeProperties.time_columns": {
        "code": "class TimeProperties:\n    def time_columns(self, shape):\n        return self.df.columns\n\n    def setup(self, shape):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df)",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeProperties.time_columns",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "371c54e3ed71de7d9a90601685f95a9a17a2b8f30bddf01d9c8f747eb62d8044",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeProperties.time_index": {
        "code": "class TimeProperties:\n    def time_index(self, shape):\n        return self.df.index\n\n    def setup(self, shape):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df)",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeProperties.time_index",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "699a1c92d95a113816a7944b98f71ebf885071b39ccf7931a201101a9c9cf6a5",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeProperties.time_shape": {
        "code": "class TimeProperties:\n    def time_shape(self, shape):\n        return self.df.shape\n\n    def setup(self, shape):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df)",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeProperties.time_shape",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "18e9903979a6577b4db24064a47d09f727ae18f95cc0139f3fa7c0d193077731",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeResetIndex.time_reset_index": {
        "code": "class TimeResetIndex:\n    def time_reset_index(self, shape, drop, level):\n        execute(self.df.reset_index(drop=drop, level=level))\n\n    def setup(self, shape, drop, level):\n        pd = IMPL[ASV_USE_IMPL]\n        if not drop or level == \"level_1\":\n            raise NotImplementedError\n    \n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        if level:\n            index = pd.MultiIndex.from_product(\n                [self.df.index[: shape[0] // 2], [\"bar\", \"foo\"]],\n                names=[\"level_1\", \"level_2\"],\n            )\n            self.df.index = index\n        trigger_import(self.df)",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeResetIndex.time_reset_index",
        "number": 0,
        "param_names": [
            "shape",
            "drop",
            "level"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "False",
                "True"
            ],
            [
                "None",
                "'level_1'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "53deff70a93b12387fa508c3c928f4056d8d8919cf4fd97a8597f4a6b1614df0",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeSortValues.time_sort_values": {
        "code": "class TimeSortValues:\n    def time_sort_values(self, shape, columns_number, ascending_list):\n        execute(self.df.sort_values(self.columns, ascending=self.ascending))\n\n    def setup(self, shape, columns_number, ascending_list):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df)\n        self.columns = random_columns(self.df.columns, columns_number)\n        self.ascending = (\n            random_booleans(columns_number)\n            if ascending_list\n            else bool(random_booleans(1)[0])\n        )",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeSortValues.time_sort_values",
        "number": 0,
        "param_names": [
            "shape",
            "columns_number",
            "ascending_list"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "1",
                "5"
            ],
            [
                "False",
                "True"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "80291c87f0eb5241a860340ccd219981eb683da4e5702954d223fbbd475354d9",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeValueCountsDataFrame.time_value_counts": {
        "code": "class TimeValueCountsDataFrame:\n    def time_value_counts(self, *args, **kwargs):\n        execute(self.df.value_counts(subset=self.subset))\n\nclass BaseTimeValueCounts:\n    def setup(self, shape, ngroups=5, subset=1):\n        ngroups = translator_groupby_ngroups(ngroups, shape)\n        self.df, self.subset = generate_dataframe(\n            ASV_USE_IMPL,\n            \"int\",\n            *shape,\n            RAND_LOW,\n            RAND_HIGH,\n            groupby_ncols=subset,\n            count_groups=ngroups,\n        )\n        trigger_import(self.df)",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeValueCountsDataFrame.time_value_counts",
        "number": 0,
        "param_names": [
            "shape",
            "ngroups",
            "subset"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "100",
                "'huge_amount_groups'"
            ],
            [
                "2",
                "10"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "130f78c46e8dd21a9803c5e15312e7bbeea976b28fa21590ee73e0fe18de8624",
        "warmup_time": -1
    },
    "omnisci.benchmarks.TimeValueCountsSeries.time_value_counts": {
        "code": "class TimeValueCountsSeries:\n    def time_value_counts(self, shape, ngroups):\n        execute(self.series.value_counts())\n\n    def setup(self, shape, ngroups):\n        super().setup(shape, ngroups, subset=1)\n        self.series = self.df[self.subset[0]]\n        trigger_import(self.series)",
        "min_run_count": 2,
        "name": "omnisci.benchmarks.TimeValueCountsSeries.time_value_counts",
        "number": 0,
        "param_names": [
            "shape",
            "ngroups"
        ],
        "params": [
            [
                "[100000, 1]"
            ],
            [
                "100",
                "'huge_amount_groups'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "50d039f809a57224798f163963708292724bc1f840d29c56433f0628d90b683b",
        "warmup_time": -1
    },
    "omnisci.io.TimeReadCsvNames.time_read_csv_names": {
        "code": "class TimeReadCsvNames:\n    def time_read_csv_names(self, cache, shape):\n        df = IMPL[ASV_USE_IMPL].read_csv(\n            self.filename,\n            names=self.names,\n            header=0,\n            dtype=self.dtype,\n        )\n        trigger_import(df)\n\n    def setup(self, cache, shape):\n        # ray init\n        if ASV_USE_IMPL == \"modin\":\n            pd.DataFrame([])\n        file_id = get_shape_id(shape)\n        self.filename, self.names, self.dtype = cache[file_id]\n\n    def setup_cache(self, test_filename=\"io_test_file_csv_names\"):\n        # filenames with a metadata of saved dataframes\n        cache = {}\n        for shape in self.shapes:\n            df = generate_dataframe(\"pandas\", \"int\", *shape, RAND_LOW, RAND_HIGH)\n            file_id = get_shape_id(shape)\n            cache[file_id] = (\n                f\"{test_filename}_{file_id}.csv\",\n                df.columns.to_list(),\n                df.dtypes.to_dict(),\n            )\n            df.to_csv(cache[file_id][0], index=False)\n        return cache",
        "min_run_count": 2,
        "name": "omnisci.io.TimeReadCsvNames.time_read_csv_names",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "omnisci.io:37",
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "ea3f66c8a5cbde5e04d94bc693e5b65e70285e7ebb5df1d6445a7f2aefb63f80",
        "warmup_time": -1
    },
    "omnisci.io.TimeReadCsvTrueFalseValues.time_true_false_values": {
        "code": "class TimeReadCsvTrueFalseValues:\n    def time_true_false_values(self, test_filenames, shape):\n        execute(\n            IMPL[ASV_USE_IMPL].read_csv(\n                test_filenames[self.shape_id],\n                true_values=[\"Yes\", \"true\"],\n                false_values=[\"No\", \"false\"],\n            ),\n            trigger_omnisci_import=ASV_USE_BACKEND == \"omnisci\",\n        )\n\nclass BaseReadCsv:\n    def setup(self, test_filenames, shape, *args, **kwargs):\n        # ray init\n        if ASV_USE_IMPL == \"modin\":\n            pd.DataFrame([])\n        self.shape_id = get_shape_id(shape)\n\n    def setup_cache(self, test_filename=\"io_test_file\"):\n        test_filenames = prepare_io_data(\n            test_filename, self.data_type, get_benchmark_shapes(self.__class__.__name__)\n        )\n        return test_filenames",
        "min_run_count": 2,
        "name": "omnisci.io.TimeReadCsvTrueFalseValues.time_true_false_values",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "io.csv:33",
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "eaa4cc15b433a38b333b4253efbc12e006b32fdb02cc28f8271db6b02e61d70a",
        "warmup_time": -1
    },
    "scalability.scalability_benchmarks.TimeFromPandas.time_from_pandas": {
        "code": "class TimeFromPandas:\n    def time_from_pandas(self, shape, cpus):\n        execute(from_pandas(self.data))\n\n    def setup(self, shape, cpus):\n        self.data = pandas.DataFrame(gen_data(\"int\", *shape, RAND_LOW, RAND_HIGH))\n        from modin.config import NPartitions\n    \n        NPartitions.get = lambda: cpus\n        # trigger ray init\n        pd.DataFrame([])",
        "min_run_count": 2,
        "name": "scalability.scalability_benchmarks.TimeFromPandas.time_from_pandas",
        "number": 0,
        "param_names": [
            "shape",
            "cpus"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "4",
                "16",
                "32"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "8af06db97bd87859b17230125772585ddc3fe0c5e23426aca77776870540eab1",
        "warmup_time": -1
    },
    "scalability.scalability_benchmarks.TimeToPandas.time_to_pandas": {
        "code": "class TimeToPandas:\n    def time_to_pandas(self, shape, cpus):\n        # to_pandas is already synchronous\n        to_pandas(self.data)\n\n    def setup(self, shape, cpus):\n        from modin.config import NPartitions\n    \n        NPartitions.get = lambda: cpus\n        self.data = generate_dataframe(\"modin\", \"int\", *shape, RAND_LOW, RAND_HIGH)",
        "min_run_count": 2,
        "name": "scalability.scalability_benchmarks.TimeToPandas.time_to_pandas",
        "number": 0,
        "param_names": [
            "shape",
            "cpus"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "4",
                "16",
                "32"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "6e9561fb9fd503ccfe496c5c520304c983774eaabfbe0ec8958c49b39bdec972",
        "warmup_time": -1
    },
    "version": 2
}