{
    "benchmarks.TimeAppend.time_append": {
        "code": "class TimeAppend:\n    def time_append(self, shapes, sort):\n        execute(self.df1.append(self.df2, sort=sort))\n\n    def setup(self, shapes, sort):\n        self.df1 = generate_dataframe(\"int\", *shapes[0], RAND_LOW, RAND_HIGH)\n        self.df2 = generate_dataframe(\"int\", *shapes[1], RAND_LOW, RAND_HIGH)\n        if sort:\n            self.df1.columns = self.df1.columns[::-1]",
        "min_run_count": 2,
        "name": "benchmarks.TimeAppend.time_append",
        "number": 0,
        "param_names": [
            "shapes",
            "sort"
        ],
        "params": [
            [
                "[[5000, 5000], [5000, 5000]]",
                "[[500000, 20], [1000000, 10]]"
            ],
            [
                "False",
                "True"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "c257454860e7d056ae778f1ae711a6b92534498d4119aff4f19040b07b45adf6",
        "warmup_time": -1
    },
    "benchmarks.TimeArithmetic.time_abs": {
        "code": "class TimeArithmetic:\n    def time_abs(self, shape, axis):\n        execute(self.df.abs())\n\n    def setup(self, shape, axis):\n        self.df = generate_dataframe(\"int\", *shape, RAND_LOW, RAND_HIGH)",
        "min_run_count": 2,
        "name": "benchmarks.TimeArithmetic.time_abs",
        "number": 0,
        "param_names": [
            "shape",
            "axis"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "ee4498b2db876e494044b6bcf3ad0e4e30877b2486396d86df2e90dc37ec3442",
        "warmup_time": -1
    },
    "benchmarks.TimeArithmetic.time_add": {
        "code": "class TimeArithmetic:\n    def time_add(self, shape, axis):\n        execute(self.df.add(2, axis=axis))\n\n    def setup(self, shape, axis):\n        self.df = generate_dataframe(\"int\", *shape, RAND_LOW, RAND_HIGH)",
        "min_run_count": 2,
        "name": "benchmarks.TimeArithmetic.time_add",
        "number": 0,
        "param_names": [
            "shape",
            "axis"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "ef916b55a54da106f5b584d2dfeef60d05126d9ec313a25e03fce8771824db7f",
        "warmup_time": -1
    },
    "benchmarks.TimeArithmetic.time_aggregate": {
        "code": "class TimeArithmetic:\n    def time_aggregate(self, shape, axis):\n        execute(self.df.aggregate(lambda df: df.sum(), axis=axis))\n\n    def setup(self, shape, axis):\n        self.df = generate_dataframe(\"int\", *shape, RAND_LOW, RAND_HIGH)",
        "min_run_count": 2,
        "name": "benchmarks.TimeArithmetic.time_aggregate",
        "number": 0,
        "param_names": [
            "shape",
            "axis"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "be138d73cbd53607bde720215c2d4212c6a4575ad1a3590f9bfba193601045eb",
        "warmup_time": -1
    },
    "benchmarks.TimeArithmetic.time_apply": {
        "code": "class TimeArithmetic:\n    def time_apply(self, shape, axis):\n        execute(self.df.apply(lambda df: df.sum(), axis=axis))\n\n    def setup(self, shape, axis):\n        self.df = generate_dataframe(\"int\", *shape, RAND_LOW, RAND_HIGH)",
        "min_run_count": 2,
        "name": "benchmarks.TimeArithmetic.time_apply",
        "number": 0,
        "param_names": [
            "shape",
            "axis"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "c2c2ca04576f8fb3174a9c69bcfabf47a3d55c2a32da1ceb83ffddee66c59f17",
        "warmup_time": -1
    },
    "benchmarks.TimeArithmetic.time_count": {
        "code": "class TimeArithmetic:\n    def time_count(self, shape, axis):\n        execute(self.df.count(axis=axis))\n\n    def setup(self, shape, axis):\n        self.df = generate_dataframe(\"int\", *shape, RAND_LOW, RAND_HIGH)",
        "min_run_count": 2,
        "name": "benchmarks.TimeArithmetic.time_count",
        "number": 0,
        "param_names": [
            "shape",
            "axis"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "a9c378817c1346cbe01748c33de3a220bd080dbce459ab7cb6b2a1673ad1ece3",
        "warmup_time": -1
    },
    "benchmarks.TimeArithmetic.time_is_in": {
        "code": "class TimeArithmetic:\n    def time_is_in(self, shape, axis):\n        execute(self.df.isin([0, 2]))\n\n    def setup(self, shape, axis):\n        self.df = generate_dataframe(\"int\", *shape, RAND_LOW, RAND_HIGH)",
        "min_run_count": 2,
        "name": "benchmarks.TimeArithmetic.time_is_in",
        "number": 0,
        "param_names": [
            "shape",
            "axis"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "a5d845dfd1ba301a26d5c80efced7d61655d337e2fb578a2d445258326c8379b",
        "warmup_time": -1
    },
    "benchmarks.TimeArithmetic.time_mean": {
        "code": "class TimeArithmetic:\n    def time_mean(self, shape, axis):\n        execute(self.df.mean(axis=axis))\n\n    def setup(self, shape, axis):\n        self.df = generate_dataframe(\"int\", *shape, RAND_LOW, RAND_HIGH)",
        "min_run_count": 2,
        "name": "benchmarks.TimeArithmetic.time_mean",
        "number": 0,
        "param_names": [
            "shape",
            "axis"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "c37af707e583fd4f971ad226bfaa5e3fc557aa71151dbcd9ea92f6689e5292db",
        "warmup_time": -1
    },
    "benchmarks.TimeArithmetic.time_median": {
        "code": "class TimeArithmetic:\n    def time_median(self, shape, axis):\n        execute(self.df.median(axis=axis))\n\n    def setup(self, shape, axis):\n        self.df = generate_dataframe(\"int\", *shape, RAND_LOW, RAND_HIGH)",
        "min_run_count": 2,
        "name": "benchmarks.TimeArithmetic.time_median",
        "number": 0,
        "param_names": [
            "shape",
            "axis"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "74e719e5ee119da824f4fae26179f8c567ae3f22e41de86e3eb00f9c85270fa9",
        "warmup_time": -1
    },
    "benchmarks.TimeArithmetic.time_mod": {
        "code": "class TimeArithmetic:\n    def time_mod(self, shape, axis):\n        execute(self.df.mod(2, axis=axis))\n\n    def setup(self, shape, axis):\n        self.df = generate_dataframe(\"int\", *shape, RAND_LOW, RAND_HIGH)",
        "min_run_count": 2,
        "name": "benchmarks.TimeArithmetic.time_mod",
        "number": 0,
        "param_names": [
            "shape",
            "axis"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f8c4ac39e060e885bc95da19b97e931e1c85a5bae463dcd6c3e07b3f90185d02",
        "warmup_time": -1
    },
    "benchmarks.TimeArithmetic.time_mode": {
        "code": "class TimeArithmetic:\n    def time_mode(self, shape, axis):\n        execute(self.df.mode(axis=axis))\n\n    def setup(self, shape, axis):\n        self.df = generate_dataframe(\"int\", *shape, RAND_LOW, RAND_HIGH)",
        "min_run_count": 2,
        "name": "benchmarks.TimeArithmetic.time_mode",
        "number": 0,
        "param_names": [
            "shape",
            "axis"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "93533197697ed6a724ce9d077c168096791012caf5f65391dc1204742efe78c3",
        "warmup_time": -1
    },
    "benchmarks.TimeArithmetic.time_mul": {
        "code": "class TimeArithmetic:\n    def time_mul(self, shape, axis):\n        execute(self.df.mul(2, axis=axis))\n\n    def setup(self, shape, axis):\n        self.df = generate_dataframe(\"int\", *shape, RAND_LOW, RAND_HIGH)",
        "min_run_count": 2,
        "name": "benchmarks.TimeArithmetic.time_mul",
        "number": 0,
        "param_names": [
            "shape",
            "axis"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "2726bce9271907b4e6456fee5d0ee6148dbf1b0286a6805bd1671e5585e1bf21",
        "warmup_time": -1
    },
    "benchmarks.TimeArithmetic.time_nunique": {
        "code": "class TimeArithmetic:\n    def time_nunique(self, shape, axis):\n        execute(self.df.nunique(axis=axis))\n\n    def setup(self, shape, axis):\n        self.df = generate_dataframe(\"int\", *shape, RAND_LOW, RAND_HIGH)",
        "min_run_count": 2,
        "name": "benchmarks.TimeArithmetic.time_nunique",
        "number": 0,
        "param_names": [
            "shape",
            "axis"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "fb43b93d371eb7f6d5abea097042dab07f3cb6564b2301ef7e3c560c5c6246b0",
        "warmup_time": -1
    },
    "benchmarks.TimeArithmetic.time_sum": {
        "code": "class TimeArithmetic:\n    def time_sum(self, shape, axis):\n        execute(self.df.sum(axis=axis))\n\n    def setup(self, shape, axis):\n        self.df = generate_dataframe(\"int\", *shape, RAND_LOW, RAND_HIGH)",
        "min_run_count": 2,
        "name": "benchmarks.TimeArithmetic.time_sum",
        "number": 0,
        "param_names": [
            "shape",
            "axis"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "460006987e31fe3f92580c0f0e949c52b650373dd62fa381c4831fffbb7f8b69",
        "warmup_time": -1
    },
    "benchmarks.TimeArithmetic.time_transpose": {
        "code": "class TimeArithmetic:\n    def time_transpose(self, shape, axis):\n        execute(self.df.transpose())\n\n    def setup(self, shape, axis):\n        self.df = generate_dataframe(\"int\", *shape, RAND_LOW, RAND_HIGH)",
        "min_run_count": 2,
        "name": "benchmarks.TimeArithmetic.time_transpose",
        "number": 0,
        "param_names": [
            "shape",
            "axis"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "7f04b0e9673cc769728dad26b6d397c576ea23ee60e386ee108ec3a9d9b27314",
        "warmup_time": -1
    },
    "benchmarks.TimeAstype.time_astype": {
        "code": "class TimeAstype:\n    def time_astype(self, shape, dtype, astype_ncolumns):\n        execute(self.df.astype(self.astype_arg))\n\n    def setup(self, shape, dtype, astype_ncolumns):\n        self.df = generate_dataframe(\"int\", *shape, RAND_LOW, RAND_HIGH)\n        if astype_ncolumns == \"all\":\n            self.astype_arg = dtype\n        elif astype_ncolumns == \"one\":\n            self.astype_arg = {\"col1\": dtype}\n        else:\n            raise ValueError(f\"astype_ncolumns: {astype_ncolumns} isn't supported\")",
        "min_run_count": 2,
        "name": "benchmarks.TimeAstype.time_astype",
        "number": 0,
        "param_names": [
            "shape",
            "dtype",
            "astype_ncolumns"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "'float64'",
                "'category'"
            ],
            [
                "'one'",
                "'all'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "06d64b156060cd5374a71b64f79563c3ed585ce6311feb7c756c0b4935070c7a",
        "warmup_time": -1
    },
    "benchmarks.TimeBinaryOp.time_binary_op": {
        "code": "class TimeBinaryOp:\n    def time_binary_op(self, shapes, binary_op, axis):\n        execute(self.op(self.df2, axis=axis))\n\n    def setup(self, shapes, binary_op, axis):\n        self.df1 = generate_dataframe(\"int\", *shapes[0], RAND_LOW, RAND_HIGH)\n        self.df2 = generate_dataframe(\"int\", *shapes[1], RAND_LOW, RAND_HIGH)\n        self.op = getattr(self.df1, binary_op)",
        "min_run_count": 2,
        "name": "benchmarks.TimeBinaryOp.time_binary_op",
        "number": 0,
        "param_names": [
            "shapes",
            "binary_op",
            "axis"
        ],
        "params": [
            [
                "[[5000, 5000], [5000, 5000]]",
                "[[500000, 20], [1000000, 10]]"
            ],
            [
                "'mul'"
            ],
            [
                "0",
                "1"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "fe707e7e930d09206b8c08fca7ad864cf9b81bb120afa334fc22ae27c5022207",
        "warmup_time": -1
    },
    "benchmarks.TimeConcat.time_concat": {
        "code": "class TimeConcat:\n    def time_concat(self, shapes, how, axis, ignore_index):\n        execute(\n            IMPL.concat(\n                [self.df1, self.df2], axis=axis, join=how, ignore_index=ignore_index\n            )\n        )\n\n    def setup(self, shapes, how, axis, ignore_index):\n        self.df1 = generate_dataframe(\"int\", *shapes[0], RAND_LOW, RAND_HIGH)\n        self.df2 = generate_dataframe(\"int\", *shapes[1], RAND_LOW, RAND_HIGH)",
        "min_run_count": 2,
        "name": "benchmarks.TimeConcat.time_concat",
        "number": 0,
        "param_names": [
            "shapes",
            "how",
            "axis",
            "ignore_index"
        ],
        "params": [
            [
                "[[5000, 5000], [5000, 5000]]",
                "[[500000, 20], [1000000, 10]]"
            ],
            [
                "'inner'",
                "'outer'"
            ],
            [
                "0",
                "1"
            ],
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "94bed16113bf2aeaaf75ac7229e0e7c5ef43059876eb31042216f20b06a91b9d",
        "warmup_time": -1
    },
    "benchmarks.TimeDescribe.time_describe": {
        "code": "class TimeDescribe:\n    def time_describe(self, shape):\n        execute(self.df.describe())\n\n    def setup(self, shape):\n        self.df = generate_dataframe(\"int\", *shape, RAND_LOW, RAND_HIGH)",
        "min_run_count": 2,
        "name": "benchmarks.TimeDescribe.time_describe",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "db36418a24bc669b3ad50485b9c4159f848815b6b06c88d049d3170395faa8ac",
        "warmup_time": -1
    },
    "benchmarks.TimeDrop.time_drop": {
        "code": "class TimeDrop:\n    def time_drop(self, shape, axis, drop_ncols):\n        execute(self.df.drop(self.labels, axis))\n\n    def setup(self, shape, axis, drop_ncols):\n        self.df = generate_dataframe(\"int\", *shape, RAND_LOW, RAND_HIGH)\n        drop_count = (\n            int(len(self.df.axes[axis]) * drop_ncols)\n            if isinstance(drop_ncols, float)\n            else drop_ncols\n        )\n        self.labels = self.df.axes[axis][:drop_count]",
        "min_run_count": 2,
        "name": "benchmarks.TimeDrop.time_drop",
        "number": 0,
        "param_names": [
            "shape",
            "axis",
            "drop_ncols"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "0",
                "1"
            ],
            [
                "1",
                "0.8"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "de0969a84145a34ea9d3553a746a8a21a980e750d413cdf2dcb75f39f0e676da",
        "warmup_time": -1
    },
    "benchmarks.TimeExplode.time_explode": {
        "code": "class TimeExplode:\n    def time_explode(self, shape):\n        execute(self.df.explode(\"col1\"))\n\n    def setup(self, shape):\n        self.df = generate_dataframe(\n            \"int\", *shape, RAND_LOW, RAND_HIGH, gen_unique_key=True\n        )",
        "min_run_count": 2,
        "name": "benchmarks.TimeExplode.time_explode",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "708b7d8afdc8d7914b044e26660b1a9279d6d9223b95a3d8153c494f2a432415",
        "warmup_time": -1
    },
    "benchmarks.TimeFillnaDataFrame.time_fillna": {
        "code": "class TimeFillnaDataFrame:\n    def time_fillna(self, value_type, shape, limit):\n        execute(self.df.fillna(**self.kw))\n\n    def setup(self, value_type, shape, limit):\n        self.df = gen_nan_data(*shape)\n        columns = self.df.columns\n    \n        if value_type == \"scalar\":\n            self.value = 18.19\n        elif value_type == \"dict\":\n            self.value = {k: i * 1.23 for i, k in enumerate(columns)}\n        elif value_type == \"Series\":\n            self.value = IMPL.Series(\n                [i * 1.23 for i in range(len(columns))], index=columns\n            )\n        elif value_type == \"DataFrame\":\n            self.value = IMPL.DataFrame(\n                {\n                    k: [i + j * 1.23 for j in range(shape[0])]\n                    for i, k in enumerate(columns)\n                },\n                index=IMPL.RangeIndex(shape[0]),\n                columns=columns,\n            )\n        else:\n            assert False\n        limit = int(limit * shape[0]) if limit else None\n        self.kw = {\"value\": self.value, \"limit\": limit}",
        "min_run_count": 2,
        "name": "benchmarks.TimeFillnaDataFrame.time_fillna",
        "number": 0,
        "param_names": [
            "value_type",
            "shape",
            "limit"
        ],
        "params": [
            [
                "'scalar'",
                "'dict'",
                "'DataFrame'",
                "'Series'"
            ],
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "None",
                "0.8"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "bf2bf93676bf51525b36b6729e159e634304706d41b92eac9eb3c26f7a0c3164",
        "warmup_time": -1
    },
    "benchmarks.TimeFillnaDataFrame.time_fillna_inplace": {
        "code": "class TimeFillnaDataFrame:\n    def time_fillna_inplace(self, value_type, shape, limit):\n        self.df.fillna(inplace=True, **self.kw)\n        execute(self.df)\n\n    def setup(self, value_type, shape, limit):\n        self.df = gen_nan_data(*shape)\n        columns = self.df.columns\n    \n        if value_type == \"scalar\":\n            self.value = 18.19\n        elif value_type == \"dict\":\n            self.value = {k: i * 1.23 for i, k in enumerate(columns)}\n        elif value_type == \"Series\":\n            self.value = IMPL.Series(\n                [i * 1.23 for i in range(len(columns))], index=columns\n            )\n        elif value_type == \"DataFrame\":\n            self.value = IMPL.DataFrame(\n                {\n                    k: [i + j * 1.23 for j in range(shape[0])]\n                    for i, k in enumerate(columns)\n                },\n                index=IMPL.RangeIndex(shape[0]),\n                columns=columns,\n            )\n        else:\n            assert False\n        limit = int(limit * shape[0]) if limit else None\n        self.kw = {\"value\": self.value, \"limit\": limit}",
        "min_run_count": 2,
        "name": "benchmarks.TimeFillnaDataFrame.time_fillna_inplace",
        "number": 0,
        "param_names": [
            "value_type",
            "shape",
            "limit"
        ],
        "params": [
            [
                "'scalar'",
                "'dict'",
                "'DataFrame'",
                "'Series'"
            ],
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "None",
                "0.8"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "16393d0848fd76f46bd911d404c58cd688ef16b49f7f06dc22b6132d3fe7f0ff",
        "warmup_time": -1
    },
    "benchmarks.TimeFillnaSeries.time_fillna": {
        "code": "class TimeFillnaSeries:\n    def time_fillna(self, value_type, shape, limit):\n        execute(self.series.fillna(**self.kw))\n\n    def setup(self, value_type, shape, limit):\n        self.series = gen_nan_data(*shape)\n    \n        if value_type == \"scalar\":\n            self.value = 18.19\n        elif value_type == \"dict\":\n            self.value = {k: k * 1.23 for k in range(shape[0])}\n        elif value_type == \"Series\":\n            self.value = IMPL.Series(\n                [k * 1.23 for k in range(shape[0])], index=IMPL.RangeIndex(shape[0])\n            )\n        else:\n            assert False\n        limit = int(limit * shape[0]) if limit else None\n        self.kw = {\"value\": self.value, \"limit\": limit}",
        "min_run_count": 2,
        "name": "benchmarks.TimeFillnaSeries.time_fillna",
        "number": 0,
        "param_names": [
            "value_type",
            "shape",
            "limit"
        ],
        "params": [
            [
                "'scalar'",
                "'dict'",
                "'Series'"
            ],
            [
                "[100000, 1]"
            ],
            [
                "None",
                "0.8"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "2982cfb0c23f7a314868429847ae6fd93c5c88b461cf55335370ca8f5f9f8a26",
        "warmup_time": -1
    },
    "benchmarks.TimeFillnaSeries.time_fillna_inplace": {
        "code": "class TimeFillnaSeries:\n    def time_fillna_inplace(self, value_type, shape, limit):\n        self.series.fillna(inplace=True, **self.kw)\n        execute(self.series)\n\n    def setup(self, value_type, shape, limit):\n        self.series = gen_nan_data(*shape)\n    \n        if value_type == \"scalar\":\n            self.value = 18.19\n        elif value_type == \"dict\":\n            self.value = {k: k * 1.23 for k in range(shape[0])}\n        elif value_type == \"Series\":\n            self.value = IMPL.Series(\n                [k * 1.23 for k in range(shape[0])], index=IMPL.RangeIndex(shape[0])\n            )\n        else:\n            assert False\n        limit = int(limit * shape[0]) if limit else None\n        self.kw = {\"value\": self.value, \"limit\": limit}",
        "min_run_count": 2,
        "name": "benchmarks.TimeFillnaSeries.time_fillna_inplace",
        "number": 0,
        "param_names": [
            "value_type",
            "shape",
            "limit"
        ],
        "params": [
            [
                "'scalar'",
                "'dict'",
                "'Series'"
            ],
            [
                "[100000, 1]"
            ],
            [
                "None",
                "0.8"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "1c66ad74b63b920014d634dee3f69422943c523a76571d1c66574e8eec3965fc",
        "warmup_time": -1
    },
    "benchmarks.TimeGroupByDefaultAggregations.time_groupby_count": {
        "code": "class TimeGroupByDefaultAggregations:\n    def time_groupby_count(self, *args, **kwargs):\n        execute(self.df.groupby(by=self.groupby_columns).count())\n\nclass BaseTimeGroupBy:\n    def setup(self, shape, ngroups=5, groupby_ncols=1):\n        ngroups = translator_groupby_ngroups(ngroups, shape)\n        self.df, self.groupby_columns = generate_dataframe(\n            \"int\",\n            *shape,\n            RAND_LOW,\n            RAND_HIGH,\n            groupby_ncols,\n            count_groups=ngroups,\n        )",
        "min_run_count": 2,
        "name": "benchmarks.TimeGroupByDefaultAggregations.time_groupby_count",
        "number": 0,
        "param_names": [
            "shape",
            "ngroups"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "100",
                "'huge_amount_groups'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f250d9b105ad86d7a1bb045eac1a69389dc8c1eef95236abbf0a7e2137b94b5a",
        "warmup_time": -1
    },
    "benchmarks.TimeGroupByDefaultAggregations.time_groupby_mean": {
        "code": "class TimeGroupByDefaultAggregations:\n    def time_groupby_mean(self, *args, **kwargs):\n        execute(self.df.groupby(by=self.groupby_columns).mean())\n\nclass BaseTimeGroupBy:\n    def setup(self, shape, ngroups=5, groupby_ncols=1):\n        ngroups = translator_groupby_ngroups(ngroups, shape)\n        self.df, self.groupby_columns = generate_dataframe(\n            \"int\",\n            *shape,\n            RAND_LOW,\n            RAND_HIGH,\n            groupby_ncols,\n            count_groups=ngroups,\n        )",
        "min_run_count": 2,
        "name": "benchmarks.TimeGroupByDefaultAggregations.time_groupby_mean",
        "number": 0,
        "param_names": [
            "shape",
            "ngroups"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "100",
                "'huge_amount_groups'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "760852f331ab3b357a78ec63bdadbafa063e1beeee7f3b6e711e49ebde083f6e",
        "warmup_time": -1
    },
    "benchmarks.TimeGroupByDefaultAggregations.time_groupby_size": {
        "code": "class TimeGroupByDefaultAggregations:\n    def time_groupby_size(self, *args, **kwargs):\n        execute(self.df.groupby(by=self.groupby_columns).size())\n\nclass BaseTimeGroupBy:\n    def setup(self, shape, ngroups=5, groupby_ncols=1):\n        ngroups = translator_groupby_ngroups(ngroups, shape)\n        self.df, self.groupby_columns = generate_dataframe(\n            \"int\",\n            *shape,\n            RAND_LOW,\n            RAND_HIGH,\n            groupby_ncols,\n            count_groups=ngroups,\n        )",
        "min_run_count": 2,
        "name": "benchmarks.TimeGroupByDefaultAggregations.time_groupby_size",
        "number": 0,
        "param_names": [
            "shape",
            "ngroups"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "100",
                "'huge_amount_groups'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "865ef126430f4c7a05109aabbcfdebd321debe09daed389b3b35f69af1ebf88b",
        "warmup_time": -1
    },
    "benchmarks.TimeGroupByDefaultAggregations.time_groupby_sum": {
        "code": "class TimeGroupByDefaultAggregations:\n    def time_groupby_sum(self, *args, **kwargs):\n        execute(self.df.groupby(by=self.groupby_columns).sum())\n\nclass BaseTimeGroupBy:\n    def setup(self, shape, ngroups=5, groupby_ncols=1):\n        ngroups = translator_groupby_ngroups(ngroups, shape)\n        self.df, self.groupby_columns = generate_dataframe(\n            \"int\",\n            *shape,\n            RAND_LOW,\n            RAND_HIGH,\n            groupby_ncols,\n            count_groups=ngroups,\n        )",
        "min_run_count": 2,
        "name": "benchmarks.TimeGroupByDefaultAggregations.time_groupby_sum",
        "number": 0,
        "param_names": [
            "shape",
            "ngroups"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "100",
                "'huge_amount_groups'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "020a36df139e48f3928773be707aaa39723da40bd17deb6ff029fe697ca2fb72",
        "warmup_time": -1
    },
    "benchmarks.TimeGroupByDictionaryAggregation.time_groupby_dict_agg": {
        "code": "class TimeGroupByDictionaryAggregation:\n    def time_groupby_dict_agg(self, *args, **kwargs):\n        execute(self.df.groupby(by=self.groupby_columns).agg(self.agg_dict))\n\n    def setup(self, shape, ngroups, operation_type):\n        super().setup(shape, ngroups)\n        self.cols_to_agg = self.df.columns[1:4]\n        operations = self.operations[operation_type]\n        self.agg_dict = {\n            c: operations[i % len(operations)] for i, c in enumerate(self.cols_to_agg)\n        }",
        "min_run_count": 2,
        "name": "benchmarks.TimeGroupByDictionaryAggregation.time_groupby_dict_agg",
        "number": 0,
        "param_names": [
            "shape",
            "ngroups",
            "operation_type"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "100",
                "'huge_amount_groups'"
            ],
            [
                "'reduce'",
                "'aggregation'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "7aa41865cba30449bba2f4d9a40fe5d15e9d9b4c2c737222bd2a643fd6dcb39a",
        "warmup_time": -1
    },
    "benchmarks.TimeGroupByMultiColumn.time_groupby_agg_mean": {
        "code": "class TimeGroupByMultiColumn:\n    def time_groupby_agg_mean(self, *args, **kwargs):\n        execute(self.df.groupby(by=self.groupby_columns).apply(lambda df: df.mean()))\n\nclass BaseTimeGroupBy:\n    def setup(self, shape, ngroups=5, groupby_ncols=1):\n        ngroups = translator_groupby_ngroups(ngroups, shape)\n        self.df, self.groupby_columns = generate_dataframe(\n            \"int\",\n            *shape,\n            RAND_LOW,\n            RAND_HIGH,\n            groupby_ncols,\n            count_groups=ngroups,\n        )",
        "min_run_count": 2,
        "name": "benchmarks.TimeGroupByMultiColumn.time_groupby_agg_mean",
        "number": 0,
        "param_names": [
            "shape",
            "ngroups",
            "groupby_ncols"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "100",
                "'huge_amount_groups'"
            ],
            [
                "6"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f64c1d90b08de31c657dc91de4d1cca00894219a11383e588b8ae326c93ac45f",
        "warmup_time": -1
    },
    "benchmarks.TimeGroupByMultiColumn.time_groupby_agg_quan": {
        "code": "class TimeGroupByMultiColumn:\n    def time_groupby_agg_quan(self, *args, **kwargs):\n        execute(self.df.groupby(by=self.groupby_columns).agg(\"quantile\"))\n\nclass BaseTimeGroupBy:\n    def setup(self, shape, ngroups=5, groupby_ncols=1):\n        ngroups = translator_groupby_ngroups(ngroups, shape)\n        self.df, self.groupby_columns = generate_dataframe(\n            \"int\",\n            *shape,\n            RAND_LOW,\n            RAND_HIGH,\n            groupby_ncols,\n            count_groups=ngroups,\n        )",
        "min_run_count": 2,
        "name": "benchmarks.TimeGroupByMultiColumn.time_groupby_agg_quan",
        "number": 0,
        "param_names": [
            "shape",
            "ngroups",
            "groupby_ncols"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "100",
                "'huge_amount_groups'"
            ],
            [
                "6"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "8bc16b09cfcbc8b405c8c61b9baa5f8ebcdaa66648012f1e6c4eca6ae1e80898",
        "warmup_time": -1
    },
    "benchmarks.TimeHead.time_head": {
        "code": "class TimeHead:\n    def time_head(self, shape, head_count):\n        execute(self.df.head(self.head_count))\n\n    def setup(self, shape, head_count):\n        self.df = generate_dataframe(\"int\", *shape, RAND_LOW, RAND_HIGH)\n        self.head_count = (\n            int(head_count * len(self.df.index))\n            if isinstance(head_count, float)\n            else head_count\n        )",
        "min_run_count": 2,
        "name": "benchmarks.TimeHead.time_head",
        "number": 0,
        "param_names": [
            "shape",
            "head_count"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "5",
                "0.8"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "a07ff54942f5f3f1cc4351611ca96ad5a2420ae330924ca9f6cb490ce6bb2a6f",
        "warmup_time": -1
    },
    "benchmarks.TimeIndexing.time_iloc": {
        "code": "class TimeIndexing:\n    def time_iloc(self, shape, indexer_type):\n        # Pandas doesn't implement `df.iloc[series boolean_mask]` and raises an exception on it.\n        # Replacing this with the semantically equivalent construction:\n        if indexer_type != \"bool_series\":\n            execute(self.df.iloc[self.indexer])\n        else:\n            execute(self.df[self.indexer])\n\n    def setup(self, shape, indexer_type):\n        self.df = generate_dataframe(\"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df)\n    \n        self.indexer = self.indexer_getters[indexer_type](self.df)\n        if isinstance(self.indexer, (IMPL.Series, IMPL.DataFrame)):\n            # HACK: Triggering `dtypes` meta-data computation in advance,\n            # so it won't affect the `loc/iloc` time:\n            self.indexer.dtypes",
        "min_run_count": 2,
        "name": "benchmarks.TimeIndexing.time_iloc",
        "number": 0,
        "param_names": [
            "shape",
            "indexer_type"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "'bool_array'",
                "'bool_series'",
                "'scalar'",
                "'slice'",
                "'continuous_slice'",
                "'numpy_array_take_all_values'",
                "'python_list_take_10_values'",
                "'function'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "7b73f9643fa771d31cbaccfd55da0c6b6d8b7f67f2252ba5f17ed73350a54288",
        "warmup_time": -1
    },
    "benchmarks.TimeIndexing.time_loc": {
        "code": "class TimeIndexing:\n    def time_loc(self, shape, indexer_type):\n        execute(self.df.loc[self.indexer])\n\n    def setup(self, shape, indexer_type):\n        self.df = generate_dataframe(\"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df)\n    \n        self.indexer = self.indexer_getters[indexer_type](self.df)\n        if isinstance(self.indexer, (IMPL.Series, IMPL.DataFrame)):\n            # HACK: Triggering `dtypes` meta-data computation in advance,\n            # so it won't affect the `loc/iloc` time:\n            self.indexer.dtypes",
        "min_run_count": 2,
        "name": "benchmarks.TimeIndexing.time_loc",
        "number": 0,
        "param_names": [
            "shape",
            "indexer_type"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "'bool_array'",
                "'bool_series'",
                "'scalar'",
                "'slice'",
                "'continuous_slice'",
                "'numpy_array_take_all_values'",
                "'python_list_take_10_values'",
                "'function'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "822e648264a13f7e22816c17b42e9d47753fbcb058fcd3885ec93872245c4290",
        "warmup_time": -1
    },
    "benchmarks.TimeIndexingColumns.time___getitem__": {
        "code": "class TimeIndexingColumns:\n    def time___getitem__(self, shape):\n        execute(self.df[self.labels_indexer])\n\n    def setup(self, shape):\n        self.df = generate_dataframe(\"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df)\n        self.numeric_indexer = [0, 1]\n        self.labels_indexer = self.df.columns[self.numeric_indexer].tolist()",
        "min_run_count": 2,
        "name": "benchmarks.TimeIndexingColumns.time___getitem__",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "6fa82daf47b740e60aad7b96fd846c6a92b09b84143fc302aef64690219c9b35",
        "warmup_time": -1
    },
    "benchmarks.TimeIndexingColumns.time_iloc": {
        "code": "class TimeIndexingColumns:\n    def time_iloc(self, shape):\n        execute(self.df.iloc[:, self.numeric_indexer])\n\n    def setup(self, shape):\n        self.df = generate_dataframe(\"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df)\n        self.numeric_indexer = [0, 1]\n        self.labels_indexer = self.df.columns[self.numeric_indexer].tolist()",
        "min_run_count": 2,
        "name": "benchmarks.TimeIndexingColumns.time_iloc",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "5bb0aafeffe2a1aeb522c1fd1d12dd0e71c4b31ede8e2b6eff891ef79a0af478",
        "warmup_time": -1
    },
    "benchmarks.TimeIndexingColumns.time_loc": {
        "code": "class TimeIndexingColumns:\n    def time_loc(self, shape):\n        execute(self.df.loc[:, self.labels_indexer])\n\n    def setup(self, shape):\n        self.df = generate_dataframe(\"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df)\n        self.numeric_indexer = [0, 1]\n        self.labels_indexer = self.df.columns[self.numeric_indexer].tolist()",
        "min_run_count": 2,
        "name": "benchmarks.TimeIndexingColumns.time_loc",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b4304883d436bf17c07ce9b7ff3e7ff1cda770f40a7860d94de51f65d417717f",
        "warmup_time": -1
    },
    "benchmarks.TimeInsert.time_insert_qc": {
        "code": "class TimeInsert:\n    def time_insert_qc(self, *args, **kwargs):\n        self.df.insert(loc=self.iloc, column=random_string(), value=self.item)\n        execute(self.df)\n\nclass BaseTimeSetItem:\n    def setup(self, shape, item_length, loc, is_equal_indices):\n        self.df = generate_dataframe(\"int\", *shape, RAND_LOW, RAND_HIGH).copy()\n        self.loc, self.iloc = self.get_loc(\n            self.df, loc, item_length=item_length, axis=1\n        )\n    \n        self.item = self.df[self.loc] + 1\n        self.item_raw = self.item.to_numpy()\n        if not is_equal_indices:\n            self.item.index = reversed(self.item.index)",
        "min_run_count": 2,
        "name": "benchmarks.TimeInsert.time_insert_qc",
        "number": 0,
        "param_names": [
            "shape",
            "item_length",
            "loc",
            "is_equal_indices"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "1"
            ],
            [
                "'zero'",
                "'middle'",
                "'last'"
            ],
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "11cd3415659a7fe96544fd56885335a0d9f62fb6c22fa92600c35ab3c06b530d",
        "warmup_time": -1
    },
    "benchmarks.TimeInsert.time_insert_raw": {
        "code": "class TimeInsert:\n    def time_insert_raw(self, *args, **kwargs):\n        self.df.insert(loc=self.iloc, column=random_string(), value=self.item_raw)\n        execute(self.df)\n\nclass BaseTimeSetItem:\n    def setup(self, shape, item_length, loc, is_equal_indices):\n        self.df = generate_dataframe(\"int\", *shape, RAND_LOW, RAND_HIGH).copy()\n        self.loc, self.iloc = self.get_loc(\n            self.df, loc, item_length=item_length, axis=1\n        )\n    \n        self.item = self.df[self.loc] + 1\n        self.item_raw = self.item.to_numpy()\n        if not is_equal_indices:\n            self.item.index = reversed(self.item.index)",
        "min_run_count": 2,
        "name": "benchmarks.TimeInsert.time_insert_raw",
        "number": 0,
        "param_names": [
            "shape",
            "item_length",
            "loc",
            "is_equal_indices"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "1"
            ],
            [
                "'zero'",
                "'middle'",
                "'last'"
            ],
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "2f18a3c582775030c1760504d6527ff75e9f595438e6bf73dc98b18f452ebf1e",
        "warmup_time": -1
    },
    "benchmarks.TimeJoin.time_join": {
        "code": "class TimeJoin:\n    def time_join(self, shapes, how, sort):\n        # join dataframes on index to get the predictable shape\n        execute(self.df1.join(self.df2, how=how, lsuffix=\"left_\", sort=sort))\n\n    def setup(self, shapes, how, sort):\n        self.df1 = generate_dataframe(\"int\", *shapes[0], RAND_LOW, RAND_HIGH)\n        self.df2 = generate_dataframe(\"int\", *shapes[1], RAND_LOW, RAND_HIGH)",
        "min_run_count": 2,
        "name": "benchmarks.TimeJoin.time_join",
        "number": 0,
        "param_names": [
            "shapes",
            "how",
            "sort"
        ],
        "params": [
            [
                "[[5000, 5000], [5000, 5000]]",
                "[[500000, 20], [1000000, 10]]"
            ],
            [
                "'left'",
                "'inner'"
            ],
            [
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "a4334177a289165853ea4d6b94f526b95359f1d16c46e145c02f836d6f3d84ac",
        "warmup_time": -1
    },
    "benchmarks.TimeMerge.time_merge": {
        "code": "class TimeMerge:\n    def time_merge(self, shapes, how, sort):\n        # merge dataframes by index to get the predictable shape\n        execute(\n            self.df1.merge(\n                self.df2, left_index=True, right_index=True, how=how, sort=sort\n            )\n        )\n\n    def setup(self, shapes, how, sort):\n        self.df1 = generate_dataframe(\"int\", *shapes[0], RAND_LOW, RAND_HIGH)\n        self.df2 = generate_dataframe(\"int\", *shapes[1], RAND_LOW, RAND_HIGH)",
        "min_run_count": 2,
        "name": "benchmarks.TimeMerge.time_merge",
        "number": 0,
        "param_names": [
            "shapes",
            "how",
            "sort"
        ],
        "params": [
            [
                "[[5000, 5000], [5000, 5000]]",
                "[[500000, 20], [1000000, 10]]"
            ],
            [
                "'left'",
                "'inner'"
            ],
            [
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "e5ab191558a6c2d17298fcc42734dcba1b02fe6fe925ccf6cd5267813f99ba73",
        "warmup_time": -1
    },
    "benchmarks.TimeMultiIndexing.time_multiindex_loc": {
        "code": "class TimeMultiIndexing:\n    def time_multiindex_loc(self, shape):\n        execute(\n            self.df.loc[\n                self.df.index[2] : self.df.index[-2],\n                self.df.columns[2] : self.df.columns[-2],\n            ]\n        )\n\n    def setup(self, shape):\n        df = generate_dataframe(\"int\", *shape, RAND_LOW, RAND_HIGH)\n    \n        index = IMPL.MultiIndex.from_product(\n            [df.index[: shape[0] // 2], [\"bar\", \"foo\"]]\n        )\n        columns = IMPL.MultiIndex.from_product(\n            [df.columns[: shape[1] // 2], [\"buz\", \"fuz\"]]\n        )\n    \n        df.index = index\n        df.columns = columns\n    \n        self.df = df.sort_index(axis=1)",
        "min_run_count": 2,
        "name": "benchmarks.TimeMultiIndexing.time_multiindex_loc",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "80db4e5589d4903dd84bc23b5a924d9a65cd94e8f69e33974510be9b44ef1e1b",
        "warmup_time": -1
    },
    "benchmarks.TimeProperties.time_columns": {
        "code": "class TimeProperties:\n    def time_columns(self, shape):\n        return self.df.columns\n\n    def setup(self, shape):\n        self.df = generate_dataframe(\"int\", *shape, RAND_LOW, RAND_HIGH)",
        "min_run_count": 2,
        "name": "benchmarks.TimeProperties.time_columns",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "80367e0e463c2a60f8992cd1852cb9dbf3023a9a61ee2a222c4f4be5c9e745ef",
        "warmup_time": -1
    },
    "benchmarks.TimeProperties.time_index": {
        "code": "class TimeProperties:\n    def time_index(self, shape):\n        return self.df.index\n\n    def setup(self, shape):\n        self.df = generate_dataframe(\"int\", *shape, RAND_LOW, RAND_HIGH)",
        "min_run_count": 2,
        "name": "benchmarks.TimeProperties.time_index",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "4032fae09062e1cc662cc50bc8e4dccdd5ec517ba1106e1e3e018178dd2e005e",
        "warmup_time": -1
    },
    "benchmarks.TimeProperties.time_shape": {
        "code": "class TimeProperties:\n    def time_shape(self, shape):\n        return self.df.shape\n\n    def setup(self, shape):\n        self.df = generate_dataframe(\"int\", *shape, RAND_LOW, RAND_HIGH)",
        "min_run_count": 2,
        "name": "benchmarks.TimeProperties.time_shape",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "82b286680f2e15afc4c9ec8c4e602c3ecd7b5a10cf9e7ae9f791b4617b4c7d0b",
        "warmup_time": -1
    },
    "benchmarks.TimeResetIndex.time_reset_index": {
        "code": "class TimeResetIndex:\n    def time_reset_index(self, shape, drop, level):\n        execute(self.df.reset_index(drop=drop, level=level))\n\n    def setup(self, shape, drop, level):\n        self.df = generate_dataframe(\"int\", *shape, RAND_LOW, RAND_HIGH)\n    \n        if level:\n            index = IMPL.MultiIndex.from_product(\n                [self.df.index[: shape[0] // 2], [\"bar\", \"foo\"]],\n                names=[\"level_1\", \"level_2\"],\n            )\n            self.df.index = index",
        "min_run_count": 2,
        "name": "benchmarks.TimeResetIndex.time_reset_index",
        "number": 0,
        "param_names": [
            "shape",
            "drop",
            "level"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "False",
                "True"
            ],
            [
                "None",
                "'level_1'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "ec9603a01ff9bea8b5b38323cacc3f34f85205386817f13afe6d8ae56bcfb88c",
        "warmup_time": -1
    },
    "benchmarks.TimeSetItem.time_setitem_qc": {
        "code": "class TimeSetItem:\n    def time_setitem_qc(self, *args, **kwargs):\n        self.df[self.loc] = self.item\n        execute(self.df)\n\nclass BaseTimeSetItem:\n    def setup(self, shape, item_length, loc, is_equal_indices):\n        self.df = generate_dataframe(\"int\", *shape, RAND_LOW, RAND_HIGH).copy()\n        self.loc, self.iloc = self.get_loc(\n            self.df, loc, item_length=item_length, axis=1\n        )\n    \n        self.item = self.df[self.loc] + 1\n        self.item_raw = self.item.to_numpy()\n        if not is_equal_indices:\n            self.item.index = reversed(self.item.index)",
        "min_run_count": 2,
        "name": "benchmarks.TimeSetItem.time_setitem_qc",
        "number": 0,
        "param_names": [
            "shape",
            "item_length",
            "loc",
            "is_equal_indices"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "1"
            ],
            [
                "'zero'",
                "'middle'",
                "'last'"
            ],
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f49bbde4ab4bf24d0639b2d7ead348135baec12a7c7afcc1aa9878aae51715fc",
        "warmup_time": -1
    },
    "benchmarks.TimeSetItem.time_setitem_raw": {
        "code": "class TimeSetItem:\n    def time_setitem_raw(self, *args, **kwargs):\n        self.df[self.loc] = self.item_raw\n        execute(self.df)\n\nclass BaseTimeSetItem:\n    def setup(self, shape, item_length, loc, is_equal_indices):\n        self.df = generate_dataframe(\"int\", *shape, RAND_LOW, RAND_HIGH).copy()\n        self.loc, self.iloc = self.get_loc(\n            self.df, loc, item_length=item_length, axis=1\n        )\n    \n        self.item = self.df[self.loc] + 1\n        self.item_raw = self.item.to_numpy()\n        if not is_equal_indices:\n            self.item.index = reversed(self.item.index)",
        "min_run_count": 2,
        "name": "benchmarks.TimeSetItem.time_setitem_raw",
        "number": 0,
        "param_names": [
            "shape",
            "item_length",
            "loc",
            "is_equal_indices"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "1"
            ],
            [
                "'zero'",
                "'middle'",
                "'last'"
            ],
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "906c002eff986629d58c530931a533e7a7028cf8c56e37ab004dcec4da30176e",
        "warmup_time": -1
    },
    "benchmarks.TimeSortValues.time_sort_values": {
        "code": "class TimeSortValues:\n    def time_sort_values(self, shape, columns_number, ascending_list):\n        execute(self.df.sort_values(self.columns, ascending=self.ascending))\n\n    def setup(self, shape, columns_number, ascending_list):\n        self.df = generate_dataframe(\"int\", *shape, RAND_LOW, RAND_HIGH)\n        self.columns = random_columns(self.df.columns, columns_number)\n        self.ascending = (\n            random_booleans(columns_number)\n            if ascending_list\n            else bool(random_booleans(1)[0])\n        )",
        "min_run_count": 2,
        "name": "benchmarks.TimeSortValues.time_sort_values",
        "number": 0,
        "param_names": [
            "shape",
            "columns_number",
            "ascending_list"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "1",
                "2",
                "10",
                "100"
            ],
            [
                "False",
                "True"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "aa45dc6d849b886fa0745e0fe95e463c97aa2df6cb8d19c5b112423080434000",
        "warmup_time": -1
    },
    "benchmarks.TimeTail.time_tail": {
        "code": "class TimeTail:\n    def time_tail(self, shape, tail_count):\n        execute(self.df.tail(self.tail_count))\n\n    def setup(self, shape, tail_count):\n        self.df = generate_dataframe(\"int\", *shape, RAND_LOW, RAND_HIGH)\n        self.tail_count = (\n            int(tail_count * len(self.df.index))\n            if isinstance(tail_count, float)\n            else tail_count\n        )",
        "min_run_count": 2,
        "name": "benchmarks.TimeTail.time_tail",
        "number": 0,
        "param_names": [
            "shape",
            "tail_count"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "5",
                "0.8"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "74f045577695d482eebead7a9b5322e4e2a3b315687e4c27c7d343fa3d52a83c",
        "warmup_time": -1
    },
    "benchmarks.TimeValueCountsFrame.time_value_counts": {
        "code": "class TimeValueCountsFrame:\n    def time_value_counts(self, *args, **kwargs):\n        execute(self.df.value_counts(subset=self.subset))\n\nclass BaseTimeValueCounts:\n    def setup(self, shape, ngroups=5, subset=1):\n        ngroups = translator_groupby_ngroups(ngroups, shape)\n        self.df, self.subset = generate_dataframe(\n            \"int\",\n            *shape,\n            RAND_LOW,\n            RAND_HIGH,\n            groupby_ncols=subset,\n            count_groups=ngroups,\n        )",
        "min_run_count": 2,
        "name": "benchmarks.TimeValueCountsFrame.time_value_counts",
        "number": 0,
        "param_names": [
            "shape",
            "ngroups",
            "subset"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "100",
                "'huge_amount_groups'"
            ],
            [
                "2",
                "10"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "e614afefccd7b09a063559da691b0fc2becc8c466aecbbdd617c3337f18efbea",
        "warmup_time": -1
    },
    "benchmarks.TimeValueCountsSeries.time_value_counts": {
        "code": "class TimeValueCountsSeries:\n    def time_value_counts(self, shape, ngroups, bins):\n        execute(self.df.value_counts(bins=bins))\n\n    def setup(self, shape, ngroups, bins):\n        super().setup(ngroups=ngroups, shape=shape)\n        self.df = self.df[self.subset[0]]",
        "min_run_count": 2,
        "name": "benchmarks.TimeValueCountsSeries.time_value_counts",
        "number": 0,
        "param_names": [
            "shape",
            "ngroups",
            "bins"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "100",
                "'huge_amount_groups'"
            ],
            [
                "None",
                "3"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "161a0ca50c23d2aadc9c3fc29d46e3cd4699d4354b8a8b752b6d17f67e924a85",
        "warmup_time": -1
    },
    "hdk.benchmarks.TimeAppend.time_append": {
        "code": "class TimeAppend:\n    def time_append(self, shapes):\n        execute(self.df1.append(self.df2))\n\n    def setup(self, shapes):\n        self.df1, self.df2 = (\n            generate_dataframe(\n                \"int\",\n                *shape,\n                RAND_LOW,\n                RAND_HIGH,\n                cache_prefix=f\"{i}-th_frame_to_append\",\n            )\n            for i, shape in enumerate(shapes)\n        )\n        trigger_import(self.df1, self.df2)",
        "min_run_count": 2,
        "name": "hdk.benchmarks.TimeAppend.time_append",
        "number": 0,
        "param_names": [
            "shapes"
        ],
        "params": [
            [
                "[[500000, 20], [1000000, 10]]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "3d56626993f30d99b372ec1d74e334aa724b4f3174b13064bc8bf0e2b4e37f95",
        "warmup_time": -1
    },
    "hdk.benchmarks.TimeArithmetic.time_apply": {
        "code": "class TimeArithmetic:\n    def time_apply(self, shape):\n        execute(self.df.apply(lambda df: df.sum()))\n\n    def setup(self, shape):\n        self.df = generate_dataframe(\"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df)",
        "min_run_count": 2,
        "name": "hdk.benchmarks.TimeArithmetic.time_apply",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "5c06eea1bfff38877c7a94b785db324baef0568536b6fe22e33bcaa1c2fc1350",
        "warmup_time": -1
    },
    "hdk.benchmarks.TimeArithmetic.time_mean": {
        "code": "class TimeArithmetic:\n    def time_mean(self, shape):\n        execute(self.df.mean())\n\n    def setup(self, shape):\n        self.df = generate_dataframe(\"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df)",
        "min_run_count": 2,
        "name": "hdk.benchmarks.TimeArithmetic.time_mean",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b5932abebe92ec18c2b2845f2dad0d12ef3aabc43c5e859cbf3c1eec3fd2cace",
        "warmup_time": -1
    },
    "hdk.benchmarks.TimeArithmetic.time_median": {
        "code": "class TimeArithmetic:\n    def time_median(self, shape):\n        execute(self.df.median())\n\n    def setup(self, shape):\n        self.df = generate_dataframe(\"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df)",
        "min_run_count": 2,
        "name": "hdk.benchmarks.TimeArithmetic.time_median",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "4be907522d1c862af3f732f4c51aea9ba6f0da113da694c1eda09f6e2d4d6f6d",
        "warmup_time": -1
    },
    "hdk.benchmarks.TimeArithmetic.time_nunique": {
        "code": "class TimeArithmetic:\n    def time_nunique(self, shape):\n        execute(self.df.nunique())\n\n    def setup(self, shape):\n        self.df = generate_dataframe(\"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df)",
        "min_run_count": 2,
        "name": "hdk.benchmarks.TimeArithmetic.time_nunique",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "4c2982f7aa48c80b57ca274631524e49c76a539b0f3066cac8008cdbb2802196",
        "warmup_time": -1
    },
    "hdk.benchmarks.TimeArithmetic.time_sum": {
        "code": "class TimeArithmetic:\n    def time_sum(self, shape):\n        execute(self.df.sum())\n\n    def setup(self, shape):\n        self.df = generate_dataframe(\"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df)",
        "min_run_count": 2,
        "name": "hdk.benchmarks.TimeArithmetic.time_sum",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "bc189635d3fe40bc8cadc7f5c21988ffb9c4619a083fb4c1c709868f4ea8add9",
        "warmup_time": -1
    },
    "hdk.benchmarks.TimeAstype.time_astype": {
        "code": "class TimeAstype:\n    def time_astype(self, shape, dtype, astype_ncolumns):\n        execute(self.df.astype(self.astype_arg))\n\n    def setup(self, shape, dtype, astype_ncolumns):\n        self.df = generate_dataframe(\"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df)\n        self.astype_arg = self.create_astype_arg(dtype, astype_ncolumns)",
        "min_run_count": 2,
        "name": "hdk.benchmarks.TimeAstype.time_astype",
        "number": 0,
        "param_names": [
            "shape",
            "dtype",
            "astype_ncolumns"
        ],
        "params": [
            [
                "[1000000, 10]"
            ],
            [
                "'float64'"
            ],
            [
                "'one'",
                "'all'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "9c491a3703315c203c25d58d0ef8623b2d8f308f628538543f5b6661486e71f9",
        "warmup_time": -1
    },
    "hdk.benchmarks.TimeBinaryOpDataFrame.time_mul_dataframes": {
        "code": "class TimeBinaryOpDataFrame:\n    def time_mul_dataframes(self, shape, binary_op):\n        execute(self.op(self.df1))\n\n    def setup(self, shape, binary_op):\n        self.df1 = generate_dataframe(\"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df1)\n        self.op = getattr(self.df1, binary_op)",
        "min_run_count": 2,
        "name": "hdk.benchmarks.TimeBinaryOpDataFrame.time_mul_dataframes",
        "number": 0,
        "param_names": [
            "shape",
            "binary_op"
        ],
        "params": [
            [
                "[1000000, 10]"
            ],
            [
                "'mul'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "81baa78efbdc45bf02538ea22218bf33cfc52b6f41d7c01720a969fd988297e1",
        "warmup_time": -1
    },
    "hdk.benchmarks.TimeBinaryOpDataFrame.time_mul_scalar": {
        "code": "class TimeBinaryOpDataFrame:\n    def time_mul_scalar(self, shape, binary_op):\n        execute(self.op(2))\n\n    def setup(self, shape, binary_op):\n        self.df1 = generate_dataframe(\"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df1)\n        self.op = getattr(self.df1, binary_op)",
        "min_run_count": 2,
        "name": "hdk.benchmarks.TimeBinaryOpDataFrame.time_mul_scalar",
        "number": 0,
        "param_names": [
            "shape",
            "binary_op"
        ],
        "params": [
            [
                "[1000000, 10]"
            ],
            [
                "'mul'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "d7edfdde93db03c9df899f4d268bca8997418dd5df67f0ac2000955d705c3c2e",
        "warmup_time": -1
    },
    "hdk.benchmarks.TimeBinaryOpSeries.time_mul_series": {
        "code": "class TimeBinaryOpSeries:\n    def time_mul_series(self, shape, binary_op):\n        execute(self.op(self.series))\n\n    def setup(self, shape, binary_op):\n        self.series = generate_dataframe(\"int\", *shape, RAND_LOW, RAND_HIGH)[\"col0\"]\n        trigger_import(self.series)\n        self.op = getattr(self.series, binary_op)",
        "min_run_count": 2,
        "name": "hdk.benchmarks.TimeBinaryOpSeries.time_mul_series",
        "number": 0,
        "param_names": [
            "shape",
            "binary_op"
        ],
        "params": [
            [
                "[10000000, 1]"
            ],
            [
                "'mul'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "e90b9091848a468d0e25be32398226b0be07c94c0741cc20a192bad271ec06da",
        "warmup_time": -1
    },
    "hdk.benchmarks.TimeDescribe.time_describe": {
        "code": "class TimeDescribe:\n    def time_describe(self, shape):\n        execute(self.df.describe())\n\n    def setup(self, shape):\n        self.df = generate_dataframe(\"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df)",
        "min_run_count": 2,
        "name": "hdk.benchmarks.TimeDescribe.time_describe",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "7f4a6c93dc4546fff3a32c451246cb29727f9cc27a3029df68c54f1c30528b06",
        "warmup_time": -1
    },
    "hdk.benchmarks.TimeDrop.time_drop": {
        "code": "class TimeDrop:\n    def time_drop(self, shape, drop_ncols):\n        execute(self.df.drop(self.labels, axis=1))\n\n    def setup(self, shape, drop_ncols):\n        self.df = generate_dataframe(\"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df)\n        drop_count = (\n            int(len(self.df.axes[1]) * drop_ncols)\n            if isinstance(drop_ncols, float)\n            else drop_ncols\n        )\n        self.labels = self.df.axes[1][:drop_count]",
        "min_run_count": 2,
        "name": "hdk.benchmarks.TimeDrop.time_drop",
        "number": 0,
        "param_names": [
            "shape",
            "drop_ncols"
        ],
        "params": [
            [
                "[1000000, 10]"
            ],
            [
                "1",
                "0.8"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "6c029b580c3c1b3127bf16edb1c652e9c68b1b98f27737035ba6d05b67debc6d",
        "warmup_time": -1
    },
    "hdk.benchmarks.TimeFillna.time_fillna": {
        "code": "class TimeFillna:\n    def time_fillna(self, value_type, shape, limit):\n        execute(self.df.fillna(**self.kw))\n\n    def setup(self, value_type, shape, limit):\n        self.df = gen_nan_data(*shape)\n        columns = self.df.columns\n        trigger_import(self.df)\n    \n        value = self.create_fillna_value(value_type, columns)\n        limit = int(limit * shape[0]) if limit else None\n        self.kw = {\"value\": value, \"limit\": limit}",
        "min_run_count": 2,
        "name": "hdk.benchmarks.TimeFillna.time_fillna",
        "number": 0,
        "param_names": [
            "value_type",
            "shape",
            "limit"
        ],
        "params": [
            [
                "'scalar'",
                "'dict'"
            ],
            [
                "[1000000, 10]"
            ],
            [
                "None"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "cec49e9f2ea305342be06a191ed412dec0ec0d71531ad452e00cfdcbe5c473c5",
        "warmup_time": -1
    },
    "hdk.benchmarks.TimeGroupByDefaultAggregations.time_groupby_count": {
        "code": "class TimeGroupByDefaultAggregations:\n    def time_groupby_count(self, *args, **kwargs):\n        execute(self.df.groupby(by=self.groupby_columns).count())\n\nclass BaseTimeGroupBy:\n    def setup(self, shape, ngroups=5, groupby_ncols=1):\n        ngroups = translator_groupby_ngroups(ngroups, shape)\n        self.df, self.groupby_columns = generate_dataframe(\n            \"int\",\n            *shape,\n            RAND_LOW,\n            RAND_HIGH,\n            groupby_ncols,\n            count_groups=ngroups,\n        )\n        # correct while we use 'col*' like name for non-groupby columns\n        # and 'groupby_col*' like name for groupby columns\n        self.non_groupby_columns = self.df.columns[:-groupby_ncols]\n        trigger_import(self.df)",
        "min_run_count": 2,
        "name": "hdk.benchmarks.TimeGroupByDefaultAggregations.time_groupby_count",
        "number": 0,
        "param_names": [
            "shape",
            "ngroups"
        ],
        "params": [
            [
                "[1000000, 10]"
            ],
            [
                "100",
                "'huge_amount_groups'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "15914b0be23e820273cec1b62dcdb6fa54322cb33c3c4ac749f237bdd0cc5527",
        "warmup_time": -1
    },
    "hdk.benchmarks.TimeGroupByDefaultAggregations.time_groupby_sum": {
        "code": "class TimeGroupByDefaultAggregations:\n    def time_groupby_sum(self, *args, **kwargs):\n        execute(self.df.groupby(by=self.groupby_columns).sum())\n\nclass BaseTimeGroupBy:\n    def setup(self, shape, ngroups=5, groupby_ncols=1):\n        ngroups = translator_groupby_ngroups(ngroups, shape)\n        self.df, self.groupby_columns = generate_dataframe(\n            \"int\",\n            *shape,\n            RAND_LOW,\n            RAND_HIGH,\n            groupby_ncols,\n            count_groups=ngroups,\n        )\n        # correct while we use 'col*' like name for non-groupby columns\n        # and 'groupby_col*' like name for groupby columns\n        self.non_groupby_columns = self.df.columns[:-groupby_ncols]\n        trigger_import(self.df)",
        "min_run_count": 2,
        "name": "hdk.benchmarks.TimeGroupByDefaultAggregations.time_groupby_sum",
        "number": 0,
        "param_names": [
            "shape",
            "ngroups"
        ],
        "params": [
            [
                "[1000000, 10]"
            ],
            [
                "100",
                "'huge_amount_groups'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "121c334f6e5244634d9ef10f2332b4ba35c4c8bf837bc64b3d68f0826cbedffb",
        "warmup_time": -1
    },
    "hdk.benchmarks.TimeGroupByMultiColumn.time_groupby_agg_mean": {
        "code": "class TimeGroupByMultiColumn:\n    def time_groupby_agg_mean(self, *args, **kwargs):\n        execute(self.df.groupby(by=self.groupby_columns).agg(\"mean\"))\n\nclass BaseTimeGroupBy:\n    def setup(self, shape, ngroups=5, groupby_ncols=1):\n        ngroups = translator_groupby_ngroups(ngroups, shape)\n        self.df, self.groupby_columns = generate_dataframe(\n            \"int\",\n            *shape,\n            RAND_LOW,\n            RAND_HIGH,\n            groupby_ncols,\n            count_groups=ngroups,\n        )\n        # correct while we use 'col*' like name for non-groupby columns\n        # and 'groupby_col*' like name for groupby columns\n        self.non_groupby_columns = self.df.columns[:-groupby_ncols]\n        trigger_import(self.df)",
        "min_run_count": 2,
        "name": "hdk.benchmarks.TimeGroupByMultiColumn.time_groupby_agg_mean",
        "number": 0,
        "param_names": [
            "shape",
            "ngroups",
            "groupby_ncols"
        ],
        "params": [
            [
                "[1000000, 10]"
            ],
            [
                "100",
                "'huge_amount_groups'"
            ],
            [
                "6"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "fcc2e5acf59ef8be0cdbd65aa7b3a77b14bed4b5a721790a284b33f33f6cc9d9",
        "warmup_time": -1
    },
    "hdk.benchmarks.TimeGroupByMultiColumn.time_groupby_agg_mean_dict": {
        "code": "class TimeGroupByMultiColumn:\n    def time_groupby_agg_mean_dict(self, *args, **kwargs):\n        execute(\n            self.df.groupby(by=self.groupby_columns).agg(\n                {col: \"mean\" for col in self.non_groupby_columns}\n            )\n        )\n\nclass BaseTimeGroupBy:\n    def setup(self, shape, ngroups=5, groupby_ncols=1):\n        ngroups = translator_groupby_ngroups(ngroups, shape)\n        self.df, self.groupby_columns = generate_dataframe(\n            \"int\",\n            *shape,\n            RAND_LOW,\n            RAND_HIGH,\n            groupby_ncols,\n            count_groups=ngroups,\n        )\n        # correct while we use 'col*' like name for non-groupby columns\n        # and 'groupby_col*' like name for groupby columns\n        self.non_groupby_columns = self.df.columns[:-groupby_ncols]\n        trigger_import(self.df)",
        "min_run_count": 2,
        "name": "hdk.benchmarks.TimeGroupByMultiColumn.time_groupby_agg_mean_dict",
        "number": 0,
        "param_names": [
            "shape",
            "ngroups",
            "groupby_ncols"
        ],
        "params": [
            [
                "[1000000, 10]"
            ],
            [
                "100",
                "'huge_amount_groups'"
            ],
            [
                "6"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f2d76d36962269f3de3ad5130f469d2ae74bd71599c247c0667e0916c6462c42",
        "warmup_time": -1
    },
    "hdk.benchmarks.TimeGroupByMultiColumn.time_groupby_agg_nunique": {
        "code": "class TimeGroupByMultiColumn:\n    def time_groupby_agg_nunique(self, *args, **kwargs):\n        execute(self.df.groupby(by=self.groupby_columns).agg(\"nunique\"))\n\nclass BaseTimeGroupBy:\n    def setup(self, shape, ngroups=5, groupby_ncols=1):\n        ngroups = translator_groupby_ngroups(ngroups, shape)\n        self.df, self.groupby_columns = generate_dataframe(\n            \"int\",\n            *shape,\n            RAND_LOW,\n            RAND_HIGH,\n            groupby_ncols,\n            count_groups=ngroups,\n        )\n        # correct while we use 'col*' like name for non-groupby columns\n        # and 'groupby_col*' like name for groupby columns\n        self.non_groupby_columns = self.df.columns[:-groupby_ncols]\n        trigger_import(self.df)",
        "min_run_count": 2,
        "name": "hdk.benchmarks.TimeGroupByMultiColumn.time_groupby_agg_nunique",
        "number": 0,
        "param_names": [
            "shape",
            "ngroups",
            "groupby_ncols"
        ],
        "params": [
            [
                "[1000000, 10]"
            ],
            [
                "100",
                "'huge_amount_groups'"
            ],
            [
                "6"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b0e807026c13cefed783abf9e4063abe1482967b27bc03351360e280a1144b48",
        "warmup_time": -1
    },
    "hdk.benchmarks.TimeGroupByMultiColumn.time_groupby_sum": {
        "code": "class TimeGroupByMultiColumn:\n    def time_groupby_sum(self, *args, **kwargs):\n        execute(self.df.groupby(by=self.groupby_columns).sum())\n\nclass BaseTimeGroupBy:\n    def setup(self, shape, ngroups=5, groupby_ncols=1):\n        ngroups = translator_groupby_ngroups(ngroups, shape)\n        self.df, self.groupby_columns = generate_dataframe(\n            \"int\",\n            *shape,\n            RAND_LOW,\n            RAND_HIGH,\n            groupby_ncols,\n            count_groups=ngroups,\n        )\n        # correct while we use 'col*' like name for non-groupby columns\n        # and 'groupby_col*' like name for groupby columns\n        self.non_groupby_columns = self.df.columns[:-groupby_ncols]\n        trigger_import(self.df)",
        "min_run_count": 2,
        "name": "hdk.benchmarks.TimeGroupByMultiColumn.time_groupby_sum",
        "number": 0,
        "param_names": [
            "shape",
            "ngroups",
            "groupby_ncols"
        ],
        "params": [
            [
                "[1000000, 10]"
            ],
            [
                "100",
                "'huge_amount_groups'"
            ],
            [
                "6"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "40140eb8860732e39573e7dccd5449cca445aeb1b8a00bdb56b58d58533b9c85",
        "warmup_time": -1
    },
    "hdk.benchmarks.TimeHead.time_head": {
        "code": "class TimeHead:\n    def time_head(self, shape, head_count):\n        execute(self.df.head(self.head_count))\n\n    def setup(self, shape, head_count):\n        self.df = generate_dataframe(\"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df)\n        self.head_count = (\n            int(head_count * len(self.df.index))\n            if isinstance(head_count, float)\n            else head_count\n        )",
        "min_run_count": 2,
        "name": "hdk.benchmarks.TimeHead.time_head",
        "number": 0,
        "param_names": [
            "shape",
            "head_count"
        ],
        "params": [
            [
                "[1000000, 10]"
            ],
            [
                "5",
                "0.8"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "e3cbe98fd7c00b6ccea309f1b0e8ac2d8aab7a8e28911502757000bd43662cb9",
        "warmup_time": -1
    },
    "hdk.benchmarks.TimeIndexing.time_iloc": {
        "code": "class TimeIndexing:\n    def time_iloc(self, shape, indexer_type):\n        # Pandas doesn't implement `df.iloc[series boolean_mask]` and raises an exception on it.\n        # Replacing this with the semantically equivalent construction:\n        if indexer_type != \"bool_series\":\n            execute(self.df.iloc[self.indexer])\n        else:\n            execute(self.df[self.indexer])\n\n    def setup(self, shape, indexer_type):\n        self.df = generate_dataframe(\"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df)\n    \n        self.indexer = self.indexer_getters[indexer_type](self.df)\n        if isinstance(self.indexer, (IMPL.Series, IMPL.DataFrame)):\n            # HACK: Triggering `dtypes` meta-data computation in advance,\n            # so it won't affect the `loc/iloc` time:\n            self.indexer.dtypes",
        "min_run_count": 2,
        "name": "hdk.benchmarks.TimeIndexing.time_iloc",
        "number": 0,
        "param_names": [
            "shape",
            "indexer_type"
        ],
        "params": [
            [
                "[1000000, 10]"
            ],
            [
                "'bool_array'",
                "'bool_series'",
                "'scalar'",
                "'slice'",
                "'continuous_slice'",
                "'numpy_array_take_all_values'",
                "'python_list_take_10_values'",
                "'function'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "7b73f9643fa771d31cbaccfd55da0c6b6d8b7f67f2252ba5f17ed73350a54288",
        "warmup_time": -1
    },
    "hdk.benchmarks.TimeIndexing.time_loc": {
        "code": "class TimeIndexing:\n    def time_loc(self, shape, indexer_type):\n        execute(self.df.loc[self.indexer])\n\n    def setup(self, shape, indexer_type):\n        self.df = generate_dataframe(\"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df)\n    \n        self.indexer = self.indexer_getters[indexer_type](self.df)\n        if isinstance(self.indexer, (IMPL.Series, IMPL.DataFrame)):\n            # HACK: Triggering `dtypes` meta-data computation in advance,\n            # so it won't affect the `loc/iloc` time:\n            self.indexer.dtypes",
        "min_run_count": 2,
        "name": "hdk.benchmarks.TimeIndexing.time_loc",
        "number": 0,
        "param_names": [
            "shape",
            "indexer_type"
        ],
        "params": [
            [
                "[1000000, 10]"
            ],
            [
                "'bool_array'",
                "'bool_series'",
                "'scalar'",
                "'slice'",
                "'continuous_slice'",
                "'numpy_array_take_all_values'",
                "'python_list_take_10_values'",
                "'function'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "822e648264a13f7e22816c17b42e9d47753fbcb058fcd3885ec93872245c4290",
        "warmup_time": -1
    },
    "hdk.benchmarks.TimeIndexingColumns.time___getitem__": {
        "code": "class TimeIndexingColumns:\n    def time___getitem__(self, shape):\n        execute(self.df[self.labels_indexer])\n\n    def setup(self, shape):\n        self.df = generate_dataframe(\"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df)\n        self.numeric_indexer = [0, 1]\n        self.labels_indexer = self.df.columns[self.numeric_indexer].tolist()",
        "min_run_count": 2,
        "name": "hdk.benchmarks.TimeIndexingColumns.time___getitem__",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "6fa82daf47b740e60aad7b96fd846c6a92b09b84143fc302aef64690219c9b35",
        "warmup_time": -1
    },
    "hdk.benchmarks.TimeIndexingColumns.time_iloc": {
        "code": "class TimeIndexingColumns:\n    def time_iloc(self, shape):\n        execute(self.df.iloc[:, self.numeric_indexer])\n\n    def setup(self, shape):\n        self.df = generate_dataframe(\"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df)\n        self.numeric_indexer = [0, 1]\n        self.labels_indexer = self.df.columns[self.numeric_indexer].tolist()",
        "min_run_count": 2,
        "name": "hdk.benchmarks.TimeIndexingColumns.time_iloc",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "5bb0aafeffe2a1aeb522c1fd1d12dd0e71c4b31ede8e2b6eff891ef79a0af478",
        "warmup_time": -1
    },
    "hdk.benchmarks.TimeIndexingColumns.time_loc": {
        "code": "class TimeIndexingColumns:\n    def time_loc(self, shape):\n        execute(self.df.loc[:, self.labels_indexer])\n\n    def setup(self, shape):\n        self.df = generate_dataframe(\"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df)\n        self.numeric_indexer = [0, 1]\n        self.labels_indexer = self.df.columns[self.numeric_indexer].tolist()",
        "min_run_count": 2,
        "name": "hdk.benchmarks.TimeIndexingColumns.time_loc",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b4304883d436bf17c07ce9b7ff3e7ff1cda770f40a7860d94de51f65d417717f",
        "warmup_time": -1
    },
    "hdk.benchmarks.TimeJoin.time_join": {
        "code": "class TimeJoin:\n    def time_join(self, shape, how, is_equal_keys):\n        # join dataframes on index to get the predictable shape\n        execute(self.df1.join(self.df2, how=how, lsuffix=\"left_\"))\n\n    def setup(self, shape, how, is_equal_keys):\n        self.df1, self.df2 = (\n            generate_dataframe(\n                \"int\",\n                *frame_shape,\n                RAND_LOW,\n                RAND_HIGH,\n                cache_prefix=f\"{i}-th_frame_to_join\",\n            )\n            for i, frame_shape in enumerate((shape, shape))\n        )\n    \n        if is_equal_keys:\n            # When the frames have default indices to join on: RangeIndex(frame_length),\n            # HDK backend performs join on the internal meta-column called 'rowid'.\n            # There is a bug in the engine that makes such joins fail. To avoid joining\n            # on the meta-column we explicitly specify a non-default index to join on.\n            # https://github.com/modin-project/modin/issues/3740\n            # Generating a new object for every index to avoid shared index objects:\n            self.df1.index = pandas.RangeIndex(1, len(self.df1) + 1)\n            self.df2.index = pandas.RangeIndex(1, len(self.df2) + 1)\n        else:\n            # Intersection rate indicates how many common join-keys `self.df1`\n            # and `self.df2` have in terms of percentage.\n            indices_intersection_rate = 0.5\n    \n            frame_length = len(self.df1)\n            intersect_size = int(frame_length * indices_intersection_rate)\n    \n            intersect_part = random_state.choice(\n                self.df1.index, size=intersect_size, replace=False\n            )\n            non_intersect_part = np.arange(\n                start=frame_length, stop=frame_length + (frame_length - intersect_size)\n            )\n            new_index = np.concatenate([intersect_part, non_intersect_part])\n    \n            random_state.shuffle(new_index)\n            self.df1.index = new_index\n    \n        trigger_import(self.df1, self.df2)",
        "min_run_count": 2,
        "name": "hdk.benchmarks.TimeJoin.time_join",
        "number": 0,
        "param_names": [
            "shape",
            "how",
            "is_equal_keys"
        ],
        "params": [
            [
                "[1000000, 10]"
            ],
            [
                "'left'",
                "'inner'"
            ],
            [
                "True",
                "False"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "5cce63d6993b32a8fd278660bd619406eff0bc774cddfc9fca64fb23a79cb76f",
        "warmup_time": -1
    },
    "hdk.benchmarks.TimeMerge.time_merge": {
        "code": "class TimeMerge:\n    def time_merge(self, shapes, how):\n        # merging dataframes by index is not supported, therefore we merge by column\n        # with arbitrary values, which leads to an unpredictable form of the operation result;\n        # it's need to get the predictable shape to get consistent performance results\n        execute(\n            self.dfs[0].merge(\n                self.dfs[1], on=\"col1\", how=how, suffixes=(\"left_\", \"right_\")\n            )\n        )\n\n    def setup(self, shapes, how):\n        gen_unique_key = how == \"inner\"\n        self.dfs = []\n        for i, shape in enumerate(shapes):\n            self.dfs.append(\n                generate_dataframe(\n                    \"int\",\n                    *shape,\n                    RAND_LOW,\n                    RAND_HIGH,\n                    gen_unique_key=gen_unique_key,\n                    cache_prefix=f\"{i}-th_frame_to_merge\",\n                )\n            )\n        trigger_import(*self.dfs)",
        "min_run_count": 2,
        "name": "hdk.benchmarks.TimeMerge.time_merge",
        "number": 0,
        "param_names": [
            "shapes",
            "how"
        ],
        "params": [
            [
                "[[500000, 20], [1000000, 10]]"
            ],
            [
                "'left'",
                "'inner'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "72f155ffa902af3d474557429591d191946e29199d2a4d2520d301d7d8986236",
        "warmup_time": -1
    },
    "hdk.benchmarks.TimeProperties.time_columns": {
        "code": "class TimeProperties:\n    def time_columns(self, shape):\n        return self.df.columns\n\n    def setup(self, shape):\n        self.df = generate_dataframe(\"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df)",
        "min_run_count": 2,
        "name": "hdk.benchmarks.TimeProperties.time_columns",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "79ef769f7de5176d7b49b1bda2b9e052cf185dc6e8ea6fa84b9d43d94774f3e4",
        "warmup_time": -1
    },
    "hdk.benchmarks.TimeProperties.time_index": {
        "code": "class TimeProperties:\n    def time_index(self, shape):\n        return self.df.index\n\n    def setup(self, shape):\n        self.df = generate_dataframe(\"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df)",
        "min_run_count": 2,
        "name": "hdk.benchmarks.TimeProperties.time_index",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "71e5b478474dc50db09ac8449a19db3e194d492428268f5bb44a62a90e39b89c",
        "warmup_time": -1
    },
    "hdk.benchmarks.TimeProperties.time_shape": {
        "code": "class TimeProperties:\n    def time_shape(self, shape):\n        return self.df.shape\n\n    def setup(self, shape):\n        self.df = generate_dataframe(\"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df)",
        "min_run_count": 2,
        "name": "hdk.benchmarks.TimeProperties.time_shape",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "224f83c17301535d4a5d3726ab1eebd5ecaa4a4720187f36831467262069fe7a",
        "warmup_time": -1
    },
    "hdk.benchmarks.TimeResetIndex.time_reset_index": {
        "code": "class TimeResetIndex:\n    def time_reset_index(self, shape, drop, level):\n        execute(self.df.reset_index(drop=drop, level=level))\n\n    def setup(self, shape, drop, level):\n        if not drop or level == \"level_1\":\n            raise NotImplementedError\n    \n        self.df = generate_dataframe(\"int\", *shape, RAND_LOW, RAND_HIGH)\n        if level:\n            index = IMPL.MultiIndex.from_product(\n                [self.df.index[: shape[0] // 2], [\"bar\", \"foo\"]],\n                names=[\"level_1\", \"level_2\"],\n            )\n            self.df.index = index\n        trigger_import(self.df)",
        "min_run_count": 2,
        "name": "hdk.benchmarks.TimeResetIndex.time_reset_index",
        "number": 0,
        "param_names": [
            "shape",
            "drop",
            "level"
        ],
        "params": [
            [
                "[1000000, 10]"
            ],
            [
                "False",
                "True"
            ],
            [
                "None",
                "'level_1'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "c83ec8e909012cee872aaab93da9884d02bd99fe5c09711ae72b02f63af3e76f",
        "warmup_time": -1
    },
    "hdk.benchmarks.TimeSortValues.time_sort_values": {
        "code": "class TimeSortValues:\n    def time_sort_values(self, shape, columns_number, ascending_list):\n        execute(self.df.sort_values(self.columns, ascending=self.ascending))\n\n    def setup(self, shape, columns_number, ascending_list):\n        self.df = generate_dataframe(\"int\", *shape, RAND_LOW, RAND_HIGH)\n        trigger_import(self.df)\n        self.columns = random_columns(self.df.columns, columns_number)\n        self.ascending = (\n            random_booleans(columns_number)\n            if ascending_list\n            else bool(random_booleans(1)[0])\n        )",
        "min_run_count": 2,
        "name": "hdk.benchmarks.TimeSortValues.time_sort_values",
        "number": 0,
        "param_names": [
            "shape",
            "columns_number",
            "ascending_list"
        ],
        "params": [
            [
                "[1000000, 10]"
            ],
            [
                "1",
                "5"
            ],
            [
                "False",
                "True"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "8344c06c681d6e0bfdcf6288dbb6b2105dceaf4ea1d6024b4be3dbd3d3932e2e",
        "warmup_time": -1
    },
    "hdk.benchmarks.TimeValueCountsDataFrame.time_value_counts": {
        "code": "class TimeValueCountsDataFrame:\n    def time_value_counts(self, *args, **kwargs):\n        execute(self.df.value_counts(subset=self.subset))\n\nclass BaseTimeValueCounts:\n    def setup(self, shape, ngroups=5, subset=1):\n        ngroups = translator_groupby_ngroups(ngroups, shape)\n        self.df, self.subset = generate_dataframe(\n            \"int\",\n            *shape,\n            RAND_LOW,\n            RAND_HIGH,\n            groupby_ncols=subset,\n            count_groups=ngroups,\n        )\n        trigger_import(self.df)",
        "min_run_count": 2,
        "name": "hdk.benchmarks.TimeValueCountsDataFrame.time_value_counts",
        "number": 0,
        "param_names": [
            "shape",
            "ngroups",
            "subset"
        ],
        "params": [
            [
                "[1000000, 10]"
            ],
            [
                "100",
                "'huge_amount_groups'"
            ],
            [
                "2",
                "10"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f5809ce427e28d849989d0a53fbdf7cd8701e5b2262062aaffbbca77e36cb37d",
        "warmup_time": -1
    },
    "hdk.benchmarks.TimeValueCountsSeries.time_value_counts": {
        "code": "class TimeValueCountsSeries:\n    def time_value_counts(self, shape, ngroups):\n        execute(self.series.value_counts())\n\n    def setup(self, shape, ngroups):\n        super().setup(shape, ngroups, subset=1)\n        self.series = self.df[self.subset[0]]\n        trigger_import(self.series)",
        "min_run_count": 2,
        "name": "hdk.benchmarks.TimeValueCountsSeries.time_value_counts",
        "number": 0,
        "param_names": [
            "shape",
            "ngroups"
        ],
        "params": [
            [
                "[10000000, 1]"
            ],
            [
                "100",
                "'huge_amount_groups'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "50d039f809a57224798f163963708292724bc1f840d29c56433f0628d90b683b",
        "warmup_time": -1
    },
    "hdk.io.TimeReadCsvNames.time_read_csv_names": {
        "code": "class TimeReadCsvNames:\n    def time_read_csv_names(self, cache, shape):\n        df = IMPL.read_csv(\n            self.filename,\n            names=self.names,\n            header=0,\n            dtype=self.dtype,\n        )\n        trigger_import(df)\n\n    def setup(self, cache, shape):\n        # ray init\n        if ASV_USE_IMPL == \"modin\":\n            IMPL.DataFrame([])\n        file_id = get_shape_id(shape)\n        self.filename, self.names, self.dtype = cache[file_id]\n\n    def setup_cache(self, test_filename=\"io_test_file_csv_names\"):\n        # filenames with a metadata of saved dataframes\n        cache = {}\n        for shape in self.shapes:\n            df = generate_dataframe(\"int\", *shape, RAND_LOW, RAND_HIGH, impl=\"pandas\")\n            file_id = get_shape_id(shape)\n            cache[file_id] = (\n                f\"{test_filename}_{file_id}.csv\",\n                df.columns.to_list(),\n                df.dtypes.to_dict(),\n            )\n            df.to_csv(cache[file_id][0], index=False)\n        return cache",
        "min_run_count": 2,
        "name": "hdk.io.TimeReadCsvNames.time_read_csv_names",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "hdk.io:35",
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "fcb6bccb6607d1e89e8d031640af59b1853b751ffa88e558fe346a5b599f1d69",
        "warmup_time": -1
    },
    "hdk.io.TimeReadCsvTrueFalseValues.time_true_false_values": {
        "code": "class TimeReadCsvTrueFalseValues:\n    def time_true_false_values(self, test_filenames, shape):\n        execute(\n            IMPL.read_csv(\n                test_filenames[self.shape_id],\n                true_values=[\"Yes\", \"true\"],\n                false_values=[\"No\", \"false\"],\n            ),\n            trigger_hdk_import=ASV_USE_STORAGE_FORMAT == \"hdk\",\n        )\n\nclass BaseReadCsv:\n    def setup(self, test_filenames, shape, *args, **kwargs):\n        # ray init\n        if ASV_USE_IMPL == \"modin\":\n            IMPL.DataFrame([])\n        self.shape_id = get_shape_id(shape)\n\n    def setup_cache(self, test_filename=\"io_test_file\"):\n        test_filenames = prepare_io_data(\n            test_filename, self.data_type, get_benchmark_shapes(self.__class__.__name__)\n        )\n        return test_filenames",
        "min_run_count": 2,
        "name": "hdk.io.TimeReadCsvTrueFalseValues.time_true_false_values",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "io.csv:32",
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b83cec19138a00f15f7a014d3fccb511e85353a6968fa8a05285213c403d214d",
        "warmup_time": -1
    },
    "io.csv.TimeReadCsvNamesDtype.time_read_csv_names_dtype": {
        "code": "class TimeReadCsvNamesDtype:\n    def time_read_csv_names_dtype(self, cache, shape, names, dtype):\n        execute(\n            IMPL.read_csv(\n                self.filename,\n                names=self.names,\n                header=0,\n                dtype=self.dtype,\n                parse_dates=self.parse_dates,\n            )\n        )\n\n    def setup(self, cache, shape, names, dtype):\n        # ray init\n        if ASV_USE_IMPL == \"modin\":\n            IMPL.DataFrame([])\n        file_id = self._get_file_id(shape, dtype)\n        self.filename, self.names, self.dtype = cache[file_id]\n    \n        self.parse_dates = None\n        if dtype == \"Int64_Timestamp\":\n            # cached version of dtype should not change\n            self.dtype = self.dtype.copy()\n            for col in self._timestamp_columns:\n                del self.dtype[col]\n            self.parse_dates = self._timestamp_columns\n\n    def setup_cache(self, test_filename=\"io_test_file_csv_names_dtype\"):\n        # filenames with a metadata of saved dataframes\n        cache = {}\n        for shape in self.shapes:\n            for dtype in self._dtypes_params:\n                df = generate_dataframe(\n                    \"int\", *shape, RAND_LOW, RAND_HIGH, impl=\"pandas\"\n                )\n                if dtype == \"Int64_Timestamp\":\n                    df = self._add_timestamp_columns(df)\n    \n                file_id = self._get_file_id(shape, dtype)\n                cache[file_id] = (\n                    f\"{test_filename}_{file_id}.csv\",\n                    df.columns.to_list(),\n                    df.dtypes.to_dict(),\n                )\n                df.to_csv(cache[file_id][0], index=False)\n        return cache",
        "min_run_count": 2,
        "name": "io.csv.TimeReadCsvNamesDtype.time_read_csv_names_dtype",
        "number": 0,
        "param_names": [
            "shape",
            "names",
            "dtype"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "'array-like'"
            ],
            [
                "'Int64'",
                "'Int64_Timestamp'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "io.csv:107",
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "3a38aa8596d6086419b2a97a392ad457fb7876350a14b7ef5857ab5d7ea0105b",
        "warmup_time": -1
    },
    "io.csv.TimeReadCsvSkiprows.time_skiprows": {
        "code": "class TimeReadCsvSkiprows:\n    def time_skiprows(self, test_filenames, shape, skiprows):\n        execute(IMPL.read_csv(test_filenames[self.shape_id], skiprows=self.skiprows))\n\n    def setup(self, test_filenames, shape, skiprows):\n        super().setup(test_filenames, shape, skiprows)\n        self.skiprows = self.skiprows_mapping[skiprows] if skiprows else None\n\nclass BaseReadCsv:\n    def setup_cache(self, test_filename=\"io_test_file\"):\n        test_filenames = prepare_io_data(\n            test_filename, self.data_type, get_benchmark_shapes(self.__class__.__name__)\n        )\n        return test_filenames",
        "min_run_count": 2,
        "name": "io.csv.TimeReadCsvSkiprows.time_skiprows",
        "number": 0,
        "param_names": [
            "shape",
            "skiprows"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "None",
                "'lambda_even_rows'",
                "'range_uniform'",
                "'range_step2'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "io.csv:32",
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "3557c0f933d3d081b6c179b59f000645bac0817d77ef5d1d67e7bb0ed039ff57",
        "warmup_time": -1
    },
    "io.csv.TimeReadCsvTrueFalseValues.time_true_false_values": {
        "code": "class TimeReadCsvTrueFalseValues:\n    def time_true_false_values(self, test_filenames, shape):\n        execute(\n            IMPL.read_csv(\n                test_filenames[self.shape_id],\n                true_values=[\"Yes\", \"true\"],\n                false_values=[\"No\", \"false\"],\n            ),\n            trigger_hdk_import=ASV_USE_STORAGE_FORMAT == \"hdk\",\n        )\n\nclass BaseReadCsv:\n    def setup(self, test_filenames, shape, *args, **kwargs):\n        # ray init\n        if ASV_USE_IMPL == \"modin\":\n            IMPL.DataFrame([])\n        self.shape_id = get_shape_id(shape)\n\n    def setup_cache(self, test_filename=\"io_test_file\"):\n        test_filenames = prepare_io_data(\n            test_filename, self.data_type, get_benchmark_shapes(self.__class__.__name__)\n        )\n        return test_filenames",
        "min_run_count": 2,
        "name": "io.csv.TimeReadCsvTrueFalseValues.time_true_false_values",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "io.csv:32",
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b83cec19138a00f15f7a014d3fccb511e85353a6968fa8a05285213c403d214d",
        "warmup_time": -1
    },
    "io.parquet.TimeReadParquet.time_read_parquet": {
        "code": "class TimeReadParquet:\n    def time_read_parquet(self, test_filenames, shape):\n        execute(\n            IMPL.read_parquet(\n                test_filenames[self.shape_id],\n            )\n        )\n\n    def setup(self, test_filenames, shape):\n        # ray init\n        if ASV_USE_IMPL == \"modin\":\n            IMPL.DataFrame([])\n        self.shape_id = get_shape_id(shape)\n\n    def setup_cache(self, test_filename=\"io_test_file\"):\n        test_filenames = prepare_io_data_parquet(\n            test_filename, self.data_type, get_benchmark_shapes(self.__class__.__name__)\n        )\n        return test_filenames",
        "min_run_count": 2,
        "name": "io.parquet.TimeReadParquet.time_read_parquet",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "io.parquet:34",
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "3147afada63eff0525fac21ceffae7c023662b4786918548b83b70a5b9702a95",
        "warmup_time": -1
    },
    "scalability.scalability_benchmarks.TimeFromPandas.time_from_pandas": {
        "code": "class TimeFromPandas:\n    def time_from_pandas(self, shape, cpus):\n        execute(from_pandas(self.data))\n\n    def setup(self, shape, cpus):\n        self.data = pandas.DataFrame(gen_data(\"int\", *shape, RAND_LOW, RAND_HIGH))\n        from modin.config import NPartitions\n    \n        NPartitions.get = lambda: cpus\n        # trigger ray init\n        pd.DataFrame([])",
        "min_run_count": 2,
        "name": "scalability.scalability_benchmarks.TimeFromPandas.time_from_pandas",
        "number": 0,
        "param_names": [
            "shape",
            "cpus"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "4",
                "16",
                "32"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "8af06db97bd87859b17230125772585ddc3fe0c5e23426aca77776870540eab1",
        "warmup_time": -1
    },
    "scalability.scalability_benchmarks.TimeToPandas.time_to_pandas": {
        "code": "class TimeToPandas:\n    def time_to_pandas(self, shape, cpus):\n        # to_pandas is already synchronous\n        to_pandas(self.data)\n\n    def setup(self, shape, cpus):\n        from modin.config import NPartitions\n    \n        NPartitions.get = lambda: cpus\n        self.data = generate_dataframe(\"int\", *shape, RAND_LOW, RAND_HIGH, impl=\"modin\")",
        "min_run_count": 2,
        "name": "scalability.scalability_benchmarks.TimeToPandas.time_to_pandas",
        "number": 0,
        "param_names": [
            "shape",
            "cpus"
        ],
        "params": [
            [
                "[5000, 5000]",
                "[1000000, 10]"
            ],
            [
                "4",
                "16",
                "32"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "ad500febb53cf2ef08d60cf0308189ac64a9d4428f672364ecda97dae1a04869",
        "warmup_time": -1
    },
    "version": 2
}