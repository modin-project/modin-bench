{
    "benchmarks.TimeAppend.time_append": {
        "code": "class TimeAppend:\n    def time_append(self, shapes, sort):\n        execute(self.df1.append(self.df2, sort=sort))\n\n    def setup(self, shapes, sort):\n        self.df1 = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shapes[0], RAND_LOW, RAND_HIGH\n        )\n        self.df2 = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shapes[1], RAND_LOW, RAND_HIGH\n        )\n        if sort:\n            self.df1.columns = self.df1.columns[::-1]",
        "min_run_count": 2,
        "name": "benchmarks.TimeAppend.time_append",
        "number": 0,
        "param_names": [
            "shapes",
            "sort"
        ],
        "params": [
            [
                "((5000, 5000), (5000, 5000))",
                "((500000, 20), (1000000, 10))"
            ],
            [
                "False",
                "True"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "c2d89eb99a9d7965ff21009a90377a267577d695e1baeeedba0a97d62f2f8030",
        "warmup_time": -1
    },
    "benchmarks.TimeArithmetic.time_apply": {
        "code": "class TimeArithmetic:\n    def time_apply(self, shape, axis):\n        execute(self.df.apply(lambda df: df.sum(), axis=axis))\n\n    def setup(self, shape, axis):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)",
        "min_run_count": 2,
        "name": "benchmarks.TimeArithmetic.time_apply",
        "number": 0,
        "param_names": [
            "shape",
            "axis"
        ],
        "params": [
            [
                "(5000, 5000)",
                "(1000000, 10)"
            ],
            [
                "0",
                "1"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "219317b7fcbaf3f87050bca6999e1b68c258853598a859ac59da82b025bf251a",
        "warmup_time": -1
    },
    "benchmarks.TimeArithmetic.time_mean": {
        "code": "class TimeArithmetic:\n    def time_mean(self, shape, axis):\n        execute(self.df.mean(axis=axis))\n\n    def setup(self, shape, axis):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)",
        "min_run_count": 2,
        "name": "benchmarks.TimeArithmetic.time_mean",
        "number": 0,
        "param_names": [
            "shape",
            "axis"
        ],
        "params": [
            [
                "(5000, 5000)",
                "(1000000, 10)"
            ],
            [
                "0",
                "1"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b541392002bd635e8fdf6d069d1fb9147bf2e0d1cbccf130bf1b596c17454708",
        "warmup_time": -1
    },
    "benchmarks.TimeArithmetic.time_median": {
        "code": "class TimeArithmetic:\n    def time_median(self, shape, axis):\n        execute(self.df.median(axis=axis))\n\n    def setup(self, shape, axis):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)",
        "min_run_count": 2,
        "name": "benchmarks.TimeArithmetic.time_median",
        "number": 0,
        "param_names": [
            "shape",
            "axis"
        ],
        "params": [
            [
                "(5000, 5000)",
                "(1000000, 10)"
            ],
            [
                "0",
                "1"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "6f99b2ce6d39b39818206977c6513e7df8166e01bbff37724a82601a9c4875ad",
        "warmup_time": -1
    },
    "benchmarks.TimeArithmetic.time_nunique": {
        "code": "class TimeArithmetic:\n    def time_nunique(self, shape, axis):\n        execute(self.df.nunique(axis=axis))\n\n    def setup(self, shape, axis):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)",
        "min_run_count": 2,
        "name": "benchmarks.TimeArithmetic.time_nunique",
        "number": 0,
        "param_names": [
            "shape",
            "axis"
        ],
        "params": [
            [
                "(5000, 5000)",
                "(1000000, 10)"
            ],
            [
                "0",
                "1"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "2e6aa9b726c293d7e2d3121d8ad006add467a8da0531eac8774b3f0384ca64bc",
        "warmup_time": -1
    },
    "benchmarks.TimeArithmetic.time_sum": {
        "code": "class TimeArithmetic:\n    def time_sum(self, shape, axis):\n        execute(self.df.sum(axis=axis))\n\n    def setup(self, shape, axis):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)",
        "min_run_count": 2,
        "name": "benchmarks.TimeArithmetic.time_sum",
        "number": 0,
        "param_names": [
            "shape",
            "axis"
        ],
        "params": [
            [
                "(5000, 5000)",
                "(1000000, 10)"
            ],
            [
                "0",
                "1"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "3ade96bfe969295a9d3c99d61bc88dedda36a799925710d5620e5fb30438d074",
        "warmup_time": -1
    },
    "benchmarks.TimeAstype.time_astype": {
        "code": "class TimeAstype:\n    def time_astype(self, shape, dtype, astype_ncolumns):\n        execute(self.df.astype(self.astype_arg))\n\n    def setup(self, shape, dtype, astype_ncolumns):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        if astype_ncolumns == \"all\":\n            self.astype_arg = dtype\n        elif astype_ncolumns == \"one\":\n            self.astype_arg = {\"col1\": dtype}\n        else:\n            raise ValueError(\"astype_ncolumns: {astype_ncolumns} isn't supported\")",
        "min_run_count": 2,
        "name": "benchmarks.TimeAstype.time_astype",
        "number": 0,
        "param_names": [
            "shape",
            "dtype",
            "astype_ncolumns"
        ],
        "params": [
            [
                "(5000, 5000)",
                "(1000000, 10)"
            ],
            [
                "'float64'",
                "'category'"
            ],
            [
                "'one'",
                "'all'"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "e0815604b1644fa44789102d06d841ad6e2d03792cc5d694a40c0838ae3275f3",
        "warmup_time": -1
    },
    "benchmarks.TimeBinaryOp.time_binary_op": {
        "code": "class TimeBinaryOp:\n    def time_binary_op(self, shapes, binary_op, axis):\n        execute(self.op(self.df2, axis=axis))\n\n    def setup(self, shapes, binary_op, axis):\n        self.df1 = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shapes[0], RAND_LOW, RAND_HIGH\n        )\n        self.df2 = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shapes[1], RAND_LOW, RAND_HIGH\n        )\n        self.op = getattr(self.df1, binary_op)",
        "min_run_count": 2,
        "name": "benchmarks.TimeBinaryOp.time_binary_op",
        "number": 0,
        "param_names": [
            "shapes",
            "binary_op",
            "axis"
        ],
        "params": [
            [
                "((5000, 5000), (5000, 5000))",
                "((500000, 20), (1000000, 10))"
            ],
            [
                "'mul'"
            ],
            [
                "0",
                "1"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "9ff776f725432c65f49e1c3f59022f6f3d976278510bf9915fda51ba51ad13ae",
        "warmup_time": -1
    },
    "benchmarks.TimeConcat.time_concat": {
        "code": "class TimeConcat:\n    def time_concat(self, shapes, how, axis):\n        execute(IMPL[ASV_USE_IMPL].concat([self.df1, self.df2], axis=axis, join=how))\n\n    def setup(self, shapes, how, axis):\n        self.df1 = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shapes[0], RAND_LOW, RAND_HIGH\n        )\n        self.df2 = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shapes[1], RAND_LOW, RAND_HIGH\n        )",
        "min_run_count": 2,
        "name": "benchmarks.TimeConcat.time_concat",
        "number": 0,
        "param_names": [
            "shapes",
            "how",
            "axis"
        ],
        "params": [
            [
                "((5000, 5000), (5000, 5000))",
                "((500000, 20), (1000000, 10))"
            ],
            [
                "'inner'"
            ],
            [
                "0",
                "1"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "718c07f0450388e6f586cf10e7466f364cc94e4a6909380b7f50d8213c45205c",
        "warmup_time": -1
    },
    "benchmarks.TimeDescribe.time_describe": {
        "code": "class TimeDescribe:\n    def time_describe(self, shape):\n        execute(self.df.describe())\n\n    def setup(self, shape):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)",
        "min_run_count": 2,
        "name": "benchmarks.TimeDescribe.time_describe",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "(5000, 5000)",
                "(1000000, 10)"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b06d1af039ee49fcea92c1e11a041c293d33b86c73874976592036d57e966eb8",
        "warmup_time": -1
    },
    "benchmarks.TimeDrop.time_drop": {
        "code": "class TimeDrop:\n    def time_drop(self, shape, axis, drop_ncols):\n        execute(self.df.drop(self.labels, axis))\n\n    def setup(self, shape, axis, drop_ncols):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        drop_count = (\n            int(len(self.df.axes[axis]) * drop_ncols)\n            if isinstance(drop_ncols, float)\n            else drop_ncols\n        )\n        self.labels = self.df.axes[axis][:drop_count]",
        "min_run_count": 2,
        "name": "benchmarks.TimeDrop.time_drop",
        "number": 0,
        "param_names": [
            "shape",
            "axis",
            "drop_ncols"
        ],
        "params": [
            [
                "(5000, 5000)",
                "(1000000, 10)"
            ],
            [
                "0",
                "1"
            ],
            [
                "1",
                "0.8"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "cbeb16adcb3fadd00159e6c9922ccbfaac0eb086cd953d0eebb36b89c3e6e266",
        "warmup_time": -1
    },
    "benchmarks.TimeFillna.time_fillna": {
        "code": "class TimeFillna:\n    def time_fillna(self, self_type, value_type, shape, limit, inplace):\n        kw = {\"value\": self.value, \"limit\": self.limit, \"inplace\": inplace}\n        if inplace:\n            self.dataset.fillna(**kw)\n            execute(self.dataset)\n        else:\n            execute(self.dataset.fillna(**kw))\n\n    def setup(self, self_type, value_type, shape, limit, inplace):\n        pd = IMPL[ASV_USE_IMPL]\n        columns = [f\"col{x}\" for x in range(shape[1])]\n        if self_type == \"DataFrame\":\n            self.dataset = pd.DataFrame(\n                np.nan, index=pd.RangeIndex(shape[0]), columns=columns\n            )\n        elif self_type == \"Series\":\n            self.dataset = pd.Series(np.nan, index=pd.RangeIndex(shape[0]))\n        else:\n            assert False\n        if value_type == \"scalar\":\n            self.value = 18.19\n        elif value_type == \"dict\":\n            self.value = {k: k * 1.23 for k in range(shape[0])}\n        elif value_type == \"Series\":\n            self.value = pd.Series(\n                [k * 1.23 for k in range(shape[0])], index=pd.RangeIndex(shape[0])\n            )\n        elif value_type == \"DataFrame\":\n            if self_type == \"Series\":\n                raise NotImplementedError\n            self.value = pd.DataFrame(\n                {\n                    k: [i + j * 1.23 for j in range(shape[0])]\n                    for i, k in enumerate(columns)\n                },\n                index=pd.RangeIndex(shape[0]),\n                columns=columns,\n            )\n        else:\n            assert False\n        self.limit = int(limit * shape[0]) if limit else None",
        "min_run_count": 2,
        "name": "benchmarks.TimeFillna.time_fillna",
        "number": 0,
        "param_names": [
            "self_type",
            "value_type",
            "shape",
            "limit",
            "inplace"
        ],
        "params": [
            [
                "'DataFrame'",
                "'Series'"
            ],
            [
                "'scalar'",
                "'dict'",
                "'DataFrame'",
                "'Series'"
            ],
            [
                "(5000, 5000)",
                "(1000000, 10)"
            ],
            [
                "None",
                "0.8"
            ],
            [
                "False",
                "True"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "2fbfd0972c07a1a719adcbe59d5e0e0ca329ecab21043bd4b1c207076a8c4697",
        "warmup_time": -1
    },
    "benchmarks.TimeGroupByDefaultAggregations.time_groupby_count": {
        "code": "class TimeGroupByDefaultAggregations:\n    def time_groupby_count(self, *args, **kwargs):\n        execute(self.df.groupby(by=self.groupby_columns).count())\n\nclass BaseTimeGroupBy:\n    def setup(self, shape, ngroups=5, groupby_ncols=1):\n        ngroups = translator_groupby_ngroups(ngroups, shape)\n        self.df, self.groupby_columns = generate_dataframe(\n            ASV_USE_IMPL,\n            \"int\",\n            *shape,\n            RAND_LOW,\n            RAND_HIGH,\n            groupby_ncols,\n            count_groups=ngroups,\n        )",
        "min_run_count": 2,
        "name": "benchmarks.TimeGroupByDefaultAggregations.time_groupby_count",
        "number": 0,
        "param_names": [
            "shape",
            "ngroups"
        ],
        "params": [
            [
                "(5000, 5000)",
                "(1000000, 10)"
            ],
            [
                "100",
                "'huge_amount_groups'"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "46a1f84a3f0c0b546f071c9be94866f953ddb6e2384a6ccbc518ad0b9154380c",
        "warmup_time": -1
    },
    "benchmarks.TimeGroupByDefaultAggregations.time_groupby_mean": {
        "code": "class TimeGroupByDefaultAggregations:\n    def time_groupby_mean(self, *args, **kwargs):\n        execute(self.df.groupby(by=self.groupby_columns).mean())\n\nclass BaseTimeGroupBy:\n    def setup(self, shape, ngroups=5, groupby_ncols=1):\n        ngroups = translator_groupby_ngroups(ngroups, shape)\n        self.df, self.groupby_columns = generate_dataframe(\n            ASV_USE_IMPL,\n            \"int\",\n            *shape,\n            RAND_LOW,\n            RAND_HIGH,\n            groupby_ncols,\n            count_groups=ngroups,\n        )",
        "min_run_count": 2,
        "name": "benchmarks.TimeGroupByDefaultAggregations.time_groupby_mean",
        "number": 0,
        "param_names": [
            "shape",
            "ngroups"
        ],
        "params": [
            [
                "(5000, 5000)",
                "(1000000, 10)"
            ],
            [
                "100",
                "'huge_amount_groups'"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "23ad92017cdfe129d3ab99f79e62fe2722466cfac0a55179a1ecc00b910c4857",
        "warmup_time": -1
    },
    "benchmarks.TimeGroupByDefaultAggregations.time_groupby_size": {
        "code": "class TimeGroupByDefaultAggregations:\n    def time_groupby_size(self, *args, **kwargs):\n        execute(self.df.groupby(by=self.groupby_columns).size())\n\nclass BaseTimeGroupBy:\n    def setup(self, shape, ngroups=5, groupby_ncols=1):\n        ngroups = translator_groupby_ngroups(ngroups, shape)\n        self.df, self.groupby_columns = generate_dataframe(\n            ASV_USE_IMPL,\n            \"int\",\n            *shape,\n            RAND_LOW,\n            RAND_HIGH,\n            groupby_ncols,\n            count_groups=ngroups,\n        )",
        "min_run_count": 2,
        "name": "benchmarks.TimeGroupByDefaultAggregations.time_groupby_size",
        "number": 0,
        "param_names": [
            "shape",
            "ngroups"
        ],
        "params": [
            [
                "(5000, 5000)",
                "(1000000, 10)"
            ],
            [
                "100",
                "'huge_amount_groups'"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f597a5f0dac5a4fabed5dd5548e9d73d8d39698a8437bf3466131cb18ed4dde5",
        "warmup_time": -1
    },
    "benchmarks.TimeGroupByDefaultAggregations.time_groupby_sum": {
        "code": "class TimeGroupByDefaultAggregations:\n    def time_groupby_sum(self, *args, **kwargs):\n        execute(self.df.groupby(by=self.groupby_columns).sum())\n\nclass BaseTimeGroupBy:\n    def setup(self, shape, ngroups=5, groupby_ncols=1):\n        ngroups = translator_groupby_ngroups(ngroups, shape)\n        self.df, self.groupby_columns = generate_dataframe(\n            ASV_USE_IMPL,\n            \"int\",\n            *shape,\n            RAND_LOW,\n            RAND_HIGH,\n            groupby_ncols,\n            count_groups=ngroups,\n        )",
        "min_run_count": 2,
        "name": "benchmarks.TimeGroupByDefaultAggregations.time_groupby_sum",
        "number": 0,
        "param_names": [
            "shape",
            "ngroups"
        ],
        "params": [
            [
                "(5000, 5000)",
                "(1000000, 10)"
            ],
            [
                "100",
                "'huge_amount_groups'"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "ec74cb917a463fae4337b5d3444788e696f710113878e9df35417a0f56f92d09",
        "warmup_time": -1
    },
    "benchmarks.TimeGroupByDictionaryAggregation.time_groupby_dict_agg": {
        "code": "class TimeGroupByDictionaryAggregation:\n    def time_groupby_dict_agg(self, *args, **kwargs):\n        execute(self.df.groupby(by=self.groupby_columns).agg(self.agg_dict))\n\n    def setup(self, shape, ngroups, operation_type):\n        super().setup(shape, ngroups)\n        self.cols_to_agg = self.df.columns[1:4]\n        operations = self.operations[operation_type]\n        self.agg_dict = {\n            c: operations[i % len(operations)] for i, c in enumerate(self.cols_to_agg)\n        }",
        "min_run_count": 2,
        "name": "benchmarks.TimeGroupByDictionaryAggregation.time_groupby_dict_agg",
        "number": 0,
        "param_names": [
            "shape",
            "ngroups",
            "operation_type"
        ],
        "params": [
            [
                "(5000, 5000)",
                "(1000000, 10)"
            ],
            [
                "100",
                "'huge_amount_groups'"
            ],
            [
                "'reduction'",
                "'aggregation'"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "7aa41865cba30449bba2f4d9a40fe5d15e9d9b4c2c737222bd2a643fd6dcb39a",
        "warmup_time": -1
    },
    "benchmarks.TimeGroupByMultiColumn.time_groupby_agg_mean": {
        "code": "class TimeGroupByMultiColumn:\n    def time_groupby_agg_mean(self, *args, **kwargs):\n        execute(self.df.groupby(by=self.groupby_columns).apply(lambda df: df.mean()))\n\nclass BaseTimeGroupBy:\n    def setup(self, shape, ngroups=5, groupby_ncols=1):\n        ngroups = translator_groupby_ngroups(ngroups, shape)\n        self.df, self.groupby_columns = generate_dataframe(\n            ASV_USE_IMPL,\n            \"int\",\n            *shape,\n            RAND_LOW,\n            RAND_HIGH,\n            groupby_ncols,\n            count_groups=ngroups,\n        )",
        "min_run_count": 2,
        "name": "benchmarks.TimeGroupByMultiColumn.time_groupby_agg_mean",
        "number": 0,
        "param_names": [
            "shape",
            "ngroups",
            "groupby_ncols"
        ],
        "params": [
            [
                "(5000, 5000)",
                "(1000000, 10)"
            ],
            [
                "100",
                "'huge_amount_groups'"
            ],
            [
                "6"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "6584be7f02bda8d4601daf00fbd3fce226a7d4436faa6353a196619348047dea",
        "warmup_time": -1
    },
    "benchmarks.TimeGroupByMultiColumn.time_groupby_agg_quan": {
        "code": "class TimeGroupByMultiColumn:\n    def time_groupby_agg_quan(self, *args, **kwargs):\n        execute(self.df.groupby(by=self.groupby_columns).agg(\"quantile\"))\n\nclass BaseTimeGroupBy:\n    def setup(self, shape, ngroups=5, groupby_ncols=1):\n        ngroups = translator_groupby_ngroups(ngroups, shape)\n        self.df, self.groupby_columns = generate_dataframe(\n            ASV_USE_IMPL,\n            \"int\",\n            *shape,\n            RAND_LOW,\n            RAND_HIGH,\n            groupby_ncols,\n            count_groups=ngroups,\n        )",
        "min_run_count": 2,
        "name": "benchmarks.TimeGroupByMultiColumn.time_groupby_agg_quan",
        "number": 0,
        "param_names": [
            "shape",
            "ngroups",
            "groupby_ncols"
        ],
        "params": [
            [
                "(5000, 5000)",
                "(1000000, 10)"
            ],
            [
                "100",
                "'huge_amount_groups'"
            ],
            [
                "6"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "202444e83676d4998bfbfc58f218de93462f070c86e5000c628e56fb334193dc",
        "warmup_time": -1
    },
    "benchmarks.TimeHead.time_head": {
        "code": "class TimeHead:\n    def time_head(self, shape, head_count):\n        execute(self.df.head(self.head_count))\n\n    def setup(self, shape, head_count):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        self.head_count = (\n            int(head_count * len(self.df.index))\n            if isinstance(head_count, float)\n            else head_count\n        )",
        "min_run_count": 2,
        "name": "benchmarks.TimeHead.time_head",
        "number": 0,
        "param_names": [
            "shape",
            "head_count"
        ],
        "params": [
            [
                "(5000, 5000)",
                "(1000000, 10)"
            ],
            [
                "5",
                "0.8"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "0ab97d453eb88717822a7fbc0a43910d61e597489b0d1c49eec882656edd2dcf",
        "warmup_time": -1
    },
    "benchmarks.TimeIndexing.time_iloc": {
        "code": "class TimeIndexing:\n    def time_iloc(self, shape, indexer_type):\n        execute(self.df.iloc[self.indexer])\n\n    def setup(self, shape, indexer_type):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        if indexer_type == \"bool\":\n            self.indexer = [False, True] * (shape[0] // 2)\n        elif indexer_type == \"scalar\":\n            self.indexer = shape[0] // 2\n        elif indexer_type == \"slice\":\n            self.indexer = slice(0, shape[0], 2)\n        elif indexer_type == \"list\":\n            self.indexer = [x for x in range(shape[0])]\n        elif indexer_type == \"function\":\n            self.indexer = lambda df: df.index[::-2]",
        "min_run_count": 2,
        "name": "benchmarks.TimeIndexing.time_iloc",
        "number": 0,
        "param_names": [
            "shape",
            "indexer_type"
        ],
        "params": [
            [
                "(5000, 5000)",
                "(1000000, 10)"
            ],
            [
                "'scalar'",
                "'bool'",
                "'slice'",
                "'list'",
                "'function'"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "4e7262aec0ddddcf2cf6befd225168aa1e9f52e0ebe945dc373d7bab9c5e494c",
        "warmup_time": -1
    },
    "benchmarks.TimeIndexing.time_loc": {
        "code": "class TimeIndexing:\n    def time_loc(self, shape, indexer_type):\n        execute(self.df.loc[self.indexer])\n\n    def setup(self, shape, indexer_type):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        if indexer_type == \"bool\":\n            self.indexer = [False, True] * (shape[0] // 2)\n        elif indexer_type == \"scalar\":\n            self.indexer = shape[0] // 2\n        elif indexer_type == \"slice\":\n            self.indexer = slice(0, shape[0], 2)\n        elif indexer_type == \"list\":\n            self.indexer = [x for x in range(shape[0])]\n        elif indexer_type == \"function\":\n            self.indexer = lambda df: df.index[::-2]",
        "min_run_count": 2,
        "name": "benchmarks.TimeIndexing.time_loc",
        "number": 0,
        "param_names": [
            "shape",
            "indexer_type"
        ],
        "params": [
            [
                "(5000, 5000)",
                "(1000000, 10)"
            ],
            [
                "'scalar'",
                "'bool'",
                "'slice'",
                "'list'",
                "'function'"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "7b6fd37f862f1a881d3f8e46bfd517d56f952ee9725a393f5c66ef88ba8a3a38",
        "warmup_time": -1
    },
    "benchmarks.TimeInsert.time_insert_qc": {
        "code": "class TimeInsert:\n    def time_insert_qc(self, *args, **kwargs):\n        self.df.insert(loc=self.iloc, column=random_string(), value=self.item)\n        execute(self.df)\n\nclass BaseTimeSetItem:\n    def setup(self, shape, item_length, loc, is_equal_indices):\n        self.df = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH\n        ).copy()\n        self.loc, self.iloc = self.get_loc(\n            self.df, loc, item_length=item_length, axis=1\n        )\n    \n        self.item = self.df[self.loc] + 1\n        self.item_raw = self.item.to_numpy()\n        if not is_equal_indices:\n            self.item.index = reversed(self.item.index)",
        "min_run_count": 2,
        "name": "benchmarks.TimeInsert.time_insert_qc",
        "number": 0,
        "param_names": [
            "shape",
            "item_length",
            "loc",
            "is_equal_indices"
        ],
        "params": [
            [
                "(5000, 5000)",
                "(1000000, 10)"
            ],
            [
                "1"
            ],
            [
                "'zero'",
                "'middle'",
                "'last'"
            ],
            [
                "True",
                "False"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "6a36fc5cdb39f04cd6acb87bb95abcbb19bda4f85209e8d039c523287bdbf7a2",
        "warmup_time": -1
    },
    "benchmarks.TimeInsert.time_insert_raw": {
        "code": "class TimeInsert:\n    def time_insert_raw(self, *args, **kwargs):\n        self.df.insert(loc=self.iloc, column=random_string(), value=self.item_raw)\n        execute(self.df)\n\nclass BaseTimeSetItem:\n    def setup(self, shape, item_length, loc, is_equal_indices):\n        self.df = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH\n        ).copy()\n        self.loc, self.iloc = self.get_loc(\n            self.df, loc, item_length=item_length, axis=1\n        )\n    \n        self.item = self.df[self.loc] + 1\n        self.item_raw = self.item.to_numpy()\n        if not is_equal_indices:\n            self.item.index = reversed(self.item.index)",
        "min_run_count": 2,
        "name": "benchmarks.TimeInsert.time_insert_raw",
        "number": 0,
        "param_names": [
            "shape",
            "item_length",
            "loc",
            "is_equal_indices"
        ],
        "params": [
            [
                "(5000, 5000)",
                "(1000000, 10)"
            ],
            [
                "1"
            ],
            [
                "'zero'",
                "'middle'",
                "'last'"
            ],
            [
                "True",
                "False"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "3df7c66b76b70618061bcfe51d0d0b9e10c21a48362cc453908a653cbe2fd176",
        "warmup_time": -1
    },
    "benchmarks.TimeJoin.time_join": {
        "code": "class TimeJoin:\n    def time_join(self, shapes, how, sort):\n        # join dataframes on index to get the predictable shape\n        execute(self.df1.join(self.df2, how=how, lsuffix=\"left_\", sort=sort))\n\n    def setup(self, shapes, how, sort):\n        self.df1 = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shapes[0], RAND_LOW, RAND_HIGH\n        )\n        self.df2 = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shapes[1], RAND_LOW, RAND_HIGH\n        )",
        "min_run_count": 2,
        "name": "benchmarks.TimeJoin.time_join",
        "number": 0,
        "param_names": [
            "shapes",
            "how",
            "sort"
        ],
        "params": [
            [
                "((5000, 5000), (5000, 5000))",
                "((500000, 20), (1000000, 10))"
            ],
            [
                "'left'",
                "'inner'"
            ],
            [
                "False"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "1aebc2ab80819fc05dfc2e9db051894b755bc1f69150780b6a4541019f1728dc",
        "warmup_time": -1
    },
    "benchmarks.TimeMerge.time_merge": {
        "code": "class TimeMerge:\n    def time_merge(self, shapes, how, sort):\n        # merge dataframes by index to get the predictable shape\n        execute(\n            self.df1.merge(\n                self.df2, left_index=True, right_index=True, how=how, sort=sort\n            )\n        )\n\n    def setup(self, shapes, how, sort):\n        self.df1 = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shapes[0], RAND_LOW, RAND_HIGH\n        )\n        self.df2 = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shapes[1], RAND_LOW, RAND_HIGH\n        )",
        "min_run_count": 2,
        "name": "benchmarks.TimeMerge.time_merge",
        "number": 0,
        "param_names": [
            "shapes",
            "how",
            "sort"
        ],
        "params": [
            [
                "((5000, 5000), (5000, 5000))",
                "((500000, 20), (1000000, 10))"
            ],
            [
                "'left'",
                "'inner'"
            ],
            [
                "False"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "5dd956fb7db1d5b0a96e59375c5e98318f9f43faa97b9b6562cf41d9445c9d9a",
        "warmup_time": -1
    },
    "benchmarks.TimeMultiIndexing.time_multiindex_loc": {
        "code": "class TimeMultiIndexing:\n    def time_multiindex_loc(self, shape):\n        execute(\n            self.df.loc[\n                self.df.index[2] : self.df.index[-2],\n                self.df.columns[2] : self.df.columns[-2],\n            ]\n        )\n\n    def setup(self, shape):\n        df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n    \n        index = pd.MultiIndex.from_product([df.index[: shape[0] // 2], [\"bar\", \"foo\"]])\n        columns = pd.MultiIndex.from_product(\n            [df.columns[: shape[1] // 2], [\"buz\", \"fuz\"]]\n        )\n    \n        df.index = index\n        df.columns = columns\n    \n        self.df = df.sort_index(axis=1)",
        "min_run_count": 2,
        "name": "benchmarks.TimeMultiIndexing.time_multiindex_loc",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "(5000, 5000)",
                "(1000000, 10)"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "80e00dd183fe0c4a8126be25f72361ee20f99910b9769b7b35381e106e45dc4f",
        "warmup_time": -1
    },
    "benchmarks.TimeProperties.time_columns": {
        "code": "class TimeProperties:\n    def time_columns(self, shape):\n        return self.df.columns\n\n    def setup(self, shape):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)",
        "min_run_count": 2,
        "name": "benchmarks.TimeProperties.time_columns",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "(5000, 5000)",
                "(1000000, 10)"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "effb7b0976e7b3b0ee005ca8318ad48fb5588e1836d8ec6535810367e46725a8",
        "warmup_time": -1
    },
    "benchmarks.TimeProperties.time_index": {
        "code": "class TimeProperties:\n    def time_index(self, shape):\n        return self.df.index\n\n    def setup(self, shape):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)",
        "min_run_count": 2,
        "name": "benchmarks.TimeProperties.time_index",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "(5000, 5000)",
                "(1000000, 10)"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "487a3dbef05f696142e0534475d8373a9075dd28d31de0cf3449ca7a95ffb7b2",
        "warmup_time": -1
    },
    "benchmarks.TimeProperties.time_shape": {
        "code": "class TimeProperties:\n    def time_shape(self, shape):\n        return self.df.shape\n\n    def setup(self, shape):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)",
        "min_run_count": 2,
        "name": "benchmarks.TimeProperties.time_shape",
        "number": 0,
        "param_names": [
            "shape"
        ],
        "params": [
            [
                "(5000, 5000)",
                "(1000000, 10)"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "b8ce432425cc9aa74975357694dfa8cb95a0553d19b8daf97522757a0a607904",
        "warmup_time": -1
    },
    "benchmarks.TimeResetIndex.time_reset_index": {
        "code": "class TimeResetIndex:\n    def time_reset_index(self, shape, drop, level):\n        execute(self.df.reset_index(drop=drop, level=level))\n\n    def setup(self, shape, drop, level):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n    \n        if level:\n            index = pd.MultiIndex.from_product(\n                [self.df.index[: shape[0] // 2], [\"bar\", \"foo\"]],\n                names=[\"level_1\", \"level_2\"],\n            )\n            self.df.index = index",
        "min_run_count": 2,
        "name": "benchmarks.TimeResetIndex.time_reset_index",
        "number": 0,
        "param_names": [
            "shape",
            "drop",
            "level"
        ],
        "params": [
            [
                "(5000, 5000)",
                "(1000000, 10)"
            ],
            [
                "False",
                "True"
            ],
            [
                "None",
                "'level_1'"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "4ae1af8df03b9d41e917e8e6e18bd1eea483e80e35aa4f462ed1acee2f0a94a2",
        "warmup_time": -1
    },
    "benchmarks.TimeSetItem.time_setitem_qc": {
        "code": "class TimeSetItem:\n    def time_setitem_qc(self, *args, **kwargs):\n        self.df[self.loc] = self.item\n        execute(self.df)\n\nclass BaseTimeSetItem:\n    def setup(self, shape, item_length, loc, is_equal_indices):\n        self.df = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH\n        ).copy()\n        self.loc, self.iloc = self.get_loc(\n            self.df, loc, item_length=item_length, axis=1\n        )\n    \n        self.item = self.df[self.loc] + 1\n        self.item_raw = self.item.to_numpy()\n        if not is_equal_indices:\n            self.item.index = reversed(self.item.index)",
        "min_run_count": 2,
        "name": "benchmarks.TimeSetItem.time_setitem_qc",
        "number": 0,
        "param_names": [
            "shape",
            "item_length",
            "loc",
            "is_equal_indices"
        ],
        "params": [
            [
                "(5000, 5000)",
                "(1000000, 10)"
            ],
            [
                "1"
            ],
            [
                "'zero'",
                "'middle'",
                "'last'"
            ],
            [
                "True",
                "False"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "1dcdd3d591970df5bad4e794a6b247d6b11cd6be21cf344809de06747fafbe17",
        "warmup_time": -1
    },
    "benchmarks.TimeSetItem.time_setitem_raw": {
        "code": "class TimeSetItem:\n    def time_setitem_raw(self, *args, **kwargs):\n        self.df[self.loc] = self.item_raw\n        execute(self.df)\n\nclass BaseTimeSetItem:\n    def setup(self, shape, item_length, loc, is_equal_indices):\n        self.df = generate_dataframe(\n            ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH\n        ).copy()\n        self.loc, self.iloc = self.get_loc(\n            self.df, loc, item_length=item_length, axis=1\n        )\n    \n        self.item = self.df[self.loc] + 1\n        self.item_raw = self.item.to_numpy()\n        if not is_equal_indices:\n            self.item.index = reversed(self.item.index)",
        "min_run_count": 2,
        "name": "benchmarks.TimeSetItem.time_setitem_raw",
        "number": 0,
        "param_names": [
            "shape",
            "item_length",
            "loc",
            "is_equal_indices"
        ],
        "params": [
            [
                "(5000, 5000)",
                "(1000000, 10)"
            ],
            [
                "1"
            ],
            [
                "'zero'",
                "'middle'",
                "'last'"
            ],
            [
                "True",
                "False"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "6cae5f1f7d662915a35e36dc638b77707287a9bc5f67309f89f75fd57743ef01",
        "warmup_time": -1
    },
    "benchmarks.TimeSortValues.time_sort_values": {
        "code": "class TimeSortValues:\n    def time_sort_values(self, shape, columns_number, ascending_list):\n        execute(self.df.sort_values(self.columns, ascending=self.ascending))\n\n    def setup(self, shape, columns_number, ascending_list):\n        self.df = generate_dataframe(ASV_USE_IMPL, \"int\", *shape, RAND_LOW, RAND_HIGH)\n        self.columns = random_columns(self.df.columns, columns_number)\n        self.ascending = (\n            random_booleans(columns_number)\n            if ascending_list\n            else bool(random_booleans(1)[0])\n        )",
        "min_run_count": 2,
        "name": "benchmarks.TimeSortValues.time_sort_values",
        "number": 0,
        "param_names": [
            "shape",
            "columns_number",
            "ascending_list"
        ],
        "params": [
            [
                "(5000, 5000)",
                "(1000000, 10)"
            ],
            [
                "1",
                "2",
                "10",
                "100"
            ],
            [
                "False",
                "True"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "5cf2258ccb3d7833acd5e9765b8023fdbf0d27fd70e540f457f576be26c37ec9",
        "warmup_time": -1
    },
    "benchmarks.TimeValueCountsFrame.time_value_counts": {
        "code": "class TimeValueCountsFrame:\n    def time_value_counts(self, *args, **kwargs):\n        execute(self.df.value_counts(subset=self.subset))\n\nclass BaseTimeValueCounts:\n    def setup(self, shape, ngroups=5, subset=1):\n        ngroups = translator_groupby_ngroups(ngroups, shape)\n        self.df, self.subset = generate_dataframe(\n            ASV_USE_IMPL,\n            \"int\",\n            *shape,\n            RAND_LOW,\n            RAND_HIGH,\n            groupby_ncols=subset,\n            count_groups=ngroups,\n        )",
        "min_run_count": 2,
        "name": "benchmarks.TimeValueCountsFrame.time_value_counts",
        "number": 0,
        "param_names": [
            "shape",
            "ngroups",
            "subset"
        ],
        "params": [
            [
                "(5000, 5000)",
                "(1000000, 10)"
            ],
            [
                "100",
                "'huge_amount_groups'"
            ],
            [
                "2",
                "10"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "488013b792c8a1214b90fe24d1b8841b79b064073eec3c9c83d6c8132499b600",
        "warmup_time": -1
    },
    "benchmarks.TimeValueCountsSeries.time_value_counts": {
        "code": "class TimeValueCountsSeries:\n    def time_value_counts(self, shape, ngroups, bins):\n        execute(self.df.value_counts(bins=bins))\n\n    def setup(self, shape, ngroups, bins):\n        super().setup(ngroups=ngroups, shape=shape)\n        self.df = self.df[self.subset[0]]",
        "min_run_count": 2,
        "name": "benchmarks.TimeValueCountsSeries.time_value_counts",
        "number": 0,
        "param_names": [
            "shape",
            "ngroups",
            "bins"
        ],
        "params": [
            [
                "(5000, 5000)",
                "(1000000, 10)"
            ],
            [
                "100",
                "'huge_amount_groups'"
            ],
            [
                "None",
                "3"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "161a0ca50c23d2aadc9c3fc29d46e3cd4699d4354b8a8b752b6d17f67e924a85",
        "warmup_time": -1
    },
    "io.csv.TimeReadCsvNamesDtype.time_read_csv_names_dtype": {
        "code": "class TimeReadCsvNamesDtype:\n    def time_read_csv_names_dtype(self, cache, shape, names, dtype):\n        execute(\n            IMPL[ASV_USE_IMPL].read_csv(\n                self.filename,\n                names=self.names,\n                header=0,\n                dtype=self.dtype,\n                parse_dates=self.parse_dates,\n            )\n        )\n\n    def setup(self, cache, shape, names, dtype):\n        file_id = self._get_file_id(shape, dtype)\n        self.filename, self.names, self.dtype = cache[file_id]\n    \n        self.parse_dates = None\n        if dtype == \"Int64_Timestamp\":\n            # cached version of dtype should not change\n            self.dtype = self.dtype.copy()\n            for col in self._timestamp_columns:\n                del self.dtype[col]\n            self.parse_dates = self._timestamp_columns\n\n    def setup_cache(self, test_filename=\"io_test_file_csv_names_dtype\"):\n        # filenames with a metadata of saved dataframes\n        cache = {}\n        for shape in UNARY_OP_DATA_SIZE[ASV_DATASET_SIZE]:\n            for dtype in self._dtypes_params:\n                df = generate_dataframe(\"pandas\", \"int\", *shape, RAND_LOW, RAND_HIGH)\n                if dtype == \"Int64_Timestamp\":\n                    df = self._add_timestamp_columns(df)\n    \n                file_id = self._get_file_id(shape, dtype)\n                cache[file_id] = (\n                    f\"{test_filename}_{file_id}.csv\",\n                    df.columns.to_list(),\n                    df.dtypes.to_dict(),\n                )\n                df.to_csv(cache[file_id][0], index=False)\n        return cache",
        "min_run_count": 2,
        "name": "io.csv.TimeReadCsvNamesDtype.time_read_csv_names_dtype",
        "number": 0,
        "param_names": [
            "shape",
            "names",
            "dtype"
        ],
        "params": [
            [
                "(5000, 5000)",
                "(1000000, 10)"
            ],
            [
                "'array-like'"
            ],
            [
                "'Int64'",
                "'Int64_Timestamp'"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "setup_cache_key": "/modin/asv_bench/benchmarks/io/csv.py:105",
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "6d9fdff5f8961d02d0843ec80266028f57a32a5aa14c55979377594b2641bf5e",
        "warmup_time": -1
    },
    "io.csv.TimeReadCsvSkiprows.time_skiprows": {
        "code": "class TimeReadCsvSkiprows:\n    def time_skiprows(self, test_filenames, shape, skiprows):\n        execute(\n            IMPL[ASV_USE_IMPL].read_csv(\n                test_filenames[self.shape_id], skiprows=self.skiprows\n            )\n        )\n\n    def setup(self, test_filenames, shape, skiprows):\n        super().setup(test_filenames, shape, skiprows)\n        self.skiprows = self.skiprows_mapping[skiprows] if skiprows else None\n\nclass BaseReadCsv:\n    def setup_cache(self, test_filename=\"io_test_file\"):\n        test_filenames = {}\n        for shape in UNARY_OP_DATA_SIZE[ASV_DATASET_SIZE]:\n            shape_id = get_shape_id(shape)\n            test_filenames[shape_id] = f\"{test_filename}_{shape_id}.csv\"\n            df = generate_dataframe(\"pandas\", \"str_int\", *shape, RAND_LOW, RAND_HIGH)\n            df.to_csv(test_filenames[shape_id], index=False)\n    \n        return test_filenames",
        "min_run_count": 2,
        "name": "io.csv.TimeReadCsvSkiprows.time_skiprows",
        "number": 0,
        "param_names": [
            "shape",
            "skiprows"
        ],
        "params": [
            [
                "(5000, 5000)",
                "(1000000, 10)"
            ],
            [
                "None",
                "'lambda_even_rows'",
                "'range_uniform'",
                "'range_step2'"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "setup_cache_key": "/modin/asv_bench/benchmarks/io/csv.py:36",
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "f6ad8ffc075d605a25794b542b05d79b933743a4ad6bf416241dae3f6ec0bbe3",
        "warmup_time": -1
    },
    "scalability.scalability_benchmarks.TimeFromPandas.time_from_pandas": {
        "code": "class TimeFromPandas:\n    def time_from_pandas(self, shape, cpus):\n        execute(from_pandas(self.data))\n\n    def setup(self, shape, cpus):\n        self.data = pandas.DataFrame(gen_data(\"int\", *shape, RAND_LOW, RAND_HIGH))\n        from modin.config import NPartitions\n    \n        NPartitions.get = lambda: cpus\n        # trigger ray init\n        pd.DataFrame([])",
        "min_run_count": 2,
        "name": "scalability.scalability_benchmarks.TimeFromPandas.time_from_pandas",
        "number": 0,
        "param_names": [
            "shape",
            "cpus"
        ],
        "params": [
            [
                "(5000, 5000)",
                "(1000000, 10)"
            ],
            [
                "4",
                "16",
                "32"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "8af06db97bd87859b17230125772585ddc3fe0c5e23426aca77776870540eab1",
        "warmup_time": -1
    },
    "scalability.scalability_benchmarks.TimeToPandas.time_to_pandas": {
        "code": "class TimeToPandas:\n    def time_to_pandas(self, shape, cpus):\n        # to_pandas is already synchronous\n        to_pandas(self.data)\n\n    def setup(self, shape, cpus):\n        from modin.config import NPartitions\n    \n        NPartitions.get = lambda: cpus\n        self.data = generate_dataframe(\"modin\", \"int\", *shape, RAND_LOW, RAND_HIGH)",
        "min_run_count": 2,
        "name": "scalability.scalability_benchmarks.TimeToPandas.time_to_pandas",
        "number": 0,
        "param_names": [
            "shape",
            "cpus"
        ],
        "params": [
            [
                "(5000, 5000)",
                "(1000000, 10)"
            ],
            [
                "4",
                "16",
                "32"
            ]
        ],
        "processes": 2,
        "repeat": 0,
        "sample_time": 0.01,
        "timeout": 60.0,
        "type": "time",
        "unit": "seconds",
        "version": "6e9561fb9fd503ccfe496c5c520304c983774eaabfbe0ec8958c49b39bdec972",
        "warmup_time": -1
    },
    "version": 2
}